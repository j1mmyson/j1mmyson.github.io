[ { "title": "2년차 개발자(?)의 늦은 1년차 회고", "url": "/posts/LongTimeNoSee/", "categories": "Diary", "tags": "memoirs", "date": "2024-04-10 21:48:00 +0900", "snippet": "목차 역시나 심리적 안전감은 중요했다. 이직을 고민하며 느낀점들 말하기 능력은 중요하다 글을 끝까지 완성시키는게 왜이리 어려운지.. 마치며어느새 취업한지 1년이 지나 2년차 개발자(?)가 되었다.총선 덕에 간만에 평일에 쉴 시간이 났고, 집에서 나와 투표를 하고 뭘 할까 고민하다가 2년차가 된 기념으로 1년차를 회고하는 글을 쓰기로 했다.그냥 가볍게,, 내가 1년동안 회사를 다니면서 느꼈던 점, 푸념들을 의식의 흐름대로 나열해보려고 한다.역시나 심리적 안전감은 중요했다취준 시절,, 나는 스타트업에 합류하여 성장에 기여하고 싶다는 생각이 컸기 때문에 스타트업의 개발 문화, 업무 방식등에 관심이 많았다.그 중 특히 공감이 많이 갔던 한 가지가 “심리적 안전감을 가진 조직은 더 좋은 성과를 낸다” 라는 것이었다.그래서 자소서에서도 소프트 스킬과 팀플레이를 중요시하는 뉘앙스로 적어두었던 기억이 난다.내가 어떤 팀에 합류하게 될까, 잘 적응할 수 있을까 등 걱정반 기대반이 있었는데 내가 합류하게될 조직에서 심리적 안전감에 대한 결핍을 경험하게 될 줄은 몰랐다. 하하,,팀 내에서 심리적 안전감을 느끼지 못하게 되면 어떻게 되는가?사람마다 다르겠지만 나 같은 경우엔 업무에 임함에 있어 자아가 존재하지 않게 되었다.바람적이지 못하다는 것을 알고 있었고 내 나름대로의 노력을 해보았지만 나아질 기미가 보이지 않았던 것 같다.다행히 지금은 잘 적응해서 너무나도 잘 지내고 있다.업무 수행 능력, 적극성, 팀원에게 주는 신뢰 등 여러가지 면에서 저 때에 비해 확연히 나아졌다.의도치 않게 1년차부터 심리적 안전감의 중요성에 대해 뼈저리게 느낄 수 있었고, 내가 후에 시니어가 되었을 때 어떻게 팀의 높은 심리적 안전감에 기여해서 원팀으로 만들 수 있을까, 주니어 들과 어떻게 소통해야할까 고민할 수 있는 계기가 되었다.여튼, 주니어에게 신뢰를 주고 자신감을 불어넣어주는 것은 주니어의 성장에 지대한 영향을 미칠것이다.라는 말을 꼭 적고 싶었다.이직 고민을 하게되면서 느낀 점들저 당시 이직에 대한 고민이 정말 많았다. (말로만 ㅋㅋ)단순히 심리적 안전감에 대한 결핍 때문만은 아니였고 (0순위긴 했지만 ㅎㅎ,,), 내가 원하던 직무와 거리가 멀었던 직무라는 점 (코테, 기술 면접을 거쳐 입사하였는데 개발 비중이 낮은 직무라니 ㅠㅠ) 등 여러가지 복합적인 요소가 쌓여 있었다.이 때 가장 발목을 붙잡았던 요소가 크게 3가지 정도 있었다. 채용 시장이 너무 추웠다. 연봉, 배울점이 많은 팀원분들 등 포기해야 하는 것들,, 퇴근 후 이직 준비하는게 정말 쉽지 않았다.주변 사람들에게 이직에 대한 푸념을 내놓으면 가장 많이 듣는 말이 기회비용에 대한 얘기였다.업계 탑급은 아니지만 신입 기준 높은 수준의 대우를 받고 있었던 것도 사실이었고, 경력을 포기하고 신입으로 들어갔을 때 더 좋은 대우를 받기 힘들었던 것도 맞고 이를 위해 코테, 자소서, 면접등을 준비하기엔 수지타산도 맞지 않아보였다.그래서 기회비용 측면에서 따져봤을 땐 적절한 시기가 아니였고, 그냥 내가 심적인 이유로 좀 섣불리 고민을 하고 있었던 걸 알게 되었다.근데 뭐, 당시엔 기회비용은 크게 신경쓰지 않기로 했다.결론적으로는 관심가는 공고중 나의 핏에 맞는 공고가 없었고, 부족한 핏을 채우기 위해서는 개인 시간에 준비가 필요했는데 그러기엔 여유롭지 못했던 것 같다.그래서 지금은?위에 적어놨듯이 지금은 뭐 스트레스 받지않고 잘 다니고 있고, 심리적 안전감이 어느정도 채워지니 자연스럽게 활력, 업무에 대한 욕심 등도 생겨났다.그래서 당장은 이직에 대한 강박은 없고 팀과 회사에 기여할 수 있는 것들에 집중하고 있다.최근 회사 업무와 개인 공부를 통해 채워나가고 있는 개발 지식은 아래 정도.. 있을 것 같다.회사에선 레디스의 a to z 동접 유저가 늘어나면 게임서버, 레디스, DB는 어떻게 확장하여야 하는가?집에선 함수형 프로그래밍 레디스 golang ㅎㅎ;말하기 능력은 중요하다1년동안 크게 느꼈던 것 중 또 한가지는 말을 잘 해야 한다는 것이다.말로 부족한 것을 채우라는 것이 아니고,,아무리 좋은 내용을 전하더라도 말을 잘 하지 못하면 전달력이 떨어지고 전달하려는 내용에 대한 신뢰도 낮아질 수 있다는 것이다.어떤 날은 또 괜찮다가 어떤 날은 정말 발음이 뭉개지고 긴장을 많이하게 되는데 그럴 때 마다 말하는 연습을 해야겠구나 느낀다.최근에는 한석준 아나운서님의 ‘말하기 수업’ 이라는 책을 구매해 천천~히 읽어보고 있다.언젠가는 큰 발표에서도 떨지않고 잘 할 수 있겠지..글을 끝까지 완성시키는게 왜이리 어려운지..대학생 시절부터 조금씩 블로그에 글을 쓰기 시작했고 그 당시에도 글 하나를 완결 짓고 업로드 하는것이 정말 어려웠는데 취업 후에는 그 장벽이 더 높아진 것 같다.아무래도 더 어렵고 수준 높은 글을 쓰고 싶다는 욕심 때문이 아닐까 생각한다..지금 폴더에만 해도 닷넷의 스레드풀에 관한 글, 디자인 패턴에 관한 글, 레디스에 관한 글 등 초고만 작성해놓은 채로 업로드 되고 있지 못한 글들이 수두룩하다.지금 쓰고 있는 이 글 조차도 무사히 마무리 짓고 업로드 될 수 있을지 모르겠다 허허,그래도 이제 업무에 적응하고 마음에 여유도 더 생겼으니 올해는 다시 열심히 글을 써보려고 한다..!마치며항상 글을 마칠 때에는 무슨 말을 해야할 지 모르겠다.오늘은 내 1년 회사 생활을 하며 들었던 생각들에 대해 남겨보았다.물론 쓰고 나서 보니 너무 구구절절한 것 같아서 지운 내용도 상당히 많다 ㅎㅎ;커리어를 잘 살려나가려면 업무 외에도 개인 공부를 좀 더 해야겠구나 느꼈고,올해는 업무에 적응하여 들이는 리소스가 줄었으니 좀 더 다양한 경험을 해보려고 한다.커리어 성장을 위해서든, 취미를 위해서든, 자기계발을 위해서든 뭐든,,마치며, 혹 나처럼 조직 내에서 사람과의 관계 때문에 힘들어 하는 주니어가 있다면,,연차가 낮다고 해서 내가 꼭 그 문제의 원인이 아닐 수 있다는 것을 전해주고 싶다.나 같은 경우엔 사실 문제가 해결되었다기보단 그 분이 팀을 떠나면서 자연스럽게 심리적 안전감이 찾아왔는데 당시에는 “아 내가 문젠가, 뭘 잘못하고 있지?” 라고 자책했던 것에 비해 지금은 그때와는 정반대인 내 모습을 보며 “아 그때 꼭 나 혼자만의 문제가 아니었을 수 있겠구나” 생각한다.단순히 절대적으로 누구만의 문제야! 라기보단 자신과 잘 맞지 않는 사람을 만날 수 있고, 그게 어떤 순간에는 혼자만의 노력으로는 해결할 수 없는 문제일 수 있다는 것이다.진짜 끝으로 2024년 목표를 나열하며 글을 마무리 짓겠다. 기술적 성장 팀 내 에이스로 성장 ㅋㅋ 읽다만 책들 읽기 블로그 더 꾸준히,, 테니스, 게임 외에 취미 한 가지 더 만들기 (요리?)" }, { "title": "High Availability in REDIS (1) - Sentinel", "url": "/posts/HA_Redis_Sentinel/", "categories": "Development, DataBase", "tags": "redis, sentinel, HA", "date": "2024-01-21 19:04:00 +0900", "snippet": "Redis에서는 Sentinel, Cluster 구성을 지원하여 고가용성을 보장합니다.오늘은 고가용성이란 무엇인지, 레디스의 sentinel, cluster 구성에서는 어떻게 고가용성을 보장하는지에 대해 알아보겠습니다.고가용성(High Availability)이란?먼저 가용성이란 uptime / (uptime+downtime)즉, 서비스가 얼마나 장애없이 유저들에게 지속적으로 제공되었는지를 나타내는 지표입니다.그렇다면 가용성을 높이기 위해선 위 식의 down time을 0으로 수렴시켜야 하겠죠?서비스의 down time을 줄이기 위해서는 서비스가 다운되지 않도록 한다. 서비스가 다운되었을 때 재빨리 복구한다.요렇게 두 가지 전략을 떠올릴 수 있겠습니다.레디스에서의 고가용성은 2번 전략에 초점을 둡니다.레디스 노드가 다운되었을 때 어떻게 장애를 감지하고 재빨리 서비스를 복구시킬 것인가! 라고 할 수 있죠.레디스에서는 HA를 보장하기 위해 Sentinel 구성과 Cluster 구성을 제공합니다.두 구성의 특징이 뭔지, 어떤점이 다른지 알아봅시다.먼저 Sentinel구조 입니다.SENTINELSentinel 구성은 어떻게 HA를 제공할까요?먼저 센티넬의 가장 일반적인 구조부터 살펴봅시다. Redis는 싱글 스레드로 동작하기 때문에 여러 코어를 활용하지 못합니다.때문에 하나의 인스턴스에 두개 이상의 프로세스를 띄워 리소스를 좀 더 효과적으로 활용할 수 있습니다.Sentinel의 사전적 의미는 ‘감시자, 보초, 파수병’ 입니다.단어 뜻에서 유추가 가능하듯이 sentinel 구성은 마스터 노드가 잘 살아있는지 감시하는 센티넬 노드를 둡니다.센티넬 노드가 마스터 노드를 감시하고 있다가.. 마스터 노드가 다운된 것 같다 싶으면 마스터 노드의 replication, 즉 slave 노드를 마스터 노드로 승격시켜버리는거죠.승격 과정에 대해 좀 더 자세히 알아봅시다.아래는 센티넬 노드를 만들 때 작성하는 설정 파일입니다.https://redis.io/docs/management/config/# sentinel.conf...sentinel down-after-milliseconds mymaster 5000quorum 2...1. down-after-millisecondsmaster 노드가 살아있는지 확인하기 위한 설정값입니다.master 노드는 센티넬 노드에 주기적으로 ping을 보내게 되는데 이 설정값 이상동안 ping이 오지 않게되면 센티넬 노드는 “master가 죽었구나” 라고 판단하게 됩니다.2. quorum위 구성에서는 3대의 센티넬 노드가 있었습니다.각 센티넬 노드에서는 주기적으로 master에 핑을 요청합니다.down-after-milliseconds 시간동안 ping이 master로부터 오지 않는다면 master가 down된 상태라고 판단합니다.이를 SDOWN(Subjectively Down)이라고 합니다.그렇게 3대의 센티넬 노드중 quorum(2)만큼의 노드가 주관적 다운을 선언하게되면 이는 ODOWN(Objectively Down) 상태로 인지하게되며 슬레이브 노드 중 하나의 노드를 마스터로 선정하여 승격시키는 FailOver작업이 수행됩니다.그래서 센티넬의 페일오버 전략을 간략히 정리하면 아래와 같습니다. n대의 sentinel node가 마스터를 감시하며 주기적으로 ping을 보냅니다. master로 부터 down-after-milliseconds시간동안 응답이 오지 않는다면 SDOWN을 선언한다. quorum만큼의 센티넬 노드가 SDOWN을 선언하였다면 이는 ODOWN 상태로 간주되어 슬레이브 노드를 마스터 노드로 승격시킨다." }, { "title": "내가 만든 서버 성능 개선하기(아마도)", "url": "/posts/meopintop(1)/", "categories": "Development, Devlog", "tags": "golang, redis, side project, wss", "date": "2023-10-22 17:42:00 +0900", "snippet": "프로젝트 간단 소개현재 진행중인 사이드 프로젝트는 롤링페이퍼 서비스이다.기획자 1명, 프론트 1명, 백엔드 2명이서 진행중이며 내가 맡고 있는 부분은 유저가 롤링페이퍼를 작성하고 있을 때 다른 유저의 작업내용을 실시간으로 확인할 수 있게끔 해주는 서버제작을 담당하고 있다.웹소켓 서버를 구성하여 같은 롤링페이퍼에 참여중인 유저들끼리 데이터를 주고받을 수 있도록 구현을 하였고 go언어의 fiber 패키지를 활용해 웹소켓 서버를, 디비의 경우 인메모리 디비인 redis를 사용했다.Websocket과 Redis를 사용하게 된 이유먼저 웹소켓을 사용하게 된 이유는 두 명 이상의 유저가 같은 롤링페이퍼에 접속하게되었을 때 우리 서비스에서는 실시간으로 다른 사람의 작업내용을 확인할 수 있도록 해줘야 하기 때문에 요청 하나하나가 비교적 무겁고 단발적인 http보단 최초 연결을 맺고 이후 커넥션을 유지하는 웹소켓을 사용하기로 했다.레디스도 비슷한 이유에서 채택을 하게되었는데 비슷한 데이터가 빈번히 호출되는 서비스이기 때문에 롤링페이퍼의 실시간 데이터를 레디스에서 관리하고 롤링페이퍼 작성 작업이 최종 완료되었을 때 디비에 저장하는 식으로 진행을 하게 되었다.초기 구현 내용먼저 요청을 받았을 때 미들웨어에서 해당 요청의 프로토콜이 웹소켓이 맞는지 체크를 해준다.app.Use(&quot;/ws&quot;, func(ctx *fiber.Ctx) error { if websocket.IsWebSocketUpgrade(ctx) { return ctx.Next() } log.Println(&quot;protocol needs upgrade to websocket&quot;) return fiber.ErrUpgradeRequired})이후 메인 로직은 아래와 같다. 롤링페이퍼 아이디에 대한 커넥션을 관리하는 객체에 커넥션을 추가해준다. defer 구문을 활용해 연결이 끊길 때 현재 커넥션이 목록에서 제외되도록 보장해준다. 루프를 돌며 커넥션으로 부터 메세지가 들어올 때 까지 대기한다. 메시지가 들어오게되면 수신한 메시지를 레디스에 업데이트 해준다 업데이트 완료 이후 다시 레디스에 해당 롤링페이퍼에 대한 데이터를 요청하여 받아온 데이터를 같은 롤링페이퍼에 속한 유저에게 브로드캐스팅 해준다. app.Get(&quot;/ws/:paper_id&quot;, websocket.New(func(conn *websocket.Conn) { paperID := conn.Params(&quot;channel_id&quot;) subscriber := singleton.GetBroakerInstance() // add connection to channel subscriber.Add(paperID, conn) defer func() { // remove connection from channel subscriber.Remove(paperID, conn) // close websocket connection conn.Close() }() for { // wait for new message _, msg, err := conn.ReadMessage() if err != nil { log.Println(&quot;read message failed:&quot;, err) break } log.Printf(&quot;recv: %s\\n&quot;, msg) var payload Payload err = json.Unmarshal(msg, &amp;amp;payload) if err != nil { log.Println(&quot;unmarshal failed:&quot;, err) break } // push message to redis db := redis.GetInstance() err = db.GetAndAdd(paperID, string(msg)) if err != nil { log.Println(&quot;publish failed:&quot;, err) break } strMsg, err := db.Get(paperID) if err != nil { log.Println(&quot;get failed:&quot;, err) break } msg = []byte(strMsg) go subscriber.Broadcast(paperID, msg) log.Printf(&quot;send: %s\\n&quot;, msg) }}))문제점벌써 불편한 부분이 너무 많이보인다 ㅋㅋ..일단 가장 문제가 커 보이는 부분은 레디스에 업데이트를 완료한 뒤 다시 레디스에서 데이터를 불러와서 유저에게 브로드 캐스팅 해주는 것, 그 외에도 메시지를 수신할 때 마다 레디스 인스턴스를 불러오는 것도 굉장히 불편하다..아무튼 여기저기 굉장히 비효율적이고 멍청한 방법으로 구현을 해놨다.;.;하나씩 고쳐보자개선 방법 / 이유1. 최초 연결 시 롤링페이퍼 데이터 반환하도록 수정사실 이 부분은 버그였다고 봐도 무방하다.유저가 처음 접속하게 되면 당연히 롤링페이퍼를 반환받아와야 하는데 그렇지 못한 부분을 수정했다.2-1. 레디스에 데이터 저장하는 작업을 비동기로 처리기존에는 수신받은 데이터를 레디스에 저장하고 다시 레디스에서 데이터를 불러온 후에 유저에게 브로드 캐스팅을 하였는데 이렇게 되면 레디스와 통신하는 동안 유저는 데이터를 받지 못하고 트래픽이 몰리게 되면 이 부분에서 병목지점이 발생할 수 있는 구조이다.때문에 데이터를 수신하고 브로드캐스팅 하기 까지 대기하지 않아야 병목 지점을 없앨 수 있다고 생각하였고 데이터를 레디스에 저장하는 작업을 go 루틴을 생성하여 비동기로 처리하도록 수정하였다.이를 위해서는 한 가지 수정이 더 필요했는데 2-2 이다.이를 통해 유저가 서버로 데이터를 전송했을 때 서버는 특정 작업을 대기하지 않고 바로 브로드 캐스팅을 할 수 있게 되었다.2-2. 롤링페이퍼 전체 데이터가 아닌 수신한 메시지만 브로드캐스팅 하도록 수정실시간 데이터 동기화 (브로드캐스팅) 작업의 주기가 1초라고 가정해보자.그렇게 되면 1초마다 (현재 롤링페이퍼에 접속중인 유저) * (롤링페이퍼 전체 데이터) 만큼의 트래픽이 발생하게 된다.굉장히 비효율 적이고 유지 비용이 커질 수 밖에 없는 구조이다.뿐만 아니라 프론트에서는 현재 작업중인 유저의 데이터를 보내주게 되는데 유저 입장에서 연결 맺을 때 전체 데이터를 한번 받고, 이후에는 개별 유저들의 수정 사항에 대해서만 데이터를 받아도 실시간 업데이트가 가능한 부분이기 때문에 굳이 전체 데이터를 보내줄 필요도 없게 되었다.그래서 수신한 데이터를 바로바로 브로드 캐스팅 해주면서 유저 응답시간도 줄이고 네트워크 트래픽도 줄일 수 있었다.뭐 이 외에도 프로젝트 구조를 Go Clean Architecture 기반으로 변경한다던가, 클래스 구조, 명을 변경한다던가 하는 리팩토링 작업이 있었지만 성능적인 개선 사항을 위주로 어떤 작업을 진행했는지 남기고 싶었다.성능 개선 이전, 이후 구조에서 부하 테스트를 통해 얼마만큼의 개선이 이루어 졌는지 알 수 있었다면 좋았겠지만,, 그 부분은 아직 진행하지 못하였고.. 기회가 되면 체크해보려고 한다. 아마 부하 테스트를 하게 된다면 k6를 사용하지 않을까 싶다.결과그렇게 리팩토링된 코드다. 변경된 부분의 양이 많지는 않지만 코드 라인 수에 비해 적지 않은 성능 개선을 얻었다고 생각한다.func (m *wsHandler) WebsocketConnection(conn *websocket.Conn) { paperID := conn.Params(&quot;channel_id&quot;) log.Printf(&quot;new websocket connection: %s\\n&quot;) m.paperUsecase.Subscribe(paperID, conn) // remove connection from channel when connection is closed defer func() { m.paperUsecase.Remove(paperID, conn) conn.Close() }() // 최초 연결 시 프로젝트 데이터 수신 project, err := m.paperUsecase.GetProject(paperID) if err != nil { log.Println(&quot;get project failed:&quot;, err) return } // send project data to client err = conn.WriteMessage(websocket.TextMessage, []byte(project)) var payload domain.Payload for { // wait for new message _, msg, err := conn.ReadMessage() if err != nil { log.Println(&quot;read message failed:&quot;, err) break } log.Println(&quot;receive message:&quot;, string(msg)) // go routine에서 채널을 통해 값을 반환해주지 않으면 fire &amp;amp; forget으로 동작한다. go m.paperUsecase.PushData(payload) // fire and forget m.paperUsecase.BroadcastMessage(paperID, string(msg)) log.Printf(&quot;broadcast message: %s\\n&quot;, msg) } return}이후에 고민의 여지가 있는 포인트들?로드 밸런싱만약 이후에 스케일 아웃을 고려해 여러 대의 서버를 띄우고 앞단에 로드 밸런서를 두어 서버에 대한 부하를 분산하게 되었을 때 발생 가능한 문제는.. 각 서버가 서로 다른 롤링페이퍼-커넥션 목록을 가질 수 있다는 점이다.이 경우에는 아마도.. 각 서버끼리 공유 가능한 레디스를 통해 목록을 관리하는 방향으로 수정이 필요하지 않을까 싶다.혹은 로드 밸런서 대신 미들웨어를 두고 같은 롤링페이퍼에 속하는 유저들은 같은 서버로 접속하게끔 해주는 서버를 두는 방법도 있을 순 있겠다.레디스 구성현재 레디스는 standalone으로 배포되어있는데 가용성을 위해 센티넬 구조, 클러스터 구조를 고려해볼 수 있겠다.샤딩이 필요한가? 라고 한다면.. 롤링페이퍼 데이터는 롤링페이퍼가 작성 완료되면 폐기되기 때문에 굳이 싶긴하다.그래서 레디스 가용성을 보장하기 위해 센티넬 구조로 변경할 수 있겠다.wss서버, 레디스 configuration 최적화서버의 스레드 수를 조정한다던가, 타임아웃 설정을 한다던가, 레디스의 config를 수정하여 더 롤링페이퍼 서비스에 적절한 값을 찾는다던가 하는 작업을 진행해보는 것도 좋겠다.마치며..오랜만에 글을 쓰다보니 어떻게 끝을 맺어야 할지, 글 내용은 좀 볼만했는지 잘 모르겠다.그동안 회사 업무땜에 넘 바빠서;; 글을 많이 작성하지 못했는데 다시 열심히 글을 쓰기로 노력하기로 했다.아무튼 오늘 글을 여기까지. 끗." }, { "title": "나의 첫 회고록, 2022년을 돌아보자", "url": "/posts/2023Memoir/", "categories": "Diary", "tags": "memoirs", "date": "2023-01-08 16:59:00 +0900", "snippet": "목차 나의 2022년에는 무슨 일들이 있었나 소집해제와 동시에 막학기 GDSC 수료 취준,, 그리고 취업..! 2022년 아쉬웠던 점이 있다면? 2023년을 다짐하다 2023년에 꼭 배워보고 싶은 것들 나의 2022년에는 무슨 일들이 있었나소집해제와 동시에 막학기올해 6월. 기다리 고기다리 고기다리 던 소집해제날이 찾아왔다 허헣..심적으로 힘들었던 시절도, 신체적으로 힘들었던 시절도 있었지만 막판엔 좋은 팀장님, 담당자님을 만나서 잘 마무리를 지을 수 있었다.군 복무도 마치고 마지막 학기로 복학하게 되니 이제 정말 나의 커리어 시작을 막을 수 있는 건 없었다.아무도 날 막을 순 없으셈ㅋ이때부터 본격적으로 서류 지원을 했다. 그렇게 첫 면접을 네이버에서 보는 경험도 해보고.. 나의 면접 실력이 처참하다는 것도 알게 된 순간이었다 ㅋㅋ .복학을 하고 학교에서는 전에 소속해 있던 연구실에서 후배들 공부하는 걸 도와주는 일을 하게 되었다. 이제는 크게 관심이 없는 인공지능 분야를 공부하는 연구실이었지만 새로운 개념에 대해 배우는 것도 후배들이랑 같이 공부하는 것도 재밌고 좋은 경험이었다 ㅋㅋ.뿐만 아니라 연말엔 교수님 집에서 연말 파티도 열었다. 졸업한 선배님들, 졸업할 사람들(나..), 그리고 후배들과 함께 모여 풍성한 연말 파티를 보냈다.아마 내년 연말 파티는 더 재밌고 풍성해질듯..?아무튼.. 아무것도 모르던 저를 좋은 학생으로 지도해 주셔서 감사했습니다 교수님!GDSC 수료1년 동안 운영진을 활동했던 GDSC 동아리 활동도 마무리를 짓게 되었다.비대면인 점, 1기였다는 점들 때문에 정말 맘고생이 심했던 활동이었다..1기였기 때문에 정말 바닥부터 컨텐츠나 활동 양식을 만들었다.하지만 비대면이라는 점 때문인지 초반에 참여도가 많이.. 저조했다.다른 운영진 멤버도 공감할 테지만 역시 가장 힘들었던 것은 열심히 컨텐츠, 이벤트를 만들어도 멤버들이 참여해 주지 않을 때였다.그때의 허탈감이란… 그래도 어찌 2분기엔 대면으로도 몇 번 만나고 해커톤, 팀 프로젝트 등을 진행해서인지 성공적인 마무리를 지을 수 있게 되었다. 역시 이런 단체 활동은 대면으로 해야 하나보다 ㅋㅋ..그렇게 해커톤도 성공적으로 개최하게 되었다.다들 넘 고생했슴다 진짜ㅠ그리고 교내 활동 외에도 다른 학교의 GDSC와 함께 여러 활동을 할 수 있었던 점이 좋았다.학교 밖의 여러 개발자들을 보면서 나는 아직 많이 부족하구나.. 대단한 사람들이 정말 많구나 다시 한번 겸손한 마음을 갖게 되는 계기가 되었다 ㅋㅋ.그 외에도 winter hackerthon, GDSC Job Fair 등등 새로운 경험을 할 수 있었다.잡페어 너무 유익했고다사다난 했던 활동이었지만 지나고 보니 2022년 뜻깊었던 활동 중 한 가지였다.취준.. 그리고 취업..!GDSC 활동을 마치고 막 학기로 복학을 하게 되었다.아마 올해 가장 후회할 나의 선택 중 한 가지가 될 행동을 해버리는데 바로 남은 학점이 3학점인데도 불구하고 11학점을 들은 것이다. ㅋㅋㅋㅋㅋㅋ…..그렇지만 어쩔 수 없었다.. 내가 들은 수업이 배드민턴, 교양 경제, 정보 보안(재수강), 리눅스 이렇게 4갠데 음,,여기서 굳이 하나를 빼자면 리눅스..? 아무튼 배드민턴, 교양 경제는 꼭 듣고 싶었고 정보 보안은 재수강이라 선택의 여지가 없었다..학교생활도, 취준도 내가 생각했던 것보다 많은 시간을 필요로 했다.별거 없는 나의 학교생활을 가지고 이력서를 작성하는 데에도 진짜 많은 시간이 들었고 시험 기간과 채용 지원 날짜가 겹쳐 말도 안 되는 퀄리티의 포트폴리오를 제출하기도 했다.그러던 와중에도 몇 군데에서 서류 합격을 하게 되었고 또 그중 절반에서는 코딩 테스트도 통과하게 되었다.그렇게 자연스럽게 면접 준비도 시작하게 되었다.면접 처음엔 진짜 말도 제대로 못하고 머릿속으로 알고 있다고 생각이 드는 것도 입 밖으로 제대로 내뱉지 못하는 수준이었다.미리 다른 기업에도 지원을 해보면서 면접 연습 좀 할걸 하는 아쉬움도 남았지만 첫 취준인 만큼 내가 가고 싶은 기업에만 지원하기로 했으니 별 수 없었다. 가고 싶은 기업의 면접들을 탈락해서인지 탈락할 때마다 면접 실력이 쑥쑥 늘었고 cs 지식도 쌓여간다는 게 느껴졌다.그러다 “아 이 정도면 내년 상반기에는 취업이 가능하겠는데?”라는 생각이 들 때쯤 넷마블에 최종 합격하게 되었다…!나 어떻게 넷마블에 합격?개인적으로 어느 정도 면접 준비를 마친 후에 나라는 사람에 대해 정리해 보는 시간을 가졌던 게 꽤 많은 도움이 되었던 것 같다.취업을 하고 보니 이제 진짜 시작이라는 생각이 들었다.취업했다고 안주하지 않고 성장을 위해 달려나가는 2023년이 되었으면 좋겠다..!2022년 아쉬웠던 점이 있다면?흠.. 역시 가장 아쉬웠던 점은 2월에 코로나에 걸린 이후로 꾸준히 해오던 운동 루틴이 멈춘 것?코로나 걸리기 전엔 진짜 열심히 꾸준히 운동을 해왔었는 데 코로나 걸린 이후로 잘 안 하게 되니까 넘 억울하고 아쉬웠다.. 2023년엔 다시 예전의 그 꾸준함을 찾을 수 있도록 노력하겠다..!또 아쉬웠던 점이 있다면 책을 별로 읽지 못한 것.. 실용주의 프로그래머, 리팩터링 2판, 클린 아키텍쳐 등 구입 해놓고 반도 못 읽은 책들이 넘 많았다.. 최근에도 개발자 원칙, 조던 피터슨 형님의 12가지 인생의 법칙 책을 사놓고 펴지도 못하고 있다.. 이젠 취준도 끝냈고 학업도 끝냈으니 틈틈이 책을 꾸준히 읽어가야겠다..!2023년을 다짐하다그럼 이제 회고록의 끝으로 2023년을 어떤 마음가짐으로 어떻게 보낼 건지 다짐해 보자.먼저 신입으로 넷마블에 들어오게 되었다. 지금은 신입 교육을 받고 있어서 내가 어느 부서에서 어떤 일을 하게 될진 모르지만 좋은 사회 초년생이 되고 싶다.좋은 개발자가 되기 위해서는 물론이며 좋은 개발자 이전에 더 좋은 사람이 되려고 노력해 보자. 입사하고 보니 나보다 정말 뛰어난 사람들이 많다고 느꼈다. 이렇게 좋은 동료들을 만나는 행운을 얻은 만큼 나도 더 좋은 사람이 되기 위해 노력하자. 2023년 회고록은 어느 정도 사회생활 뉴비 딱지를 떼고 더 성숙한 사람인 채로 쓰게 되었으면 좋겠다 ㅋㅋ.끝으로 2023년 회고록의 지표로 쓸 수 있게끔 목표를 세워보자.2023년에 꼭 배워보고 싶은 것들 개발 함수형 프로그래밍, clojure? haskell? scala? gRPC MSA (Micro Service Architecture) 사이드 “팀” 프로젝트 golang으로 코테문제 풀기 개발 외 영어 공부 간단한 집밥 요리 손글씨 이쁘게 쓰기 2023년에 이것만큼은 반드시 해내겠다. 꾸준히 운동하기 (회사 헬스장이 한 달에 만 원..!?) 책 6권 이상 읽기 (일단 실용주의 프로그래머, 12가지 인생의 법칙 먼저!) 여름 전에 회사 주변에 자취하기 (출퇴근 진짜 너무 힘듬.;.;.;.;) 게임 리뷰 글쓰기 더 좋은 퀄리티의 블로그 글쓰기 (글쓰기 자체도 어려운데 어려운 주제로 쓰는 건 더 어렵다..)올해 회고록은 여기까지..2023년에 어떤 회고록을 쓰게 될지, 2023년의 내가 이 글을 보고 어떤 생각을 하게 될지 너무 궁금하다 ㅋㅋ.조금 늦었지만 다들 새해 복 많이 받으시고 2023년도 화이팅해봅시다 ㅎㅎ!" }, { "title": "[Go] strings package 파헤치기 (상)", "url": "/posts/StringsPackage/", "categories": "Development, Go", "tags": "go, golang, strings", "date": "2022-12-29 22:35:00 +0900", "snippet": "예전부터 오픈소스를 까보고 분석하는 글을 꼭 써보고 싶었는데 이번 글을 시작으로 종종 올리게 될 것 같습니다.첫 글이니까 가장 많이 쓰이면서 쉬운 편에 속한다 생각되는 문자열을 다루는 패키지 strings 대해 알아봅시다!목적내가 고언어를 다루다가 문자열을 다뤄야 할 때 보고 금방 되새김질하기 위함.따라서 strings의 모든 기능에 대해 서술하지 않음. 내가 자주 쓸 것 같은 것만!목차 Clone: 문자열의 복사본을 만들어줘 Compare: 두 문자열을 비교해줘 Count: 내가 찾는 글자가 몇개나 있어? Fields: 공백을 기준으로 문자열 나눠줘 FieldsFunc: 나만의 기준으로 문자열을 나눌래 Contains: 내가 찾는 문자열이 있어? Join: 문자열을 합쳐줘 Map: 모든 글자에 함수를 적용시키겠어 Replace: 원하는 글자만 바꿔줘 Split: sep으로 문자열을 나눠줘 Trim: 양쪽에서 cutset에 속하는 문자들을 지우고싶어Clone: 문자열의 복사본을 만들어줘문자열을 깊은 복사1 해줍니다.그렇기 때문에 당연히 새로운 메모리를 할당받게 돼요.내부적으로는 원본 s와 같은 길이의 문자열을 만들고 내용을 복사해 줍니다.func Clone(s string) string { if len(s) == 0 { return &quot;&quot; } b := make([]byte, len(s)) copy(b, s) return *(*string)(unsafe.Pointer(&amp;amp;b))}example codeCloned된 문자열과 원본 문자열은 당연히 독립적!func main() {origin := &quot;my name is byungwook&quot;copied := strings.Clone(origin)copied = &quot;my name is jimmy&quot;fmt.Println(&quot;origin: &quot;, origin)fmt.Println(&quot;copied: &quot;, copied)}================Output:my name is byungwookmy name is jimmyCompare: 두 문자열을 비교해줘간단합니다.두 문자열을 비교해 주어 같다면 0, 그렇지 않다면 어떤 문자열이 사전 순으로 빠르냐에 따라 -1, 1을 반환해 줍니다.package mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() { a := &quot;apple&quot; b := &quot;apple&quot; c := &quot;banana&quot; fmt.Println(strings.Compare(a, b)) fmt.Println(strings.Compare(a, c))}=======================Output:0-1Count: substr이 s안에 몇개 존재해?substr이 s안에 몇 개 존재하는지 반환해 줍니다.특이한 점은 substr == &quot;&quot;일 경우 len(s) + 1을 반환해 줍니다.내부적으로 Index(s, substr)를 사용하여 KMP 알고리즘을 반복해 반복되는 횟수를 구하며 시간 복잡도는 O(n), n = len(s)입니다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() { apple := &quot;apple&quot; banana := &quot;banana&quot; fmt.Println(strings.Count(banana, &quot;na&quot;)) fmt.Println(strings.Count(apple, &quot;a&quot;)) fmt.Println(strings.Count(apple, &quot;&quot;))}====================Output:216Fields: 공백을 기준으로 문자열을 나눠줘굉장히 많이 쓰일 것 같은 함수 중에 하나.공백을 기준으로 문자열을 나눠줍니다.공백이 아니라 다른 문자를 기준으로 자르고 싶다구요? 그렇다면 FieldsFunc()를 사용하시면 됩니다.example codepackage main ​ import ( &quot;fmt&quot; &quot;strings&quot; ) ​ func main() { fmt.Printf(&quot;Fields are: %q\\n&quot;, strings.Fields(&quot;공백을 기준으로 나눠줍니다 공백이 여러개여도   나눠줍니다&quot;)) } ​ ============================ Output: Fields are: [&quot;공백을&quot; &quot;기준으로&quot; &quot;나눠줍니다&quot; &quot;공백이&quot; &quot;여러개여도&quot; &quot;나눠줍니다&quot;]FieldsFunc: 나는 공백말고 다른 기준으로 문자열을 나누고 싶어!자바스크립트의 콜백 함수2가 떠오르는 방식이다.커스텀 함수를 설정하여 내가 원하는 기준으로 문자열을 나눌 수 있습니다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot; &quot;unicode&quot;)func main() {// ,를 기준으로 문자열을 나눕니다sepComma := func(r rune) bool { return r == &#39;,&#39;} // 알파벳, 숫자가 아닌 모든 문자를 기준으로 나눕니다sep := func(r rune) bool { return !unicode.IsLetter(r) &amp;amp;&amp;amp; !unicode.IsNumber(r)} fmt.Printf(&quot;Fields are: %q\\n&quot;, strings.FieldsFunc(&quot;a,b,c&quot;, sepComma)) fmt.Printf(&quot;Fields are: %q\\n&quot;, strings.FieldsFunc(&quot;이것도 / 나눠, 줄*래?&quot;, sep))}​ ============================ Output: Fields are: [&quot;a&quot; &quot;b&quot; &quot;c&quot;]Fields are: [&quot;이것도&quot; &quot;나눠&quot; &quot;줄&quot; &quot;래&quot;]Contains: 내가 찾는 문자열이 있어?substr이 s안에 존재하는지 판별해줍니다.example codepackage main ​ import ( &quot;fmt&quot; &quot;strings&quot; ) ​ func main() { fmt.Println(strings.Contains(&quot;byungwook son&quot;, &quot;son&quot;)) fmt.Println(strings.Contains(&quot;byungwook son&quot;, &quot;SON&quot;)) fmt.Println(strings.Contains(&quot;byungwook son&quot;, &quot;none&quot;)) } ​ ============================= Output: true false falsetime complexity?func Contains(s, substr string) bool { return Index(s, substr) &amp;gt;= 0 }Index 함수 내부를 보면 아래와 같이 되어있습니다.간단히 요약하자면 kmp 알고리즘을 사용하는 Index()함수가 있고 이 함수는 substr이 s에 속할 때 그 시작 인덱스를 반환하며 속하지 않는다면 -1을 반환합니다.그래서 리턴 값이 -1이 아닌 정수라면 true를 반환, -1이라면 false를 반환해 주게 됩니다.Index() if len(substr) == 0 –&amp;gt; 0 if len(substr) == 1 –&amp;gt; 처음으로 속하는 인덱스 if len(substr) == len(s) –&amp;gt; 두 문자열이 같으면 0, 다르면 -1 len(s)와 len(substr) 둘 다 충분히 작을 때 –&amp;gt; brute force로 찾음 len(s), len(substr) 모두 충분히 클 때 –&amp;gt; KMP알고리즘 사용따라서 Contains()의 시간 복잡도는 O(n + k), n = len(s), k = len(substr) = O(n)이 된다.안심하고 써도 되겠다!func Index(s, substr string) int { n := len(substr) switch { case n == 0: return 0 case n == 1: return IndexByte(s, substr[0]) case n == len(s): if substr == s { return 0 } return -1 case n &amp;gt; len(s): return -1 case n &amp;lt;= bytealg.MaxLen: // s가 16보다 작을 때는 브루트 포스로 하는게 더 빠름 if len(s) &amp;lt;= bytealg.MaxBruteForce { return bytealg.IndexString(s, substr) } c0 := substr[0] c1 := substr[1] i := 0 t := len(s) - n + 1 fails := 0 for i &amp;lt; t { if s[i] != c0 { o := strings.IndexByte(s[i+1:t], c0) if o &amp;lt; 0 { return -1 } i += o + 1 } if s[i+1] == c1 &amp;amp;&amp;amp; s[i:i+n] == substr { return i } fails++ i++ if fails &amp;gt; bytealg.Cutover(i) { r := bytealg.IndexString(s[i:], substr) if r &amp;gt;= 0 { return r + i } return -1 } } return -1 } c0 := substr[0] c1 := substr[1] i := 0 t := len(s) - n + 1 fails := 0 for i &amp;lt; t { if s[i] != c0 { o := IndexByte(s[i+1:t], c0) if o &amp;lt; 0 { return -1 } i += o + 1 } if s[i+1] == c1 &amp;amp;&amp;amp; s[i:i+n] == substr { return i } i++ fails++ if fails &amp;gt;= 4+i&amp;gt;&amp;gt;4 &amp;amp;&amp;amp; i &amp;lt; t { j := bytealg.IndexRabinKarp(s[i:], substr) if j &amp;lt; 0 { return -1 } return i + j } } return -1 }Join: 문자열을 합쳐줘Fields()의 역연산(?)이다.이것도 굉장히 많이 쓰일 듯?? 사용법도 매우 간단하다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() { s := []string{&quot;one&quot;, &quot;two&quot;, &quot;three&quot;} fmt.Println(strings.Join(s, &quot;, &quot;))}======================Output:one, two, threeMap: 모든 글자에 mapping을 거친 문자열을 반환해줘문자열에 있는 한 글자마다 mapping()을 적용시킨 문자열을 반환해 줍니다.원본 문자열에 영향을 미치진 않습니다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot; &quot;unicode&quot;)func main() { s := &quot;HeLLo STRINgs pAckaGE!&quot; // 대문자를 전부 마스킹 해줍니다 f := func(r rune) rune { if unicode.IsUpper(r) { return &#39;*&#39; } return r } fmt.Println(&quot;대문자를 마스킹해줘: &quot;, strings.Map(f, s)) fmt.Println(s)}=======================Output:대문자를 마스킹해줘: *e**o *****gs p*cka**!HeLLo STRINgs pAckaGE!Replace: 원하는 글자만 바꿔줘문자열에서 특정 문자를 원하는 문자로 바꾸어주는 함수입니다.n = -1인 경우 ReplaceAll()과 같은 행동을 취합니다.실제 ReplaceAll()함수를 보면 이렇게 짜여있음ㅋㅋfunc ReplaceAll(s, old, new string) string { return Replace(s, old, new, -1)}Replace()는 새로운 메모리를 할당하여 문자열을 만들어주기 때문에 원본에 영향을 미치지 않는다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() { pig := &quot;oink oink oink&quot; cow := strings.Replace(pig, &quot;oink&quot;, &quot;moo&quot;, -1) cow2 := strings.Replace(pig, &quot;oink&quot;, &quot;moo&quot;, 2) fmt.Println(pig) fmt.Println(cow) fmt.Println(cow2)}=========================Output:oink oink oinkmoo moo moomoo moo oinkSplit: sep으로 문자열을 나눠줘FieldsFunc()와 비슷한 듯 다른 함수입니다.사용법은 매우 간단합니다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() { pig := &quot;oink pig oink pig oink&quot; fmt.Printf(&quot;%q\\n&quot;, strings.Split(pig, &quot;pig&quot;))}======================Output:[&quot;oink &quot; &quot; oink &quot; &quot; oink&quot;]Trim: 양쪽에서 cutset을 없애고 싶어trim은 손질하다 라는 의미를 갖는 동사입니다.양쪽에서 cutset에 해당하는 문자를 삭제하여 반환해 줍니다.문자열의 양쪽에 존재하는 공백을 지울 때 유용할 듯합니다.자매품으로 TrimLeft(), TrimRight()와 같은 함수들도 있습니다.example codepackage mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() { s := &quot; Hello world &quot; s2 := &quot;trashtrash HELLO WORLD trashtrash&quot; fmt.Println(strings.Trim(s, &quot; &quot;)) fmt.Println(strings.Trim(s2, &quot;tarhs &quot;))}=========================Output:Hello worldHELLO WORLD다음 글에서는 Builder와 Reader에 대해 알아보겠습니다.!Foot Note 깊은 복사(deepcopy): 실제 값을 메모리의 새로운 공간에 할당하는 행위를 말한다. &amp;#8617; 콜백함수(callback): 다른 코드의 인수로서 넘겨주는 실행 가능한 코드를 말한다. &amp;#8617; " }, { "title": "2022 넷마블컴퍼니 공채 최종합격 후기", "url": "/posts/netmarble/", "categories": "Diary", "tags": "netmarble, 2022netmarble, recruit, job hunting", "date": "2022-12-24 04:34:00 +0900", "snippet": "10월 6일.2022 넷마블컴퍼니 신입사원 채용공고가 떴고 나는 넷마블 본사의 소프트웨어 엔지니어 직무에 지원을 하게되었다.2022 넷마블 공채내가 지원한 직무는 본사 소프트웨어 엔지니어서류전형 이때까지만 해도 내가 최종합격을 하게될 줄 누가 알았으랴..나의 깃헙/블로그 주소와 함께 게임 산업에 관심을 갖게 된 이유, 기술/커뮤니케이션 역량을 보여줄 수 있었던 경험을 자소서에 적어서 제출하였다.최종 합격을 하고 보니 서류전형이 가장 중요했던 것 같다. 면접까지 간다고 생각하고 서류를 작성해야 한다.과장된 내용 없이, 솔직하게 내용을 작성하였고 그 부분이 좀 더 맘 편히 면접을 보게 해주었던 요소였다고 생각한다.서류 합격!결과는 합격.코딩테스트를 준비하게 되었다.코딩 테스트코딩 테스트는 프로그래머스를 통해 이루어졌다.화면 공유와 웹캠을 통해 부정행위를 방지하였고 문제는 총 4문제였던 걸로 기억한다.백준 기준으로 실버 상위 티어 2문제, 골드 티어 2문제 수준이었다고 생각이 든다.나의 경우엔 3문제를 풀고 제출하였으나 한 문제에 대해 최적의 알고리즘을 구현하지 못했디고 생각해서 아마 2.5솔로 제출하게 되었다.이 문제에 사용한 알고리즘을 전에 블로그에 정리해서 남겨두었는데 그때 글로 남기면서 좀 더 머릿속에 기억에 남게 되어서 풀 수 있었던 문제라고 생각한다. 과거의 나 너무 고맙다..그렇게 결과가 나왔고 또다시 합격. 오픈채팅에서 합격 컷을 들어보니 1솔부터 4솔까지 다양했다.서류와 포폴까지 종합해서 갈랐나? 하지만 정확한 정보는 아니다.개인적으로는 아슬하게 통과했다고 생각한다.넷마블 테스트넷마블의 경우에는 오프라인으로 cs 필기테스트 + 넷마블 애사심(!?) 테스트 를 보았다.엔씨도 이런 형식의 테스트를 본다고 들었는데 게임업계 쪽에서는 게임, 게임산업에 대한 관심과 배경지식을 중요시한다는 것이 느껴졌다.cs 필기테스트 같은 경우에는 전공지식 공부를 하면 되겠다 싶었는데 넷마블 테스트? 뭘 공부해야 하나 싶었다.후기를 살펴보니 넷마블 홈페이지에 나와있는 내용을 모두 익혀야 한다고 하더라.. 나 같은 경우에는 홈페이지를 한번 싹 훑으면서 뼈대를 잡고 오픈채팅에서 사람들과 함께 스터디를 하게 되었다.스터디도 누가 모집하냐에 따라 형식이 다 달랐다.소수 정예로 각자 맡은 부분에 대해 꼼꼼하게 조사(내가 느끼기엔 좀 과했다) 하여 서로 공유하는 방이 있었던 반면에 그냥 사람들 여러 명이서 udp 패킷 던지듯이 가볍고 많은 양의 정보를 툭툭 던지는 식의 스터디도 있었고 나는 후자에 해당하는 방에 들어가 함께하였다.이 스터디가 굉장히 도움이 되었다. 내가 생각지도 못한 정보를 많이 던져주셨다.나는 스터디원분들이 던져주는 방대한 양의 정보를 하나로 취합하여 다시 올려주었다 ㅋㅋ.실제로 같이 준비한 부분에서 꽤 많은 문제가 출제되었다. 그리고 이 스터디에서 꽤 많은 분들이 최종 합격까지 생존하셨다 ㅋㅋㅋㅋ 굿!.다시 한번 넷마블 퀴즈방 분들에게 감사의 마음을 전합니다 ㅎㅎ..그렇게 넷마블 테스트 당일이 되었고 용산고등학교에서 총 3시간 동안 넷마블 테스트를 보게 되었다. 근처 역인 숙대 입구역에 이런 표지판을 보고 찾아갈 수 있게 되어있었다.보고 따라가다보면 시험장에 도착!학교에서 시험을 보니 수능의 분위기가 살짝 느껴졌었다 ㅋㅋㅋㅋㅋ. 수능인데 같은 고사실끼리 경쟁자인 수능..ㅎㄷㄷ..그렇게 3시간 동안의 시험을 마치게 되었고 집에 돌아오게 되었다.아 그리고 학교 1층에서 소정의 굿즈를 제공해 주었는데 이런 사소한 부분이 넷마블에 가고 싶은 욕구를 더 끌어올렸던 것 같다 ㅋㅋ.공책과 캐릭터 거울이 들어있다.결과는…. 역시나 합격!1차 면접을 준비하게 되었다. 면접 경험이 많지 않아 걱정이 많았다.그래도 어떡하겠는가 다른 두 명의 지원자와 기술면접 스터디를 결성하였고 함께 열심히 준비하게 되었다.1차 기술면접스터디원분들과 열심히 준비하고, 면접 왕 이형님의 유튭을 챙겨보면서 면접에 대한 감을 좀 잡을 수 있었다.1차 면접은 기술면접인 만큼 CS 지식에 대해 꼼꼼히 공부를 하였고 생각을 정리하여 말하는 연습(이게 진짜 중요한 듯)도 꾸준히 하였다.그 결과 이전 면접과는 다르게 좀 더 자신감을 갖고 면접에 임할 수 있었다!이런곳에서 일하면 어떤 기분일까그렇게 도착한 구로의 등대 G 타워! 정말 높았다..적당히 둘러보다가 지타워 3층의 ㅋㅋ다방 면접 대기장소에서 인사팀분들의 안내를 받아 면접을 기다리게 되었다 (인사팀분들이 정말 친절하셔서 너무 좋았다!).면접은 3:1로 진행되었다.나 같은 경우 생각했던 것보다 기술 질문이 적어서 조금 당황했다.다 기억나진 않지만 게임에 대한 애정, 지식, 경험을 묻는 질문들과 자소서를 기반으로 한 커뮤니케이션 능력과 프로젝트 경험에 대한 질문들이 주를 이루었던 것 같다.처음에 진짜 긴장을 많이 했는데 인사팀 면접관님께서 대화를 통해 긴장을 많이 풀어주셨고 덕분에 나의 생각을 좀 더 잘 전달할 수 있었다. 그렇게 1차 면접도 마치게 되었다.이번에도 지원자들을 위한 선물이 있었다!필통을 포함한 굿즈 몇 가지와 ㅋㅋ다방 이용권을 받았다.여기서 젤 비싼걸로다가뭘 마실지 고민하다가 바나나 두유(?)를 마시면서 마음을 가라앉히고 집으로 돌아왔다.그리고 받아온 굿즈들! 귀엽다..이것저것 뭐가 많다ㅎ..면접 결과는 정말 감이 안 왔다..별의별 걱정을 다 하면서 한 주를 보내게 되었으나 다행히 합격 소식을 전달받았다ㅋ.이때부터 와 나 진짜 넷마블 가나? 생각이 들었다.하지만 2차 면접 준비는 순탄치 못했다.괜히 집중도 잘 안되었고 뭘 준비해야 할지 몰랐다.그래서 따로 전략을 짜거나 무언가 필살기(?)를 준비해 가지 않았고 나 자신에 대한 생각 정리를 주로 했다.나는 왜 개발자가 되기로 하였는지, 나의 꿈은 무엇인지, 나는 어떤 개발자, 사람이 되고 싶은지.. 와 같은 물음에 대한 내 생각을 정리하였고 2차 면접날을 기다리게 되었다.2차 임원면접, 그리고 최종합격그렇게 다가온 2차 면접.2차 면접을 본 주는 정말 바빴다.월, 화, 수요일에 아침마다 배드민턴 보강수업이 있었고 화요일엔 전공시험까지.. 또 면접 전날인 수요일엔 타 회사 면접도 잡혀있어 정신이 하나도 없었다..2차 면접에서는 임원진 세 분과 대화를 나누게 되었다.1차 면접에서도 그랬지만 면접관님들의 표정을 읽는 게 진짜 어렵다.무슨 생각을 하고 계신지 감도 오지 않았다. “내가 지금 뭔가 잘못하고 있나?” 라는 생각이 들 뻔도 했지만 자신감을 잃지 않고 처음 페이스대로 유지하며 답변을 이어나갔다.준비되지 않은 인성 질문이 꽤 들어왔다고 생각하는데 면접 이전에 나에 대한 생각 정리를 했던 것이 꽤 많은 도움이 되었다.그렇게 12월 15일. 10월 6일부터 해서 거의 두 달간의 채용 과정의 마무리를 찍게 되었다.나의 막학기는 넷마블 채용 프로세스와 함께였다..2차 면접까지 마무리 짓고 이제 내가 할 수 있는 건 기다리는 것뿐이었다.그리고 12월 20일.. 종강을 하고 친구들과 점심을 먹고 있는데 핸드폰에서 진동이 울렸다..넷마블 최종 결과가 담긴 메일이었다.쿵쾅쿵쾅 뛰는 심장을 부여잡고 메일을 열어보았다.해냈다 해냈어 버거가 해냈어어!!짧은 외침과 함께 얼어붙은 몸. 그리고 흐르는 눈물 한 방울 ㅋㅋㅋㅋ큐ㅠㅠㅠ기간도 길었고 중간중간 기다림도 많았기에 더 감격스러웠던 것 같다..마치며이번 넷마블 공채를 진행하면서 넷마블 공채에 대한 후기글이 적어 정보를 얻기가 힘들다고 느꼈습니다.그래서 꼭 채용 프로세스를 마치게 되면 후기글을 써야겠다고 마음먹게 되었구요 최종 합격까지 하게 되어 더 기쁜 마음으로 후기를 남길 수 있게 되었습니다..2023년 그리고 그 이후의 공채에 지원하는 분들에게 조금이라도 도움이 되었으면 좋겠네요!저는 이번 넷마블 공채 합격으로 취준을 끝낼 수 있게 되었습니다.막상 합격을 하게 되니까 취준이 끝났다!라는 생각보단 아 이제 진짜 시작이구나라는 기분이네요..1월 2일부터 출근을 하게 되었는데 걱정 반 기대 반인 심정입니다 하핳..끝으로 이 글을 보고 계신 취준생 분들, 보고 계시지 않은 취준생 분들까지도 화이팅하셨으면 좋겠습니다.불합격 소식을 받을 때마다 한 가지 포인트씩 고쳐나가며 성장할 수 있다고 생각합니다.수많은 불합격들이 거름이 되어 합격이라는 꽃을 피웁니다. 짧다면 짧았지만 취준이 심적으로 얼마나 힘들지 알기에 모든 취준생분들의 합격을 기원하고 응원합니다!!" }, { "title": "내가 되고 싶은 개발자", "url": "/posts/MeAsDeveloper/", "categories": "Diary", "tags": "diary, agonize", "date": "2022-12-11 16:48:00 +0900", "snippet": "개발자가 되기로 한 이유내가 개발자가 되기로 한 이유는 게임을 만들기 위해서였다.고등학교 때 게임을 만드는 사람이 되고 싶다는 생각이 들었고 제대로 돌아가지도 않는 컴퓨터로 유니티 공굴리기 튜토리얼을 돌려보면서 프로그래밍의 존재를 알게 되었다. 그래서 혼자 윤성열의 열혈 C 프로그래밍 책을 사 읽어보곤 했었다.그렇게 나의 꿈은 인디게임 개발자가 되었고 언젠가 나와 마음 맞는 사람들을 모아 인디게임 팀을 꾸리는 것이 목표가 되었다.그런데 스무 살 이후 대학생활을 보내면서 게임회사 말고도 서비스 회사에서 기여를 하고 싶다는 생각도 들었다.게임이 사람들의 삶에 재미를 선사해 준다면 다양한 서비스들은 사람들의 삶의 질을 올려주었다. 또한 스타트업에서 좀 더 빠릿빠릿하고 탄력적으로 목표를 이루는 문화가 나에게 더 잘 맞을 것이라는 생각도 들었다.그래서 나는 게임회사, B2C 스타트업에 취업하자고 마음먹었고 이런 회사들에서 원하는 뛰어난 개발자가 되기 위해 노력하였다.뛰어난 개발자뛰어난 개발자라는 말은 누가 정의하느냐에 따라 다양하게 해석될 수 있다고 생각한다. 어떤 누구는 슈퍼컴퓨터급의 두뇌를 가진 개발자를 뛰어난 개발자라고 생각하는 반면 기술적 능력은 떨어지더라도 팀을 잘 이끄는 리더십이 뛰어난 사람을 뛰어난 개발자를, 또 누군가는 에러를 빠르고 완벽하게 고치는 개발자를 뛰어난 개발자라고 주장할 수 있다. 난 이런 의견들이 모두 정답이라고 생각한다.게임의 보스(마주한 문제 혹은 공동의 목표)를 잡기 위해 누군가는 딜러 캐릭터를 키울 수 있고 누군가는 탱커, 서포터를 키울 수 있듯이 각자의 가치관과 성향에 따라 정의가 달라질 수 있는 질문이라고 생각한다.그럼 내가 생각하는 뛰어난 개발자는 무엇이냐.. 하면 개인적으로도 뛰어나지만 팀으로 일할 때 팀 전체의 퍼포먼스를 끌어올려 주는 개발자이다. 이게 참 재밌는게 이런 성향이 내가 여태 해온 게임에서 나타난 성향과 비슷하다. 나는 게임에서 한마디로 피지컬 뛰어난 서포터를 지향한다 ㅋㅋ. 롤에서도 시즌 3 다이아(서포터로 올린거 아님)로 출중한 실력을 가졌지만 서포터 라인을 제일 선호하는 유저이다. 로아와 같은 롤플레잉 게임에서도 마찬가지다.내가 이러한 가치관(?)과 성향을 가졌기 때문에 이런 개발자를 뛰어난 개발자라고 생각하게 되었나 보다. 그럼 내가 말한 뛰어난 개발자, 피지컬 좋은 서포터 같은 개발자는 정확히 어떤 개발자일까? 현실 세계에서 예를 들자면 아래와 같지 않을까 생각한다. 문제가 막혔을 때 편하게 먼저 문제에 대한 고민을 나눌 수 있으며 대화와 토론을 통해 유의미한 해결책이나 개선안을 도출해낼 수 있게 해주는 동료 동료로서 한 팀에서 일할 때 &quot;아 이 사람과 같이 한 팀에서 일을 하게 되면 이 사람과 함께 성장할 수 있을 것 같아!&quot; 라는 생각이 드는 성장에 대한 자극과 동기부여를 주는 동료 개발 외적으로도 주변에 긍정적인 에너지를 주어 뭔가 내 업무도 더 잘 되는 느낌 (invisible something? ㅋㅋㅋ)을 주는 동료 등등,,나는 이런 개발자는 기술적으로 뛰어난 역량을 보유한 동시에 좋은 사람이어야 한다고 생각한다. 서포터는 팀원들에게 버프를 넣어주고 팀원으로 하여금 평소보다 더 뛰어난 퍼포먼스를 보여줄 수 있게 해주지 않는가?현실 세계에서 이런 역할을 하려면 먼저 좋은 사람이 되어야 가능할 것이다.그렇다면 현재의 나는 어떤 사람/개발자인가?나는 지금 한낱 취업을 기다리는 개발자이다…. 본격적으로 서류도 넣어보면서 취준을 시작한 지 반년도 안되었지만 나의 가치를 증명하거나 실현하는 것이 아닌 취업이라는 것에 내 에너지를 쏟아야 한다는 게 힘들다.. 그래도 반년 동안 열심히 노력을 한 결과 취업이라는 문턱이 멀지 않았다고 느껴지긴 하는데… (취업하기 전까진 모르는 거니까..)이번 분기에는 내가 가서 붙었을 때 일하고 싶은 회사에만 지원을 했고 코딩 테스트 승률은 40% 정도 ㅠㅠ.. 대신 과제 전형의 경우에는 과거에 붙었던 인턴과 합치면 2전 2승, 100%라는 승률을 가지고 있긴 하다 ㅋㅋ. 서류 같은 경우는 이력서를 만든 이후로는 통과가 꽤 되는 것 같고 면접 같은 경우엔 처음엔 진짜 준비도 안 해가고 경험도 없어서 머릿속이 새하얘져서 대답도 제대로 못했다면 막바지쯤에 나에 대한 생각 정리도 좀 하고 면접 왕 이형님 영상도 챙겨봤더니 최근 본 머기업 1차 면접을 통과할 만큼 사람 구실을 하게 되었다. (다음 주에 볼 최종 면접 붙게 해주세요..)아무튼.. 아직 취준생이기 때문에 내가 지금 어떤 개발자다! 라고 딱 단정 짓기 좀 어렵다.그래도 한 가지 확실한 것은 이번 분기 취업 준비를 하면서 기본기도 더 탄탄해지고 여러 면에서 성장했다는 것이다. 그래서 나는 내가 올해 안에는 취업을 못할 수 있겠지만 내년 상반기에는 무조건 취업을 할 것이라고 확신한다.그렇다면 한 명의 사람으로서의 나는 어떤 사람인가에 대해서는 내가 뭐라 적지는 못하겠다. 나는 내가 괜찮은 사람이라고 생각하지만 누가 보느냐에 따라 다 다를 테니..중요한 건 꺾이지 않는 마음 내가 되고싶은 사람이 어떤 사람이고 그런 사람이 되기 위해 노력하는가라고 생각한다.마무리적은 내용 외에도 고민거리라던가,, 앞으로의 계획 등 더 적어보고 싶었지만 위 내용만 작성하는 데에도 3일이 걸렸다.이 글에 적어내지 못한 내용은 연말에 회고록과 함께 남겨볼 예정이다.어찌 되었든 나는 지금 취준생이고 지금으로선 취업이 제1 목표이다. 어서 빨리 내가 원하는 회사 중 한곳에 들어가 커리어를 시작하고 싶다.. 또 내년엔 올해보다 신입 취업시장이 더 어렵다던데 여러모로 걱정이다.. 빨리 미국이 금리도 낮춰주고 전쟁도 끝나 다시 세계경제가 활력을 띠었으면 하는 바람이다..이제 올해 나에게 남은 기회는 3번이다.그중 두 곳은 최종 면접.. 개인적으로는 이번 학기 초에는 서류, 코테에서 떨어져 면접까지 갈 기회가 별로 없었는데 탈락들을 거름 삼아 성장하고 있다고 느껴진다.남은 기회들에서는 긴장하지 않고 회사에 내가 어떤 사람인지 잘 전달했으면 좋겠다.이번 글은 이쯤에서 마무리를 짓겠다. 이제 다음 주에 있을 면접들과 학교 기말고사 (하필 겹치냐,,) 준비를 하러…다음 글은 2022년 회고록으로 돌아오겠다.블로그를 시작한 이후로 첫 회고록 작성인데 어떤 내용을 쓰면 좋을지 고민이다.끝으로 나를 포함한 전국 취준생들 화이팅,,, 중요한 건 무수한 불합격 메일에도 꺾이지 않는 마음.." }, { "title": "Clustered Index vs Non-Clustered Indexes", "url": "/posts/Clustered_Index/", "categories": "Development, DataBase", "tags": "index", "date": "2022-11-16 19:50:00 +0900", "snippet": "Index?클러스터드/넌클러스터드 인덱스가 뭔지 알아보기 전에 인덱스에 대해 간단히 정리하고 가보자.인덱스는 데이터베이스에서 내가 원하는 값을 가진 데이터를 빠르게 찾게 해주는 자료구조이다.보통 검색을 위해 사용하는 알고리즘에는 대표적으로 이진 탐색, 해시 탐색 등이 있는데 데이터베이스의 특성상 딱 원하는 값을 찾는 where age = 25와 같은 구문뿐만 아니라 where age &amp;gt; 25등의 범위를 조건으로 달아주는 구문도 자주 요청되기 때문에 해시 알고리즘을 적용하기에는 한계가 있어 대부분의 인덱스는 트리를 활용한 탐색을 사용하며 B-Tree (Balanced Tree) 자료구조를 사용한다.그럼 인덱스는 탐색을 빠르게 해주니까 모든 열에 인덱스를 걸어주면 되는거 아닌가요?라고 생각하기 쉽지만 그렇지 않다.__인덱스는 SELECT의 성능을 올려주는 반면에 UPDATE, INSERT, DELETE 요청이 들어오면 부하가 발생하게 된다.인덱스를 씌운 열에 새로운 데이터가 들어오거나 값이 바뀌게 되면 저장된 데이터의 배열을 다시 바꾸어 주어야 하기 때문이다.그렇기 때문에 인덱스는 마구잡이로 생성해 주면 안 된다.그러면 어떤 열에 인덱스를 생성해 주어야 하나요?위에서 언급한 것처럼 인덱스는 SELECT와 UPDATE, DELETE, INSERT 성능의 등가교환이기 때문에 신중히 달아주어야 하는데 이 고민 해결에 도움이 될 몇 가지 좋은 기준들이 있다. 카디널리티(Cardinality)가 높은 컬럼에 달아주어라 카디널리티란 데이터의 유니크한 정도를 의미한다. 카디널리티가 높다는 것은 컬럼이 갖는 값의 중복도가 낮다는 의미이고 이는 낮은 선택도로 연결되어 인덱스를 생성하기에 적합한 조건을 갖추게 된다. 조회 활용도가 높은 컬럼에 달아주어라 WHERE속의 조건으로 많이 활용되는지!인덱스를 달아주어도 WHERE절에서 쓰이지 않으면 인덱스를 활용하여 탐색을 하지 않는다. 삽입, 변경, 삭제가 자주 발생하지 않는 컬럼에 달아주어라 인덱스는 삽입, 변경, 삭제가 발생할 때 성능이 떨어지기 때문에 이 작업이 잘 이루어지지 않는 컬럼에 걸어주어야 한다. 내 생각으로는 삽입이 없는 데이터베이스는 상상하기 힘들다.삽입이 불가피하다면 닉네임이나 직업과 같은 컬럼보다는 이름, 주민번호와 같이 불변성이 더 높은 컬럼을 우선적으로 고려해 보면 되겠다. Clustered IndexCluster?Cluster는 무리, 무리를 이루다와 같은 사전적 의미를 갖고 있습니다.그렇기 때문에 실제 데이터와 인덱스가 하나의 무리를 이룬다, 즉 실제 데이터가 저장된 공간을 정렬하여 인덱스를 만드는 것이 클러스터드 인덱스이고 실제 데이터와 무리를 이루지 않는, 실제 데이터와 무관하게 인덱스를 생성하는 것을 넌클러스터드 인덱스라고 보면 됩니다. 이러한 차이 때문에 클러스터드 인덱스와 넌클러스터드 인덱스 사이에 장단점과 차이점이 발생하게 됩니다.먼저 클러스터드 인덱스는 테이블에서 데이터가 물리적으로 저장된 공간의 순서를 결정짓습니다. 어떤 열로 정렬을 하냐에 따라 데이터들의 배열이 달라지기 때문에 한 테이블에는 하나의 컬럼에 대한 클러스터드 인덱스를 만들 수 있습니다.SQL 서버에서는 테이블을 생성할 때 프라이머리키를 설정해 주면 자동적으로 해당 열에 대한 클러스터 인덱스를 생성합니다.만약 기존 테이블에 클러스터 인덱스가 존재하지 않는 경우 하나의 컬럼에 unique + not null을 설정해 주면 해당 열에 대한 클러스터 인덱스를 생성합니다. 또한 하나의 열에 대해 클러스터 인덱스를 생성하는 명령을 통해서도 생성이 가능합니다.Non-Clustered Indexes반대로 넌클러스터드 인덱스는 실제 테이블에서 데이터가 저장되는 공간에 관여를 하지 않습니다. 대신에 추가적인 공간을 생성하여 넌클러스터드 인덱스와 테이블의 데이터를 저장합니다.이러한 점 때문에 클러스터 인덱스와는 달리 한 테이블에 여러 개의 넌클러스터드 인덱스를 생성할 수 있는 것이죠.클러스터드 인덱스와는 달리 리프 노드(리프 테이블)에 데이터 자체가 아닌 해당 데이터의 주소값을 저장합니다. 그렇기 때문에 넌클러스터드 인덱스는 주소값을 구한 후 한 번의 방문 과정을 더 거쳐야 하므로 클러스터드 인덱스보다 SELECT 성능이 살짝 느립니다.대신 수정, 삭제, 삽입 시 클러스터드 인덱스는 실제 데이터 공간을 활용하므로 B-Tree의 높이 값을 유지하기 위한 작업이 수행되어 더 불리하다고 할 수 있죠.넌클러스터드 인덱스도 클러스터드 인덱스와 마찬가지로 CREATE NONCLUSTERED INDEX 키워드를 사용하여 생성할 수 있으며 unique 키워드가 붙으면 자동으로 생성됩니다.결론 하나의 테이블에는 하나의 클러스터드 인덱스만 만들 수 있다.반대로 넌클러스터드 인덱스는 여러 개 만들 수 있음! 클러스터드 인덱스는 실제 데이터가 존재하는 테이블을 정렬하는 것만으로 동작하기 때문에 추가적인 메모리 공간을 필요로 하지 않는다.반대로 넌클러스터드 인덱스들은 추가적인 공간이 필요! SELECT 문의 성능은 클러스터드 인덱스가 조금 더 빠르다!추가적인 방문 단계 없이 데이터를 찾기 때문!정도로 정리할 수 있겠다…개인적인 이해로는1. 조회 성능을 높이기 위해 인덱스를 도입해야지! =&amp;gt; 여러 개의 인덱스(현재 넌클러스터드 인덱스라고 불리는)를 만듦2. 어? 근데 이거 실제 데이터 공간에 접근해서 정렬해 주면 기존 인덱스 방법보다 조회도 조금 더 빠르고 메모리도 아낄 수 있겠는데? 대신 하나밖에 못 만들어!3. 그럼 가장 효율이 좋을 것 같은 열을 해당 인덱스로 만들자!4. 만들고 보니 두 가지의 인덱스가 생겼네? 그럼 우리 이거 이름을 클러스터드 / 넌클러스터드 인덱스라고 하자!와 같은 흐름으로 이해를 하고 있다. 처음부터 클러스터드/넌클러스터드 딱 딱 나눠져서 생겼다기보단 이런 식의 과정 속에서 두 단어가 생기지 않았을까.. 하는 내 생각이다 ㅇㅇ…아무튼 오늘 클러스터드 인덱스와 넌클러스터드 인덱스가 무엇이며 어떤 점이 다른지에 대해 알아보았다. 이렇게 정리하고 나니 기억에 오래 남을 것 같다..전에는 아무 생각 없이 인덱스 쓰면 빨라져요!라는 말만 듣고 뭔지도 모른 채 그냥 집어넣었는데 뭔지 알고 나니까 어떻게 더 효율적으로 사용할 수 있을지, 어떤 점을 조심해야 하는지 한 번 더 생각하고 사용할 수 있을 것 같다.Reference 10분 테코톡, 찰리의 인덱싱 What is the difference between Clustered and Non-Clustered Indexes in SQL Server?" }, { "title": "[번역/요약] 협업을 위한 REST API Best Practices", "url": "/posts/Rest_for_Noobies/", "categories": "Development, Network", "tags": "cowork, restful, rest api", "date": "2022-11-03 15:55:00 +0900", "snippet": " 먼저 이 글은 REST API Best Practices – REST Endpoint Design Examples by Kolade Chris 아티클을 번역 및 요약한 것을 알립니다.이전 진행했던 팀 프로젝트에서 팀원들에게 도움이 되고자 노션에 번역, 요약해놨던 글을 거의 그대로 옮겨왔습니다.협업이 처음인데 RESTFUL함이 확실히 뭔지 모르겠다 하시는 분들이라면 아래의 규칙들만 잘 지켜도 꽤 괜찮은 API 설계를 할 수 있을 것이라고 생각합니다..!1. 데이터를 주고받을 때 Json을 사용하라!2. API의 엔드포인트는 되도록 명사로, 동사 x!REST API 는 요청에 이미 GET, POST, PUT, PATCH, DELETE 동사가 들어가 있기 때문에 요청하는 엔드포인트에 COPY, PURGE, LINK 와 같은 동사는 넣지 말자. 👍: POST &quot;/user&quot; 👎: POST &quot;/createUser&quot;3. 명사를 복수형으로 설계하라!API의 엔드포인트가 https:/mysite.com/post/123 일때 DELETE, PUT, PATCH 메소드로 요청을 할때는 별 문제가 없다.하지만 GET 메소드로 호출했을 때 결과가 하나 이상일 수 있기 때문에 api 엔드포인트를 설계할 때 복수형 명사를 사용하여야 한다. 👍: GET “/users/123” 👎: GET &quot;/user/123&quot;4. 에러를 핸들링 할때는 항상 Status Code를 사용하라!사용자가 자신의 요청이 성공했는지, 실패했는지, 실패했다면 왜 실패했는지를 쉽게 알게 하기 위해 이미 정규화된 상태코드를 사용하자.[상태코드는 아래 링크에서 확인]HTTP 상태 코드 - HTTP | MDN5. 관계를 나타내기 위해 엔드포인트에 nesting을 사용하라!때로는 서로 다른 엔드포인트가 연관된 작업을 수행하는데 그럴 때는 엔드포인트를 nesting(둥지틀기?)를 해주자. 특정 글쓴이의 글을 불러올때 👍: GET &quot;/post/{author}&quot; 👎: GET &quot;/postAuthor?author={author}&quot; 특정 글의 댓글목록을 불러올때 👍: GET &quot;/post/{post_id}/comments&quot; 👎: GET &quot;/comments/postid&quot; 단, 가독성과 멋을 해치지 않기위해 3번 초과의 nesting은 지양하자 !6. 데이터를 요청할때에는 필터링, 정렬, 페이징을 사용하라!DB서버의 과부화를 막기위해 필요한 데이터만 요청할 수 있도록 filtering, sorting, pagination을 활용하자. 성별이 남자인 유저의 목록만 불러오고 싶을때 👍: GET &quot;/users?gender=male&quot; 👎: GET &quot;/maleUser&quot; 7. 보안을 위해 SSL을 사용하라!SSL을 사용하여 악의적인 해킹으로부터 덜 취약한 API를 만들자. 👍: https://mysite.com 👎: http://mysite.com8. 버전관리를 하라!너의 API에 새로운 업데이트 사항이 있다면, 그 업데이트로 이전 API를 전처럼 사용하지 못한다면 api를 수정하지말고 새로운 버전을 파야한다.그렇지 않으면 이전 api를 사용하던 어플리케이션이 제대로 작동하지 않게된다.대부분의 대기업, 개인들은 아래와 같은 방법으로 버전을 나눈다. https://mysite.com/v1/user: version 1 https://mysite.com/v2/user: version 29. 정확한 API문서를 제공하라!REST API를 만들때 너는 사용자가 API를 제대로 사용하도록 도와야한다.그 방법중 가장 좋은 방법은 좋은 API 문서를 작성하는 것이다. 문서에 반드시 포함되어야 할 것 적절한 API의 엔드포인트 엔드포인트의 요청 예시 여러개의 프로그래밍 언어로 구현하는 방법 상태코드와 함께 나열된 여러개의 메시지 목록들 API 문서작성에 가장 많이 쓰이는 것은 Swagger 이며 PostMan 도 많이쓴다." }, { "title": "[Go] sql.Open()은 정말로 디비와의 커넥션을 만들까?", "url": "/posts/sql_Open/", "categories": "Development, Go", "tags": "golang, sql, open", "date": "2022-10-30 14:26:00 +0900", "snippet": "고 언어로 짜여진 서버사이드 코드를 보면 아래와 같은 코드를 빈번히 볼 수 있다.func main() { ... conn, err := sql.Open(config.DBDriver, config.DBSource) if err != nil { log.Fatal(&quot;fail to connect db: &quot;, err) } ...}위 코드만 봤을 때 우리는 아! 이 부분에서 에러가 발생하면 디비와의 연결이 되어있지 않은 상태인 거구나! 라고 생각하기 쉽다.하지만!! db.Open()에서 반환되는 에러는 디비와의 커넥션과는 무관하다!!문서를 읽어보면 아래처럼 설명한다.Open may just validate its arguments without creating a connection to the database. ...Open()메서드는 인자 값들의 유효성만 검증해 줄 뿐 실제 디비와 커넥션을 이루어주지는 않는다.그렇다면 디비와의 연결이 보장되었다는 걸 알고 싶으면 어떻게 해야 할까?사실 위문장 뒤에 한 문장이 더 숨겨져있다.Open may just validate its arguments without creating a connection to the database. To verify that the data source name is valid, call Ping.실제 디비와의 커넥션이 잘 이루어져 있는지 확인하려면 Ping()메서드를 사용해야 하나보다.그래서 기존의 코드를 알맞은 의도와 방법으로 수정하면 아래와 같이 수정할 수 있겠다.func main() { ... conn, err := sql.Open(config.DBDriver, config.DBSource) if err != nil { log.Fatal(&quot;invalid db: &quot;, err) } defer conn.Close() if err := conn.Ping(); err != nil { log.Fatal(&quot;cannot connect to db: &quot;, err) } ...}" }, { "title": "백준 6064 카잉달력, 이 문제를 풀지 못한 사람들을 위한 풀이", "url": "/posts/BOJ6064/", "categories": "Development, Algorithm", "tags": "boj, math", "date": "2022-10-01 01:45:00 +0900", "snippet": "이 글을 쓰게된 이유처음에는 완전 탐색으로 풀었다가 시간 초과가 나서..조금 더 고민해 보다가 답이 나오지 않아 검색을 해서 답을 찾아봤는데..이해가 가는 블로그 글이 하나도 없다.. 적어도 나같은 바보들도 이해갈 수 있게 설명을 써놓은 블로그는 없었다…그 뭐야.. 한 블로그에서는 풀이에 왼쪽에 주어진 연도를 M으로 나누었을 때 x이어야 하기 때문에.. 라고 적혀있는데 그걸 아는 사람들은 문제 이미 정답을 제출하고 구글에 이 문제를 검색해서 풀이를 보러 들어오지 않았을 것이다.그래서 나는 문제를 풀지 못한 사람들도 이해할 수 있는 풀이를 남기려고 해본다.. 나 같은 경우엔 이미 답을 아는 상태에서 풀이를 해석해 보았다.풀이 시작M, N, x, y가 입력으로 들어온다.여기서 x는 x + i*M번째마다 등장하고 y는 y+j*N번째마다 등장한다. 이 부분은 다들 이해가 갈 거라 생각한다.그리고 종말의 날은 M, N의 최소공배수이다.이건 또 왜냐? 종말의 날은 x=M, y=N인 경우이기 때문에 x = M + i*M번째마다, y = N + j*N번째마다 등장.즉, x = (1+i)*M y = (1+j)*N 번째마다 등장하기 때문에 두 값이 같을 때는 M과 N의 최소공배수이기 때문이다.예시)M = 10, N = 12x = 10, y = 12 일 때x가 10인 날은 =&amp;gt; 10, 20, 30, 40, 50, 60, ...y가 12인 날은 =&amp;gt; 12, 24, 36, 48, 60, ...이므로 종말년도는 두 값의 최소공배수이다.=&amp;gt; &quot;아 뭔가 루프를 돌 때 종말년도인 M, N의 최소공배수는 넘지 말아야겠구나!&quot;자 그러면 이제 답을 구해보자.M, N, x, y가 입력으로 들어왔고 우리는 &amp;lt;x:y&amp;gt;가 몇번째 날인지 알고 싶다.위에서 말했듯이 X = x + i*M, Y = y + j*N번째 날에 등장하고 우리가 원하는 것은 두 숫자가 동시에 등장하는 날 즉, X == Y가 되는 날이다.따라서 x + i*M = y + j*N이 되고 이 식에서 y를 이항해주면x + i*M - y = j * N위 식을 유도해낼 수 있다.그렇다 위 식이 바로 답이다.우리는 x에 M을 계속 더해준 값에 y를 뺀 값이 N의 배수인 가장 작은 수를 구해주면 되는 것이다.이를 코드로 나타내면 아래와 같다.doomsDay = lcm(M, N) # 종말의 날 = M, N의 최소공배수answer = -1while x &amp;lt;= doomsDay: # (x + i*M - y)의 값이 N으로 나누어지는 경우 그 날이 답이며 루프 탈출 if (x - y) % N == 0: answer = x break x += M # 루프를 한번 돌 때마다 x에 M을 더해줌if answer == -1: # 루프를 다 돌았는데 답을 구하지 못한경우 = 종말의 날까지 존재하지 않는 날. print(-1)else: print(answer)정답 코드def gcd(x, y): while(y): x, y = y, x%y return xdef lcm(x, y): result = (x*y)//gcd(x, y) return resultn = int(input())for _ in range(n): M, N, x, y = map(int, sys.stdin.readline().split()) answer = -1 doomsDay = lcm(M, N) while x &amp;lt;= doomsDay: if (x - y) % N == 0: answer = x break x += M if answer == -1: print(-1) else: print(answer)" }, { "title": "[Docker] Docker 기본 명령어들과 짧은 팁", "url": "/posts/StartDocker/", "categories": "Development, DevOps", "tags": "docker", "date": "2022-09-12 19:00:00 +0900", "snippet": "Container 현재 실행중인 컨테이너 리스트 목록 출력하기 docker ps 중지된 컨테이너 리스트까지 출력하기 docker ps -a 중지된 컨테이너를 시작하기 docker start &amp;lt;container&amp;gt; 실행중인 컨테이너를 중지하기 docker stop &amp;lt;container&amp;gt; Detach 모드로 컨테이너 실행하기 docker run -d &amp;lt;image&amp;gt; 컨테이너의 로그 기록 출력하기 docker logs &amp;lt;container&amp;gt; 로그 기록 출력 + 연결하기 docker logs -f &amp;lt;container&amp;gt; Attach 모드로 중지되었던 컨테이너 실행시키기 docker start -a &amp;lt;container&amp;gt; Detach 모드의 컨테이너에 연결하기 docker attach &amp;lt;container&amp;gt; 중지 상태의 컨테이너 삭제하기 docker rm &amp;lt;container&amp;gt; 중지 상태의 모든 컨테이너 삭제하기 docker container prune 컨테이너가 중지될 때 자동으로 컨테이너 제거하도록 예약 걸어놓기 docker run --rm &amp;lt;image&amp;gt; 컨테이너와 파일 교환하기 # 컨테이너 -&amp;gt; 로컬docker cp &amp;lt;container&amp;gt;:/container_folder local_folder# 로컬 -&amp;gt; 컨테이너docker cp test/text.txt &amp;lt;container&amp;gt;:/c_folder 컨테이너 실행 시 이름 부여하기 docker run --name j1mmyContainer &amp;lt;image&amp;gt; Image 이미지 삭제이미지를 삭제할 때에는 해당 이미지를 사용중인 컨테이너(실행 혹은 중지상태의)가 없어야 한다. docker rmi &amp;lt;image 사용중이지 않은 이미지들 제거 docker image prune 이미지 생성 시 태그 생성하기 docker build -t name:latest . 이미지를 다른 이름/태그로 복제하기 docker tag &amp;lt;old_image&amp;gt; &amp;lt;new_image&amp;gt; DockerHub에 내 이미지 푸시하기 # 1. 도커허브에서 새 레포 생성# 2. 생성한 레포와 같은 이름의 이미지 생성# 3. 푸시 명령어로 이미지를 도커허브에 푸시docker push user_name/image_name:tag DockerHub에서 이미지 가져오기 docker pull user_name/image_name:tag 이런 저런 팁1. Container id 값 복사 붙여넣기는 이제 그만&amp;lt;container_id&amp;gt; 를 포함하는 명령어를 실행할 때 id값 전체를 입력할 필요없이 앞에 unique한 몇글자만 입력해도 실행이 된다.예를 들어 내가 실행시키려는 컨테이너의 id값이 abc123 이고 abc 로 시작하는 id값을 가진 컨테이너가 abc123 으로 유일한 경우 docker start abc 까지만 입력해도 도커는 abc 를 abc123 으로 인식하여 작업을 수행한다.2. 레이어를 이해하고 더 효율적으로 이미지 빌드하기아래 두개의 도커파일이 있다.Dockerfile_1FROM node:14WORKDIR /appCOPY . .RUN npm installEXPOSE 3000CMD [&quot;node&quot;, &quot;app.js&quot;]Dockerfile_2FROM node:14WORKDIR /appCOPY package.json .RUN npm installCOPY . .EXPOSE 3000CMD [&quot;node&quot;, &quot;app.js&quot;]두 도커파일 모두 같은 이미지를 생성해 주지만 이미지를 만들 때 걸리는 시간에는 차이가 있다. 이유가 뭘까?도커파일의 경우 한 줄 한 줄을 실행할 때마다 레이어를 쌓게되고 이전에 실행했던 작업과 결과가 같으면 캐싱을 사용하게된다.Dockerfile_1 을 보면 로컬의 모든 파일을 가져온 뒤 RUN npm install 명령을 시행하게 된다. RUN npm install 명령은 로컬의 package.json 파일을 보고 필요한 패키지들을 내려받는 명령인데 package.json 파일이 변하지 않는다면 항상 같은 작업을 수행하기 때문에 캐싱을 사용하여 작업이 진행된다.하지만 1번 도커파일의 경우 package.json 파일이 수정되지 않더라도 캐싱을 사용할 수 없는 경우가 발생한다.예를 들어 app.js 파일이 수정되었다고 했을 때, COPY . . 명령어에서 app.js 파일의 변화를 감지하여 캐싱을 사용하지 못하게 되고 이로 인해 그 이후의 모든 작업에서 캐싱을 사용할 수 없게 되기 때문이다.반면 Dockerfile_2 을 보면 COPY . . 명령 이전에 COPY package.json 명령을 실행해 준 후 RUN npm install 명령을 실행하기 때문에 다른 파일들이 바뀌었더라도 package.json 파일이 변하지 않았다면 새롭게 npm install 명령을 수행하지 않는다.이렇게 도커의 이미지가 레이어 형태로 쌓인다는 것을 이해하고 오래 걸리는 작업들의 명령 순서를 잘 조정하면 더 적은 시간으로 이미지를 빌드 할 수 있다." }, { "title": "떨어진 네이버 트랙인턴 면접 복기하기 (Search CIC)", "url": "/posts/naverInterview/", "categories": "Diary", "tags": "Naver, Interview, Search CIC, Intern", "date": "2022-07-30 14:36:00 +0900", "snippet": "트랙인턴쉽 Search CIC내가 지원한 부서는 Search CIC의 Next Engine&amp;amp;Solution 팀의 백엔드 개발자 직군이었다.네이버엔 굉장히 많은 부서와 팀이 있는데 나는 나의 기술 스택과 맞는 팀, 그중에서 해결하는 문제가 흥미로운 팀을 골랐고 최종적으로 Next Engine&amp;amp;Solution 팀에 지원을 하게 되었다.평소에 클라우드 분야로 커리어를 쌓아도 재밌겠다는 생각도 갖고 있었고 그 커리어를 쌓기에 좋은 시작이 될 수 있다고 생각했다.그렇게 나는 이 직군에 지원서를 넣었고 결과를 기다리고 있었다…헉바로 전에 봤던 skt 코테에서 모든 문제를 풀고도 떨어진 것도 그렇고 네이버의 경우 코테와 서류를 종합하여 합불을 가리게 되는데 나 같은 경우 서류가.. 상당히.. 빈약하다는 생각을 하고 있어서 큰 기대는 안 하면서 결과를 기다렸다.그런데.. 통과해버렸다..ㅋㅋㅋㅋ. 기대 안 하는척하면서 내심 기대를 하고 있긴 했지만 붙으니까 정말 기뻤다. 하지만 기쁨도 잠시 면접 경험이 전혀 없었기에 1차 면접을 어떻게 준비를 해야 하나.. 걱정하지 않을 수 없었다.면접 준비의 경우 우선 쩜튜브님의 영상을 보며 어떤 분위기에 어떤 느낌으로 진행되는지 보았고 1차 면접의 경우 기술면접이었기에 기본 CS 지식, 알고리즘, 자료구조 등등에 대해 공부를 했는데 규글님의 깃헙을 참고하여 공부해야 할 키워드들을 얻고 내가 확실하게 알지 못하는 부분의 경우 추가적인 검색이나 책을 보면서 공부를 하였다.그렇게 1차 면접날이 다가오고..월요일 ~ 금요일 중 하루를 골라서 면접을 진행할 수 있었는데 바로 전 주말 이틀간 해커톤 스태프를 가게 되어서 컨디션 조절을 위해 월요일은 거르고 화요일을 골라 면접을 보게 되었다. 이번 면접은 비대면으로 진행이 되었는데 대면 면접을 원했던지라 좀 아쉬웠다 ㅠ. 아무튼 면접날이 오게 되었고 생애 첫 면접을 보게 되었다.면접은 3:1로 진행되었다.기억이 자세히 나지는 않지만 부서의 리더님, 백엔드 리더님, 백엔드 팀원 한 분 이렇게 들어오셨던 것 같다. 면접의 분위기는 굉장히 좋았다 특히 존중받는 느낌을 받아 좋았던 것 같다. 처음엔 내가 긴장한 것을 아셨는지 편하게 아이스브레이킹을 해주셨고 자연스럽게 면접 질문으로 넘어갔다.면접은 내가 예상했던 것과는 다르게 흘러갔다.나는 기술 면접을 생각하며 열심히 cs 공부를 해왔는데 2차 면접에서 나올 거라 예상했던 질문들을 받게 되었다 ㅠㅠ.그래도 나의 경험이나 프로젝트에 관련한 질문을 해주어 정신을 차리고 대답을 해 나갔다.그럼에도 준비되지 않은 질문들에 답을 하면서 “내가 무슨 말을 하는거지?” 하는 포인트가 정말 많았다 ㅋㅋㅋㅋ.후반부에는 이런 상황의 문제가 생겼을 때 어떻게 해결을 하면 좋겠냐라는 질문을 받았다.나름 합리적인 방법으로 접근하여 문제 해결방법을 잘 제시를 했지만, 그 방법을 사용했을 때 어떤 데이터 타입을 쓰면 좋겠냐 라는 데이터 크기에 대한 질문을 받았고 여기서 그냥 비트 계산을 하여 가장 최적의 데이터 타입을 제시를 해야 하는데 순간 머릿속이 하얘지면서 비트 계산이 안됐다 ㅋㅋㅋㅋㅋ.내가 1~2분 정도 멍을 때려버리니 면접관님께서 괜찮다 넘어가자고 하셨고 이 부분이 내가 이번 면접에서 잘 대답할 수 있었는데 놓친 유일한 아쉬운 점이라고 생각한다 ㅠㅠ.어느 정도 수준의 계산을 못한 거냐면 int4 형에 담을 수 있는 정수형의 범위를 틀렸다 정도로 생각하면 된다 ㅋㅋㅋㅋ.면접관님께서 “아 이 친구는 기본이 안 되어있구나”라고 생각하셨을 게 틀림없다 ㅋㅋ큐ㅠㅠㅠ. 이 부분에서 좀 말려서 면접 막판에 자신감 없어 보이는 대답을 했는데 아마 이 두 부분이 면접 탈락의 큰 요인이 아니었을까 생각하고 있다.그렇게 생애 첫 면접을 마무리하게 되었다.결과는 예상했던대로불합격 메일을 받게 되었다. T^T그래도 이번 불합격을 통해 나 자신을 한번 돌아보게 되었고 어떤 점을 개선해야 할지 갈피를 잡을 수 있었다. 비록 떨어졌지만 자신감이 생기기도 하였고 면접 경험도 쌓게 되어 면접 탈락에서 많을 것을 챙겼다.그렇다면 문제점이 뭐였을까?기술에 대한 깊이와 기술 스택에 대한 근거의 부족면접뿐 아니라 서류를 작성할 때부터 느껴졌다.먼저 내가 갖고 있는 기술 스택들을 좀 더 깊게 공부해야겠다는 생각이 들었고, 다음으로는 내가 이 기술을 왜 선택을 하였는가?에 대한 답도 없었다. 지금까지는 그저 캐릭터가 귀여워서, 혹은 그냥 기술을 선택했었다.여러 언어나 프레임워크에는 각각의 장단점이 있는데 이런 점도 고려를 해서 합리적으로 기술을 선택해야겠다는 생각을 하게 되었다.깊이에 대한 부분에 대해 추한 변명을 하자면 ㅋㅋㅋㅋ 지난 1년간 GDSC라는 동아리에서 운영진으로 활동을 했었는데 동아리 활동에 시간을 많이 투자하다 보니 나 자신의 기술적 성장까지 달성하기 위한 노력이 부족했다고 생각한다. 그래도 후회는 하지 않는다 많은 경험을 하게 되었고 다양한 개발자들을 만나면서 시야도 넓혔다고 생각한다.아직 이런 동아리 활동을 안해봤다면 한번 쯤 꼭 해보는 걸 추천한다!지원한 직군의 기술에 대한 경험과 지식 부족이번에 클라우드 분야로 지원을 하였는데 클라우드에 대한 경험이 많은 편도 아니었고 지식도 많이 부족하다는 걸 깨달았고 그 부분이 면접에서 여실히 드러났다고 생각한다.내가 가고 싶은 분야에 대해 미리 경험도 해보고 공부도 미리 해놔서 해당 분야에 지원할 때 이번과 같은 문제점이 드러나지 않게 준비하는 시간도 필요하다는 걸 깨닫게 되었다.마치며이제 곧 4학년 2학기를 시작하게 된다.들어야 할 학점도 별로 안 남은 상태고 졸업작품도 마친 상태인데다가 동아리 활동도 마무리 짓게 되었다.그래서 당분간은 좀 더 기본기와 깊이 있는 학습에 전념할 생각이다.어느 정도 기본기가 튼튼해지고 만족할 만한 전문성을 가졌다고 생각되었을 때 본격적으로 시작할 것 같다.위 과정이 지루하고 눈에 잘 보이지 않더라도 나의 큰 무기가 되어줄 거라 믿는다.재밌는 활동은 지난 1년 동안 많이 했으니 ㅋㅋ아무튼 오늘 네이버 트랙 인턴에 대한 복기는 요 정도로 마치겠다.다시 한번 좋은 면접 경험을 선사해 주고 나의 부족한 부분을 알게 해준 네이버에게 감사하다는 말씀을 드립니다..!" }, { "title": "[알고리즘/짧] 구간 합 알고리즘, Prefix Sum", "url": "/posts/prefixSum/", "categories": "Development, Algorithm", "tags": "prefix sum, algorithm", "date": "2022-07-04 15:15:00 +0900", "snippet": "내가 구하고 싶은 것배열이 주어졌을 때 내가 원하는 구간의 원소들의 합.arr = [1, 3, 5, 7, 9, 12]def prefixSum(arr, start, end): # arr배열의 start번째 원소부터 end번째 원소까지의 합 return result비효율 적인 방법def prefixSum(arr, start, end): result = 0 for i in range(start, end): result += arr[i] return result효율적인 방법2부터 5 구간 사이의 합은 5 + 7 + 9 + 12 = 33이다.이는 5번째 원소까지의 합 1 + 3 + 5 + 7 + 9 + 12 에서 (2-1)번째 원소까지의 합 1 + 3 을 뺀 값과 같다.arr = [1, 3, 5, 7, 9, 12]arrSum = [0]for v in arr: arrSum.append(v+arrSum[-1])# arrSum = [0, 1, 4, 9, 16, 25, 37]def prefixSum(arrSum, start, end): result = arrSum[end+1] - arrSum[start] return result왜 효율적인가하나의 배열이 주어지고 구간 합의 구간이 k 개 주어졌을 때를 가정해 봅시다.비효율적인 방법을 사용하면 k 개의 쿼리를 받을 때마다 구간 사이의 거리에 따라 다르겠지만 배열을 순회하며 구간 합을 구해야 합니다. 이때 시간 복잡도는 k * O(n) (이때 n은 배열의 길이) = O(n)입니다.하지만 두 번째 방법을 사용하게 되면 처음에 arrSum을 한번 구해주기만 하면 이후에 들어오는 모든 요청들에 대해서 배열의 두 값에 접근하여 차잇값만 구하면 되므로 O(1) 만큼의 시간밖에 소요되지 않습니다. 따라서 이 방법의 시간 복잡도는 처음에 배열을 구하는 시간 n + k * O(1) = O(1)이 됩니다.결론 들어오는 구간합을 구하는 요청이 많아질수록, 배열의 길이가 길어질수록두 번째 방법이 유리한 접근 방법이 된다." }, { "title": "[짧] Query Parameter vs Path parameter", "url": "/posts/QueryVsPath/", "categories": "Development, Shorts", "tags": "parameter, query parameter, path parameter", "date": "2022-06-27 14:15:00 +0900", "snippet": "Path params vs Query params우리는 서버의 라우팅을 설계할 때 아래와 같은 기능을 두가지 방법으로 나타낼 수 있다. 작성자가 bob인 모든 게시글들을 조회한다 Query Params /posts?id=bob Path Params /posts/bob 여기서 1번과 같은 방식으로 데이터를 전송하는 것을 query parameter 2번을 path parameter 라고 한다.이렇게 같은 기능을 두가지 형식으로 표현할 수 있는데 언제 어떤 형식을 사용해야 할까?그리 복잡하지 않은 구조라면 아래의 기준에따라 나눠보면 좋다. 어떤 리소스를 식별하고 싶다면 Path Parameter 정렬이나 필터링을 원한다면 Query Parameter예시 아이디가 Jimmy인 유저를 가져온다. (특정 유저) =&amp;gt; path params[GET] /users/jimmy 직업이 프로그래머인 유저목록을 가져온다 (필터링) =&amp;gt; query params[GET] /users?job=programmer 게시글id값이 192인 게시글을 삭제한다. (특정 게시글) =&amp;gt; path params[DELETE] /posts/192 생성일을 기준으로 모든 유저목록을 불러온다. =&amp;gt; query params[GET] /users?sort=created_at 아이디가 jimmy인 유저의 게시글중(특정 유저) 에 카테고리가 게임인 게시글(필터링)을 불러온다.[GET] /posts/jimmy?categori=game" }, { "title": "[Shorts] Read Config files using Viper in Golang ", "url": "/posts/Viper/", "categories": "Development, Shorts", "tags": "env, config, viper", "date": "2022-06-03 10:21:00 +0900", "snippet": "Installationgo get github.com/spf13/viperWrite Config Filesapp.envDB_DRIVER=&quot;postgres&quot;DB_SOURCE=&quot;postgres://root:secret@localhost:5432/test_db?sslmode=disable&quot;SERVER_ADDRESS=&quot;0.0.0.0:3000&quot;you can also create config files in other extensions like yaml, json, TOML …Read Config Filesenv/config.gopackage envimport &quot;github.com/spf13/viper&quot;type Config struct { DBDriver string `mapstructure:&quot;DB_DRIVER&quot;` DBSource string `mapstructure:&quot;DB_SOURCE&quot;` ServerAddress string `mapstructure:&quot;SERVER_ADDRESS&quot;`}func LoadConfig(path string) (config Config, err error) { viper.AddConfigPath(path) viper.SetConfigName(&quot;app&quot;) // your config file&#39;s name : [app].env viper.SetConfigType(&quot;env&quot;) // your config file&#39;s extension : app.[env] viper.AutomaticEnv() err = viper.ReadInConfig() if err != nil { return } err = viper.Unmarshal(&amp;amp;config) return}main.gopackage mainimport ( &quot;testenv/env&quot; &quot;fmt&quot; &quot;reflect&quot;)func main() { config, err := env.LoadConfig(&quot;.&quot;) // path of app.env if err != nil { log.Fatal(&quot;cannot read config: &quot;, err) } values := reflect.ValueOf(config) typeOfFields := values.Type() for i := 0; i &amp;lt; values.NumField(); i++ { fmt.Printf(&quot; %s : %v \\n&quot;, typeOfFields.Field(i).Name, v.Field(i).Interface()) }}OutputDBDriver : postgresDBSource : postgres://root:secret@localhost:5432/test_db?sslmode=disableServerAddress : 0.0.0.0:3000" }, { "title": "[Docker] Docker를 사용하여 postgreSQL 서버를 띄워보자(1)", "url": "/posts/PostgresXDocker/", "categories": "Development, DevOps", "tags": "postgreSQL, docker", "date": "2022-05-09 16:04:00 +0900", "snippet": "준비물 Docker 설치: https://www.docker.com/products/docker-desktop/Docker 기초 문법 현재 돌아가고 있는 도커 컨테이너 불러오기 docker ps 멈춰있는 상태의 컨테이너까지 불러오기 docker ps -a 도커 이미지 불러오기 docker images Docker Hub에서 이미지 가져오기 # 기본 형태docker pull &amp;lt;image&amp;gt;:&amp;lt;tag&amp;gt;# postgres:14-alpine 이미지 가져오기docker pull postgres:14-alpine 도커를 사용하면 내 로컬환경에 직접 프로그램을 설치하지 않아도 원하는 이미지를 불러와 해당 이미지로 컨테이너를 실행시켜 내가 원하는 환경을 쉽게 구축할 수 있다.우리는 postgres DB 서버를 띄우길 원하니까 DockerHub에 들어가서 최신 버전의 postgres 이미지를 가져오자.여기서 alpine은 초경량화된 배포판을 뜻한다. 컨테이너 실행하기docker images명령어로 이미지를 잘 불러왔는지 체크해보고 잘 불러왔다면 docker run명령어로 특정 이미지의 컨테이너를 실행시킬 수 있다.docker run --name &amp;lt;container_name&amp;gt; -e &amp;lt;environment_variable&amp;gt; -d &amp;lt;image&amp;gt;:&amp;lt;tag&amp;gt;image vs container ?image를 컨테이너를 찍어내는 틀이라면 container를 실제로 돌아가고 있는 환경? 인스턴스?이미지와 컨테이너의 관계를 객체지향 프로그래밍에서의 클래스와 인스턴스의 관계 비슷하게 생각하면 될 것 같다.하나의 이미지를 가지고 수백개의 컨테이너를 찍어낼 수 있다 ㅇㅇ.Port mapping포트 매핑을 통하여 특정 포트로 들어오는 트래픽을 도커의 특정 포트로 전달시킬 수 있다.postgres는 기본적으로 5432포트를 사용한다. 로컬의 5432포트로 들어오는 트래픽을 컨테이너의 5432포트로 연결시켜주려면 아래와 같이 하면 된다.docker run --name &amp;lt;c_name&amp;gt; -e &amp;lt;env_var&amp;gt; -p &amp;lt;host_ports:c_ports&amp;gt; -d &amp;lt;image&amp;gt;:&amp;lt;tag&amp;gt;docker run --name postgres14 -p 5432:5432 -e POSTGRES_USER=root -e POSTGRES_PASSWORD=secret -d postgres:14-alpinedocker run 명령이 성공적으로 실행되면 컨테이너 ID값을 반환해준다.이후 docker ps 명령어로 가동중인 컨테이너 리스트를 확인해보면 컨테이너가 정상적으로 생성된 것을 확인할 수 있다.컨테이너에 명령어 실행시키기docker exec 명령어를 사용하여 컨테이너 안에서 특정 명령어를 실행시킬 수 있다.내가 직접 디비서버에 접속해 쿼리를 작성하고 싶은 경우에 활용할 수 있다.(postgres의 경우 로컬에서 접속하는 경우 비밀번호를 요구하지 않는다고한다.)docker exec -it &amp;lt;c_name or c_id&amp;gt; &amp;lt;command&amp;gt; [args]docker exec -it postgres14 psql -U root위 명령어는 “ postgres14 컨테이너에서 명령어 $ psql -U root를 실행하겠다.”라는 의미다.그래서 위 명령어를 입력하면 컨테이너의 디비서버에 접속을 할 수 있다.컨테이너 로그 출력docker logs 명령어를 통해 컨테이너의 로그를 불러올 수 있다.docker logs &amp;lt;container name or id&amp;gt;" }, { "title": "[짧] PostgreSQL에서의 INDEX ", "url": "/posts/INDEX/", "categories": "Development, Shorts", "tags": "postgreSQL, index", "date": "2022-05-02 10:31:00 +0900", "snippet": " PostgreSQL-Index를 요약, 번역 하였습니다.CREATE TABLE test1 ( id integer, content varchar);SELECT content FROM test1 WHERE id = 5;위와 같은 상황에서 SELECT문을 실행할 때 아무런 설정을 해놓지 않으면 시스템은 테이블의 모든 행을 뒤지면서 매칭되는 행을 찾습니다. 만약 테이블의 행 크기가 크고 쿼리를 통해 반환받는 행의 개수가 적다면 모든 행을 뒤지면서 매칭되는 행을 찾는 것은 매우 비효율적입니다. 이런 경우에 (위 예시에서는 id컬럼에) 인덱스 값을 걸어준다면 매칭되는 행을 더 효율적으로 찾을 수 있습니다. postgreSQL의 인덱스는 B-Tree로 작동하므로 몇 번의 분기만으로 원하는 행을 찾을 수 있겠죠.postgreSQL에서 인덱스를 생성하는 명렁어는 아래와 같습니다.CREATE INDEX your_index_name ON test1 (id);인덱스는 언제든지 추가하거나 DROP명령어를 통해 삭제할 수 있습니다.인덱스를 한번 생성하면 추가적인 작업을 수행하지 않아도 테이블이 수정될 때 자동으로 업데이트되며 인덱스가 효율적으로 쓰일 거라 판단되는 쿼리 요청이 들어왔을 때 시스템이 알아서 인덱스를 활용합니다.또한 인덱스는 UPDATE, DELETE명령도 효율적으로 수행할 수 있게 해주며 JOIN명령이 실행될 때도 인덱스를 포함하고 있는 열이 JOIN명령에 연관이 있다면 쿼리에 대한 응답을 훨씬 빨리 뱉어낼 수 있습니다.크기가 큰 테이블에 인덱스를 생성할 때는 많은 시간이 걸릴 수 있습니다. PostgreSQL은 인덱스가 생성되고 있을 때 읽기(SELECT) 작업은 허용하지만 쓰기, 삭제, 갱신 (INSERT, UPDATE, DELETE ) 작업은 허용하지 않습니다.인덱스가 한번 생성되면 시스템은 테이블과 인덱스를 동기화하기 때문에 데이터를 다룰 때 더 많은 오버헤드가 발생합니다. 따라서 거의 쓰이지 않거나 아예 쓰이지 않는 인덱스는 삭제를 해주어야 합니다." }, { "title": "[알고리즘] 그림으로 이해하는 다익스트라(Dijkstra) 알고리즘", "url": "/posts/Dijkstra/", "categories": "Development, Algorithm", "tags": "dijkstra, algorithm", "date": "2022-04-12 13:28:00 +0900", "snippet": "다익스트라 알고리즘이란?다익스트라 알고리즘은 에츠허르 다익스트라가 고안한 알고리즘으로 하나의 시작 정점에서 다른 모든 정점까지의 최단거리를 구하는 알고리즘이다. (단 음의 가중치를 갖는 간선이 없어야 한다.).처음 다익스트라 알고리즘은 O(V^2)의 복잡도를 가졌었지만 우선순위 큐를 사용하여 O(E+VlogV)까지 시간 복잡도를 줄일 수 있게 되었다.백준 기준으로 골드 3 ~ 골드 1 정도의 문제를 풀다 보면 다익스트라 알고리즘을 활용해서 풀어야 하는 문제들을 접할 수 있으며 개발자라면 알아야 할 것 같은 알고리즘 중 하나라고 생각하기도 하고 자꾸 문제를 푸는데 다익스트라 알고리즘을 정확하게 이해하고 있지 못하고 있는 것 같아서 포스팅을 남기게 되었다.다익스트라 알고리즘의 탐색 과정아래와 같은 정점과 간선들이 있습니다. 아래의 그래프에서 정점 A에서 다른 모든 정점까지의 최단거리를 구하려고 합니다.먼저, 출발점 A를 방문하고 A에서 출발하는 간선들을 추가해 줍니다.추가된 간선들을 통해 도달할 수 있게 된 정점 B, C, D까지의 최단거리를 갱신해 줍니다. 여기서 다음으로 어느 정점을 방문해야 할까요?다익스트라 알고리즘에서는 도달할 수 있는 정점 중 가장 최단거리가 짧은 노드를 우선순위로 방문합니다. 따라서 간선 AD를 타고 D를 방문하게 됩니다.D를 방문하였으니 전과 마찬가지로 D에서 시작하는 간선을 추가하고 아직 방문하지 않은 정점(노란색으로 마킹하지 않은 정점) 중 가장 가까운 정점을 찾아 방문하게 됩니다.똑같이 진행해 줍니다. C를 방문하게 되면서 정점 E에 도달할 수 있게 되었는데 이때 정점 E의 최단거리는 C의 최단거리(3) + 간선 CE(3) = 6이 됩니다. 다음 정점은 아직 방문하지 않았고 방문할 수 있는 B와 G 중 더 최단거리가 짧은 B가 되겠습니다.B를 방문하면서 F에 도달할 수 있게 되었습니다. F의 최단거리를 B의 최단거리(5) + 간선 BF(7) = 12로 갱신해 줍시다.또 이번에는 간선 BE를 통해 E로 도달할 수 있게 되었습니다. 하지만 현재 E의 최단거리인 6이 B의 최단거리(5) + 간선 BE(2) = 7 보다 짧기 때문에 갱신해 주지 않습니다. 만약 B + BE가 6보다 작았다면 더 짧은 최단거리이므로 갱신이 되었겠죠? 하지만 B를 통해 E로 가는 길은 최단거리가 아니었기 때문에 그냥 넘어가 줍니다.이번엔 E를 방문하게 되면서 E를 통해 F로 가는 길을 찾았습니다. 이번 경우에는 기존 F의 최단거리인 12가 E의 최단거리인 6과 간선 EF의 길이 4의 합인 10보다 크기 때문에 F의 최단거리를 10으로 갱신해 줍니다. 그 후 전과 동일하게 남아있는 정점 F와 G 중 더 짧은 최단거리를 가진 F를 방문합니다.F를 방문하니 F를 통해 G로 방문하는 길이 생겼습니다. 이번 경우에도 F를 통해 G로 도달하는 거리가 기존 G의 최단거리보다 짧아 G의 최단거리 값을 갱신해 줍니다. 이제 남은 정점은 G밖에 없으니 G를 방문해 줍니다.이제 모든 정점을 방문하였습니다. 다익스트라 알고리즘은 모든 정점을 방문하게 되면 탐색을 종료합니다.표를 한번 보면 A로부터 모든 정점까지의 최단거리를 확인할 수 있습니다. 이때 최단 경로는 빨간색 간선들을 통해 정점까지 도달하는 경로가 됩니다.끝내며..원래 위 그림들을 피피티 형식으로 샥샥 넘겨가면서 봐야 이해가 더 잘 될 거같은데 그렇게 올릴 수가 없어서 좀 아쉽다,, 그래서 슬라이드를 움짤로 만들어봤는데 글씨가 잘 안 보이긴 한다..아무튼 다익스트라에 대한 포스팅은 이 정도로 끝내겠다. 다익스트라 알고리즘이 길 찾기 알고리즘 중에 가장 대표적이고 쉬운 알고리즘에 속한다.다익스트라 알고리즘은 하나의 정점에서 다른 정점까지의 최단거리를 구해주는 반면에 모든 정점 쌍들 간의 거리를 구해주는 플로이드-워셜 알고리즘, 음의 가중치를 가진 간선에서도 최단거리를 구해주는 벨만-포드 알고리즘 그리고 다익스트라 알고리즘의 심화판인 A* 알고리즘 등 더 어렵고 신기한 알고리즘들도 있다.다음에 기회가 되면 다른 길 찾기 알고리즘에 대해 탐구해 보는 시간을 가져보도록 해보겠다." }, { "title": "QnA로 기록하는 2022 GDSC KR Winter Hack 후기", "url": "/posts/GDSCWinterHack/", "categories": "Diary", "tags": "GDSC, Winter Hack, Google Solution Challenge", "date": "2022-02-08 17:17:00 +0900", "snippet": "Q. 처음으로 시작부터 끝까지 본 해커톤이었는데?그렇다. 얼마 전에 원티드 해커리어 해커톤도 참여는 했었는데 기획 심사에서 탈락하여 개발은 시작도 못한 채 끝이 나서 나에게는 이번 해커톤이 내 인생 첫 해커톤이었다. 첫 해커톤인 만큼 부담을 갖지 않으려 했고 팀원들도 전부 첫 해커톤, 협업 경험x 여서 해커톤 트라이팟 느낌으로 도전을 해보았다.Q. 해커톤에 대해 간단히 설명해주세요. 그리고 어떤 주제로 프로젝트를 만드셨나요?GDSC WinterHack은 GDSC에서 개최하는 해커톤으로 유엔의 지속 가능 개발 목표 (SDGS) 중 3가지 주제 Quality Education, Gender Equality, Climate Action 중 한 가지를 선정하여 해당 문제를 해결할 수 있는 서비스를 만드는 해커톤이다. 우리 팀의 경우 팀원들의 투표로 Quality Education 주제 중에서 젊은 세대의 문해력이 떨어진다는 문제점을 해결하기로 결정하였고, 미연시 게임류를 만들어 문해력 발달에 도움을 줄 수 있는 게임 앱을 만들기로 했다.Q. 결과는 어떻게 되었는지요?아쉽게도? 당연하게도? ㅋㅋ 수상은 하지 못하였다. 애초에 팀 목표가 완성까지 해보자! 였고 수상보다는 그 앱을 완성하면서 디자이너, 개발자 간의 협업 경험을 해보는 것에 중점을 두었었다. 또 수상은 하지 못하였지만 다른 팀들 작품, 아이디어를 보면서 배울 점도 많았고 다음 해커톤에는 더 많은 준비를 해가야겠다는 걸 배웠다. 결국 뭘 하든 처음을 겪어야 하는데 해커톤 경험이 없는 팀원들끼리 모여 모두에게 한 번쯤은 꼭 필요했던 실패를 경험했다고 생각한다..!Q. 이번 해커톤을 하면서 아쉬웠던 점이 있나요?해커톤이 끝날 때쯤 아쉬웠던 점이 하나 있었는데 바로 우리가 잘하는 스택으로 개발을 진행하지 않았다는 점이다. 우리 팀원은 디자이너 1, 웹 프론트 개발자 1, 웹 백엔드 개발자 2로 이루어져 있는데 앱 개발을….. 하기로 하게 된 것이다 ㅋㅋㅋㅋㅋ. 사실 처음에 앱 개발로 정할 때까지는 우린 어차피 첫 해커톤이니까! 우리가 하고 싶은 거 해보자! 라는 마인드였는데 우리가 절반 정도밖에 완성을 못해서… 발표할 때쯤 되니까 우리가 잘하는 스택을 활용했다면 다른 참가자들과 심사위원분들에게 더 좋은 결과를 보여줄 수 있지 않았을까 하는 아쉬움이 있었다 하하핳ㅎ,,,Q. 그럼 반대로 좋았던점도 당연히 있었겠죠?ㅇㅇ. 우선 앱 개발자와 디자이너가 어떤 식으로 협업을 하게 되는지 그 과정을 조금 (사실 우리가 진행한 방법이 맞는 방법인지는 모르겠다) 체험하게 되었다. 내가 프론트 개발자는 아니지만 항상 개발자와 디자이너가 어떤 식으로 협업을 하는지 참 궁금했었는데 이번 해커톤을 통해 조금은 궁금증을 해소하게 됐다고 생각한다. (내 앱 개발 실력이 부족해서 디자이너 분이 준 디자인에서 뭔가 20% 부족한 디자인으로 적용하게 된 건 안비밀..ㅋㅋㅌㅋ)또 이번에 내가 전혀 할 줄 몰랐던 앱 개발로 프로젝트를 진행하면서 앱 개발 지식도 좀 갖추게 되었는데 이 정도 실력이면 시간만 충분하다면 나 혼자 앱 개발할 수 있겠는데..? 하는 근거 없는 자신감도 생겼다.. 앱 개발까지 기술을 넓히게 된 건 좋지만 내가 앱 개발 쪽으로 커리어를 쌓을 거 같지는 않아서.. 이게 좋은건지 나쁜건지는 모르겠다..Q. 새롭게 배웠던 점이 있었다면?가장 놀랐던 건 아마 나와 비슷한 나이대 분들이 참가하신것 같은데 진짜 열정도 넘치는데 잘하기까지 하는 사람들이 엄청 많았던 것이었다. 아마도 참가하신 분들의 스펙트럼이 학생 ~ 취준생 일 거라고 생각이 드는데 완성도도 높고 기술적으로도 뛰어난 솔루션을 구축한 팀들이 많았다.. 발표를 들으며 자극도 받게 되었고 배운 것도 많았다. 무엇보다 항상 내가 이해 가능한 수준의 코드이면서 나보다 더 잘 짠 코드들을 보고 싶다는 생각이 너무너무 많이 들었는데 이번에 참가한 팀들의 코드를 보며 더 성장할 수 있을 것 같다.!.! 아무튼 여러 방면으로다가 이것저것 배울 수 있었다.Q. 앞으로의 계획!!이제 3월 말까지 구글의 솔루션 챌린지를 준비해야 한다. 이번 팀은 앱 개발자 1, 디자이너 1분과 나까지 세명으로 이루어져 있는데 GDSC 윈터핵에서의 실패와 배운 점들을 발판 삼아 수상은 하지 못하더라도 내가 납득이 가능한? 뿌듯해할 만한? 결과를 만들어내고 싶다. 앞으로 두 달. 정도의 준비 기간이 있는 만큼 열심히 준비해서 좋은 결과 만들어 낼 수 있을 것 같다.마를래바 깃허브: https://github.com/gdsckoreahackathon2022/06_MaReulraeba" }, { "title": "Connection: Upgrade의 의미", "url": "/posts/upgrade/", "categories": "Development, Network", "tags": "upgrade, websocket", "date": "2021-12-27 13:14:00 +0900", "snippet": "Upgrade?웹소캣을 공부하다가 웹소캣 연결을 위해 서버로 요청을 보낼 때 Connection:Upgrade를 헤더에 포함하여 보내는걸 보고 이게 무슨 뜻인가.. 해서 찾아봤어요.결론은 바로 클라이언트가 서버에게 &quot;현재 연결된 프로토콜을 다른 프로토콜로 바꿔줘!&quot; 라고 요청하는 것이었습니다. 다른 프로토콜의 연결을 새로 만드는게 아니라 현재 연결의 프로토콜을 전환시키는 것임!뭐 예를 들어 현재 HTTP 1.1 프로토콜에서 HTTP 2.0, HTTPS, Web socket으로 전환하는 것입니다.요청의 예시를 보면 아래와 같아요.GET /hello HTTP/1.1Host: localhostConnection: upgradeUpgrade: websocket, fooupgrade가 뭔지 아니까 처음 볼때보다 더 눈에 잘들어온다. Connection: upgrade를 보고 다른 프로토콜로 전환해달라는 요청인 것을 알수 있게 되었습니다. 그러면 당연히 어떤 프로토콜로? 라는 질문이 따라오게 되는데 Upgrade: websocket, foo 부분을 보고 “아 이걸로 바꿔달라는 거구나” 알 수 있습니다. Upgrade에 한개 이상의 프로토콜이 들어오는 경우가 있는데 이는 클라이언트가 전환해주길 원하는 프로토콜 목록의 선호도를 내림차순으로 리스팅하여 보낸것이다. Upgrade가 헤더에 포함되면 Connection:upgrade도 필수적으로 요청에 포함되어야 한다. 101: Switching Protocols그렇게 프로토콜 전환 요청이 성공적으로 이루어 지면 서버측에서는 101 Switching Protocols응답과 함께 아래와 같이 응답을 해줍니다.HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: Upgrade426: Upgrade Required위 내용과 살짝 별개의 내용이긴 한데 서버가 내가 보내는 요청의 프로토콜을 수행할 수 없으나 다른 프로토콜로 전환하면 수행할 수 있을 경우 426 Upgrade Required상태코드를 반환합니다.HTTP/1.1 426 Upgrade RequiredUpgrade: HTTP/2.0Connection: UpgradeContent-Length: 53Content-Type: text/plainThis service requires use of the HTTP/2.0 protocol" }, { "title": "슈도코드로 이해하는 소켓 프로그래밍", "url": "/posts/Socket/", "categories": "Development, Network", "tags": "socket, tcp", "date": "2021-12-16 11:38:00 +0900", "snippet": "인터넷을 통해 데이터를 주고받을 때 가장 먼저 떠오르는 두가지는 http 통신과 소켓 통신입니다.이 둘엔 한가지 큰 차이점이 있는데 http 통신의 경우에는 클라이언트가 서버에 요청을 보내면 서버는 받은 요청에 알맞는 응답을 보내주는 식으로 동작을 하는데 이것을 단방향 통신이라고 해요.반면에 소켓 통신의 경우에는 클라이언트와 서버 측 둘 다 데이터를 주고 받을 수 있습니다.그래서 채팅과 같이 양 쪽 모두 데이터를 주고 받아야 하는 상황에서는 양방향 통신이 가능한 소켓 통신이 유리하다고 할 수 있겠습니다.오늘은 이 소켓 통신, 소켓 프로그래밍이 어떤 원리로 이루어 지는지 정리를 해보겠습니다.소켓 통신에는 대표적으로 tcp 통신, udp 통신이 있는데 이 두가지에 대한 내용은 다음에 기회가 되면 다뤄보도록 하겠습니다.Connect to TCP socket통신을 하는 개체에는 서버와 클라이언트가 있는데 먼저 서버에서의 tcp 네트워킹 구성은 어떻게 이루어 지는지 슈도 코드로 알아보겠습니다. 먼저 서버 측 슈도코드입니다.Servermain() { s = socket(TCP); s.bind(5959); s.listen(); s2 = s1.accept(); for() { r = s2.recv(); if (r.length &amp;lt;= 0) break; print(r); } s2.close();}위 코드를 나누어 설명하면 TCP 소켓을 생성합니다. s = socket(TCP); 생성된 소켓을 특정 포트번호에 바인딩 시킵니다. (클라이언트는 이 바인드된 포트번호로 연결을 요청해야 서버측과 TCP 네트워킹을 할 수 있습니다.). s.bind(5959); 소켓을 요청을 받는 상태로 만들어 준 다음 요청을 기다리는 상태로 전환합니다.accept()메소드가 실행되면 서버로의 연결 요청이 들어올 때 까지 대기상태로 들어가게 됩니다.요청이 들어오게되면 accept()는 요청을 보낸 클라이언트와 통신할 수 있는 소켓 핸들러를 반환하게 됩니다. s.listen();s2 = s.accept(); 이제 무한 루프를 돌면서 클라이언트가 보낸 데이터가 없을 때 까지 받아온 데이터를 출력해줍니다. TCP 소켓에선 수신 받은 데이터의 크기가 0바이트면 상대방이 tcp연결을 끝낸 것을 의미합니다. for() { receivedMessage = s2.recv(); if (receivedMessage.length &amp;lt;= 0) break; print(receivedMessage);} 통신이 끝났음으로 소켓을 닫아줍니다. s2.close(); Client클라이언트 측의 코드도 간단합니다. 서버 측 코드를 보고 왔다면 더 빨리 이해할 수 있을거같네요.main() { s = socket(TCP); s.bind(6000); s.connect(&quot;localhost:5959&quot;); s.send(&quot;hello server ;p&quot;); s.close();} 마찬가지로 TCP소켓을 생성하고 특정 포트에 바인드 시켜 줍니다. s = socket(TCP);s.bind(6000); TCP소켓을 열어둔 서버로 연결을 요청합니다. s.connect(&quot;localhost:5959&quot;); 연결이 완료 되었다면 메세지를 보낸 후 소켓을 닫습니다. s.send(&quot;Hello server ;p&quot;);s.close(); 송수신 버퍼위 코드에서 특정 상황에서 send(), recv()메소드가 블로킹이 걸리는 경우가 있습니다. 우선 왜 블로킹이 걸리는지 알기 전에 소켓 버퍼에 대한 이해가 필요한데 각 소켓에는 송신 버퍼와 수신 버퍼를 하나씩 갖고 있습니다.송신 버퍼 (send buffer)송신 버퍼는 큐의 형태로 작동합니다. send(A)메소드가 실행이 되면 송신 버퍼에 A를 푸시하게 됩니다. (상대방에게 A를 보내는것이 아님!!) 송신 버퍼가 채워지면 잠시 후 가장 먼저 들어온 데이터가 운영체제로 송출됩니다.1. [ , , ] 송신 버퍼 비어있음.2. send(A,B); =&amp;gt; [B, A, ] 송신 버퍼에 A, B가 채워짐.3. 시간이 지나면 가장 먼저 들어온 데이터부터 pop되어 운영체제로 송출됨.4. [B, , ]5. [ , , ]그렇다면 send()메소드는 어떤 경우에 블로킹이 걸리게 될까요? 바로 송신 버퍼가 가득 차 있을 때 입니다.아래와 같이 송신 버퍼가 가득 차 있는 상황에서 send(data) 메소드가 실행되면 블로킹이 걸려 다음 코드로 진행되지 못하고 송신 버퍼에 빈 자리가 생길 때 까지 대기하게 됩니다.1. [A, B, C, D] 송신 버퍼가 가득 차 있는 상태.2. send(E);3. E -&amp;gt; [A, B, C, D] 송신 버퍼에 빈 자리가 없어서 블로킹 발생!4. [ , A, B, C] 빈자리가 생김.5. [E, A, B, C] 송신 버퍼에 E가 채워지고 블로킹 해제.수신 버퍼 (receive buffer)반대로 receive()메소드는 수신 버퍼가 비어있을 때 블로킹이 발생하게 됩니다.블로킹 상태로 대기를 하다가 1바이트라도 받을 데이터가 채워지면 블로킹을 해제하게 됩니다.그런데 여기서 수신 버퍼가 가득 찬 상태가 되면 어떤 일이 발생할까요?수신 버퍼가 가득 차게 되는 상황은 수신 버퍼에서 데이터를 꺼내는 속도가 운영체제가 수신 버퍼에 데이터를 채우는 속도보다 느릴 때 발생하게 되는데 이 경우에는 송신 측의 send()메소드에 블로킹이 걸리게 됩니다.TCP연결의 경우 이런식으로 수신버퍼가 찼을 때 블로킹을 걸어 데이터 유실이 발생하지 않도록 하여 통신의 신뢰성을 높여줍니다.그렇다면 UDP 통신의 경우에는 수신 버퍼가 가득 차면 어떻게 될까요?UDP 소켓의 경우엔 수신 버퍼가 가득차도 블로킹을 걸어 주지 않아 데이터 유실이 발생하게 됩니다.이게 tcp와 udp의 차점 중 한가지 입니다.여기까지 소켓 프로그래밍에 대해 간단히 알아보았습니다.오늘 설명한 소켓은 전부 블로킹 소켓입니다 (소켓의 디폴트 값이 블로킹 소켓임).오늘처럼 1대1 통신과 같은 상황에서는 블로킹 소켓을 사용해도 큰 문제가 없지만 여럿과 통신을 할때에는 블로킹 소켓을 사용할 경우 여러 문제상황과 마주 할 수 있는데 이를 해결하기 위해 논-블록 소켓이란 것이 존재합니다.기존 블록 소켓의 경우에는 send()혹은 recv() 메소드가 블로킹에 빠져 대기상태에 들어가는 경우가 있었지만 소켓을 논-블로킹 소켓으로 전환을 해주면 버퍼가 꽉차이든 비어있든 원래는 블로킹이 발생해야 하는 상황에서 대기 상태에 빠지지 않고 바로바로 값을 리턴을 해줍니다. 그래서 블로킹 소켓을 사용할 때 발생할 수 있는 여러 문제상황을 해결할 수 있게 해줍니다.오늘은 여기까지만 알아보고 다음에 non-blocking socket에 대해 공부해보는 시간을 가져보도록 하겠습니다,,Reference 배현직, 게임서버 프로그래밍 교과서 (2019)" }, { "title": "[Setting] M1 pro 맥북 개발환경 세팅.기록", "url": "/posts/M1Setting/", "categories": "Development, Settings", "tags": "m1pro, macbook, setting", "date": "2021-12-02 11:10:00 +0900", "snippet": "1. HomeBrew 설치아래 명령어를 터미널에 복붙해주자./bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;설치가 제대로 되었는지 확인brew update이때 path를 지정해주지 않아 아마zsh: command not found: brew에러가 발생할건데eval $(/opt/homebrew/bin/brew shellenv)를 명령어를 실행하고 난 뒤에는 정상적으로 작동하는 것을 확인할 수 있음.그런데 터미널은 닫았다가 다시 열면 또 brew 명령어를 찾지 못한다고 나오는데vi ~/.zshrc로 .zshrc파일로 들어가 가장 아랫줄에eval $(/opt/homebrew/bin/brew shellenv)를 저장해 주고 나면 터미널을 백번 껐다 켜도 brew명령어를 잘 찾아낸다.2. Iterm2 설치이제 다운받은 HomeBrew를 사용하여 Iterm2를 간단하게 설치할 수 있다.brew install --cask iterm23. Oh my zsh 설치Iterm2을 설치하였으니 터미널을 닫고 Iterm2를 켜보자. 이제 앞으로는 터미널을 사용하지 않고 Iterm2을 사용할 것이다.Iterm2을 켜고 아래 명령어를 실행시키자sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;Solarize Theme 설치https://gist.github.com/kevin-smets/8568070 에 접속하여 Solarized Dark theme 다운받은 후Iterm2에서 설정을 켠 후(cmd + ,) iTerm-&amp;gt;preferences-&amp;gt;profiles-&amp;gt;colors-&amp;gt;load presets에서 Solarized Dark를 선택해주자.4. PowerLevel 10K 설치아래 명령어를 실행시켜 Powerlevel10k를 설치해주자.git clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k그 후 ~./zshrc를 열어 (code ~/.zshrc 또는 vi ~/.zshrc) ZSH_THEME=&quot;powerlevel10k&quot;로 설정해주면 끝이다! Powerlevel10k설치과정 도중에 폰트를 설치하라는 경고가 발생할 수 있는데 설치해주면 된다!그렇게 완성된 터미널..!" }, { "title": "[알고리즘] 알아야 빨리푼다, LIS 알고리즘", "url": "/posts/LIS/", "categories": "Development, Algorithm", "tags": "lis, longest icreasing subsequence", "date": "2021-11-03 10:26:00 +0900", "snippet": "최장 증가 부분수열 (Longest Increasing Subsequence): 주어진 수열에서 만들 수 있는 오름차순을 만족하는 가장 긴 부분수열을 뜻한다.ex) [3, 2, 4, 1, 5]의 LIS는 [2, 4, 5][5, 3, 4, 1, 6, 8, 9]의 LIS는 [3, 4, 6, 8, 9]LIS문제는 dp(Dynamic Programming)기법으로 해결할 수 있다.수열이 주어졌다면 수열과 같은 길이를 같는 배열을 만들어주자.arr = [5, 3, 4, 1, 6, 10, 8, 9]dp = [0] * len(arr)dp 배열은 해당 위치까지 만들 수 있는 LIS를 저장해준다.dp[i]를 갱신해줄 때는 두가지 조건을 갖추어야 한다. arr[j] &amp;lt; arr[i]: 오름차순을 만족하기 위함 len(dp[j]) + 1 &amp;gt; len(dp[i]): 순회하면서 조회중인 dp[j]의 길이에 나 자신을 포함한 값이 현재 dp[i]의 길이보다 길어야 한다.for i in range(len(arr)): dp[i] = [arr[i]] for j in range(0, i): if (arr[i] &amp;gt; arr[j]) and ((len(dp[j]) + 1) &amp;gt; len(dp[i])): dp[i] = dp[j] + [arr[i]]모든 dp를 갱신해준뒤 출력해보면 아래와 같이 해당 위치까지에서 찾을 수 있는 lis를 저장한 것을 확인할 수 있으며 가장 긴 길이를 가진 [3, 4, 6, 8, 9]를 잘 찾아낸 것을 확인할 수 있다.print(dp)# [[5], [3], [3, 4], [1], [3, 4, 6], [3, 4, 6, 10], [3, 4, 6, 8], [3, 4, 6, 8, 9]]LIS 알고리즘으로 풀 수 있는 문제백준 2631번: 줄세우기이 문제는 N명의 학생들이 1~n까지의 번호표를 달고 무작위 순서로 줄을 서있을 때 최소한의 횟수로 학생들을 옮겨 번호 순서대로(오름차순) 다시 줄을 세워야 하는 문제이다.이 문제를 LIS알고리즘을 활용해 해결할 수 있는데 최소한의 횟수만큼만 움직여야 하니까 주어진 배열에서 LIS를 구하면 올바른 위치에 서있는 학생의 수를 구할 수 있게 되고, 그 외의 학생들을 올바른 위치로 옮겨주면 올바르게 줄을 세울 수 있다. 간단히 식으로 구하면 아래와 같다.최소한의 횟수 = (학생들의 수) - (현재 배열에서 구한 LIS의 길이)식에서 우리가 알고 있는 것은 학생들의 수이므로 구어진 배열에서 LIS의 길이만 구하면 된다. 이 글에서 소개한 방법으로는 LIS자체를 구했는데 조금만 수정해주면 쉽게 LIS의 길이를 구할 수 있다.import sysinput = sys.stdin.readlinen = int(input())arr = []dp = []maxValue = 0for _ in range(n): arr.append(int(input())) dp.append(0)for i in range(n): dp[i] = 1 for j in range(0, i): if arr[i] &amp;gt; arr[j] and dp[j] + 1 &amp;gt; dp[i]: dp[i] = dp[j] + 1 if dp[i] &amp;gt; maxValue: maxValue = dp[i]print(n-maxValue)" }, { "title": "오랜만에 올리는 글.. 내 근황..", "url": "/posts/recentTalk/", "categories": "Diary", "tags": "log", "date": "2021-10-28 00:52:00 +0900", "snippet": "한 두달 간의 공백..어쩌다 보니 블로그에 글을 안 올린지 거의 두 달이 지나있었다..두 달 동안 뭘 했길래 블로그 활동을 하지 않았냐라고 한다면 할 말은 없다.. 뭐 GDSC 활동을 시작하기도 했고 백신도 맞고.. 해커톤 팀원 모집하느라 고생도 하긴 했지만 그래도 글을 쓸 시간은 넘쳤었기 때문에 ㅋㅋㅌㅋ 모르겠다 백신 맞으면서 꾸준히 해오던 운동도 잠깐 쉬고 있는데 ㅋㅋ (백신 부작용인가….?) 암튼 ㅋㅋ 어제부터 운동도 다시 시작했고 이제 글쓰기도 다시 꾸준히 해보려고 한다! 그래서 오늘은 그 시작으로 내 최근 근황을 의식의 흐름대로 써 내려가볼까 한다.GDSC에 합류하게 되다.8월 말인가? 인스타 스토리를 구경하다가 동기 형이 무슨 구글 어쩌고.. 개발자랑 디자이너랑 어쩌고.. 하는 걸 모집한다는 스토리를 보았다. 보자마자 디엠을 보냈고(3년 만의 연락 ㅋㅋ..) 공익 신분인 나도 활동을 할 수 있다는 답을 얻고 코어 멤버(운영진 같은 거)로 지원을 했다. 나름 1년 동안 꾸준히 공부를 해와서인지 코어 멤버에 붙게 되었고.. 그렇게 GDSC 활동을 시작하게 됐다. 아 여기서 GDSC는 Google Developer Students Club의 약자이다.근데 이게 활동 시작하고 얼마 안 돼서 바로 셤기간이 되어서 아직 좀 어색어색하고 스터디 할 때도 다들 조용조용하고 그렇다.. 이게 또 내가 좀 고학번에 속하다 보니(벌써 내가 그런..;.;.;;) 뭔가 좀 더 주도해야 할 거 같고 뭔가 이끌어 가야 할 거 같은 부담감.. 비슷한 뭔가가 있는데.. intp인 나한텐 더더욱 고통이다 ㅋㅋㅋ큐ㅠ 빨리 좀 친해져서 활발한 활동을 할 수 있기를!. !그러고 내가 발표도 두 번인가 했었는데 아마 깃 세션과 백엔드 개발자 로드맵 세션 이렇게 준비를 했었다. 아 진짜 발표는 항상 쉽지 않다.. 나름 열심히 준비를 해가도 발표를 너무 못해버려서 멤버들한테 이해를 잘 못 시킨 거 같아 너무 아쉬웠다 휴.. 차라리 대면 발표가 나을 거 같은..아무튼 셤기간 끝나면 슬슬 자바스크립트나 파이썬 기초 스터디는 끝이 나니까 코드리뷰 스터디, 개발 서적 읽기 스터디, 글쓰기 스터디 등등도 기회가 되면 해보고싶다 ㅋㅋ. 앞으로 방학쯤엔 팀 프로젝트도 시작하게 될 것 같고 최종적으론 구글 솔루션 챌린지까지 참여하게 되는데 그때까지 열심히 실력을 쌓고 함께할 좋은 동료도 많이 만날 수 있으면 좋겠다.열정만 너무 앞섰나?내가 꾸준히 공부 해오던 것들이 파이썬으로 코테준비, golang이랑 백엔드 공부하기 그리고 비교적 최근엔 node.js도 조금씩 공부해왔는데 gdsc를 하면서 javascript 스터디, flutter 스터디, gcp 코드잼까지 시작하게 되니까 .. 뭐랄까 할게 많은 건 둘째치고 뭔가를 하려고 노트북을 펴면 뭘 해야 할지 모르겠는 상황이 발생해버리기 시작했다.. gdsc 활동 초반에는 이것저것 신경 쓸 것도 많아서 더 그랬다.이런 상황이 몇 번 발생하니까 “아.. 내가 감당 못할 것들을 저질러 놨구나..” 라는 걸 깨달았고 스터디 같은 경우엔 중간에 나가버릴 순 없으니까 자연스럽게 다른 부분에 투자하는 시간이 줄었고.. 그렇게 gcp 코드잼은 드랍해버린 상태다 ㅋ. 뿐만 아니라 golang으로 코드를 짜는 시간도 줄었고 노드의 경우는 자바스크립트 스터디가 끝날 때까지 봉인할 거 같다. 급할수록 돌아가라는 말이 참 와닿았던 순간이었다 ㅋ..ㅋ생애 첫 스마트워치 =@=아 근데 내가 이런 사전예약같은걸 많이 안해봐서 ㅋㅋ.. 배송날짜가 좀 많이 늦다.. 암튼 빨리와줘…이번에 나온 맥북프로 14인치도 한국 출시만을 기다리는중..생애 첫 해커톤!진짜 살면서 해커톤 꼭 한번 참여해보고 싶다고 매번 생각만 하고 있었는데..!이번에 원티드에서 해, 커리어라는 해커톤을 연다는 걸 알게 되었고 무조건 나가야겠다고 생각했다.그런데.. 팀원 구하기가…….너무….히ㅁ들었다 진짜로 .,ㅠ,…,.,., 어찌어찌 3명까지 모집을 했다가 터지고.. 주변 동기, 후배들한테 연락도 돌려보고 에타에 글도 올려보고 했는데 지원해 주는 사람이 너무 없었다.. 무엇보다 앱 개발자가 왜이리 귀한 건지.. 그렇게 신청 2일전까진가 기획자 한 분만 모집한 채로 손가락 빨고 있다가 최후의 수단으로 gdsc korea(모든 학교의 gdsc 멤버들이 모여있는) 슬랙채널에 모집글을 올렸고 정말정말 감사하게도 대진대에서 리드분과 코어분 두 분이서 지원을 해주셨다..! (두 분 다 능력자신거 같다..b^^d) 그렇게 4명이 완성이 되어 바로 지원을 하게 되었고 바로 어제 팀 과제가 주어졌고 주제는 위드 코로나 시대에서 대학생을 위한 새로운 앱 서비스 기획 이었다. 대한민국이 건국 이후로 처음 맞는 위드 코로나인 만큼 여태껏 없었던 문제가 주어졌고 그만큼 새롭고 예상못한 아이디어들이 많이 나올 수 있겠다는 생각이 들었다(진짜 재밌을거같다 ㅠㅠ).우리 팀은 이번 주 일요일에 첫 미팅을 시작으로 해커톤 준비를 하게 되었다! 첫 해커톤이지만 좋은 결과도 내고 싶고.. 내가 여태 공부해온 것들을 증명? 확인? 해보고 싶은 마음도 크다. 정말 운이 좋게 이번에 팀원분들도 좋은 분들과 진행을 하게 된 거 같아서 나만 열심히 하면 좋을 결과가 나올 것 같다. 그래서 당분간은 해커톤에 내 신경의 대부분을 투자하지 않을까 싶다. 앞으로 블로그에도 해커톤 진행 상황이나 중간 점검 같은 컨텐츠를 올려볼까 생각 중이다.아 그러고 위에도 말했듯이 내가 gdsc에서 고학번에 속해서 진행하면서 내가 뭔가를 알려주는 상황이 가끔 발생하는데 그럴 때마다 &quot;감히 내가..?&quot;라는 생각이 머릿속에서 떠나가질 않는데 ㅋㅋㅋㅋ 해커톤을 진행하면서 나에대한 어떤 자신감도 얻어 가고 싶다. 아무튼 이번 해커톤은 여러 가지 면에서 나에게 의미가 클 거 같다.마치며..위에 적은 것들 외에도 적을 것들이 더 있긴 하지만 이 정도에서 끝을 맺으려 한다. 아 그리고 이번에 10/30부터 Gdsc DevFest도 진행하는데 매일 학교마다 준비해온 세션 발표, 네트워킹, 모각코 같은 활동을 하는 축제이다. 이번에 나는 해커톤도 그렇고 맘 편히 데브 페스트를 즐기기 위해 발표는 좀 피했다. 하핳,, 100명대 앞에서의 발표는 아직.. 좀.. ㅎ,,,ㅎ,, 여튼 굉장히 재밌는 세션들이 많이 준비되어 있는 거 같아서 굉장히 기대된다. 해커톤 준비를 하면서 동시에 쉬어가는 느낌으로 세션도 듣고 모각코도 하고 하면 알찬 한 달을 보낼 수 있지 않을까 생각이 든다." }, { "title": "Channel in Golang", "url": "/posts/channel/", "categories": "Development, Go", "tags": "golang, channel", "date": "2021-09-11 21:47:00 +0900", "snippet": "이 글은 Tucker님의 고언어 강의 Go 언어가 온당을 듣고 정리한 내용을 토대로 작성하였습니다.Go언어가 온당 Youtube채널 (Channel)채널은 고루틴간의 메세지큐= Thread-safe queue = 멀티쓰레드 환경에서 Lock없이 쓸 수 있다!채널 생성var messages chan string = make(chan string)채널에 데이터 넣기messages &amp;lt;- &quot;This is a message&quot;//채널 데이터 &amp;lt;- 넣을 데이터채널에서 데이터 빼기var msg string = &amp;lt;- messages// 데이터 담을 변수 &amp;lt;- 채널 인스턴스채널의 크기채널의 기본 크기는 0 이다.크기가 0이라는것은? 받은 데이터를 보관 할 공간이 없다는 뜻!var ch chan int = make(chan int, 3)// make()의 두번째 인자로 채널의 크기를 명시해주지 않으면 크기가 0인 채널func main() { ch := make(chan int) go square() ch &amp;lt;- 9 fmt.Println(&quot;Never print&quot;)}func square() { for { time.Sleep(2 * time.Second) fmt.Println(&quot;Sleep&quot;) }}var ch chan int = make(chan int, 3)// make()의 두번째 인자로 채널의 크기를 명시해주지 않으면 크기가 0인 채널func main() { ch := make(chan int, 2) go square() ch &amp;lt;- 9 // 빈자리가 있으면 ch에 9를 넣고 바로 밑으로 더 내려감 fmt.Println(&quot;Never print&quot;)}func square() { for { time.Sleep(2 * time.Second) fmt.Println(&quot;Sleep&quot;) }}채널에서 데이터 대기// ch에 데이터가 들어올 때 까지 계속 대기// 데이터가 들어오면 for문 실행하고 다시 대기for n := range ch { ...}close()채널을 닫을 때는 close()를 사용하여 닫아줄 수 있다.close()로 채널을 닫아주면 for문이 더이상 돌지 않는다.close()로 채널을 닫아주면 for문이 더이상 돌지 않음.채널을 제때 닫아주지 않아 무한 대기를 하게되면 이를 좀비 고루틴 또는 고루틴 릭이라고 한다. =&amp;gt; 시스템 부하를 유발해 프로그램 성능을 떨어트린다.select문여러 채널에서 동시에 데이터를 기다릴 때 사용. (for문은 1개의 채널만 대기한다고 볼 수 있겠다.)select { case n := &amp;lt;-ch1: ... case n2 := &amp;lt;- ch2: ... case ...}select{}는 기다리는 채널중에 하나의 값만 들어와도 액션을 취하고 select를 탈출하기 때문에 for문 안에 넣어서 주로 사용한다.한번에 여러개의 채널에서 select로 데이터를 보내면 select는 랜덤하게 하나만 실행한다.package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)func main() { var wg sync.WaitGroup ch := make(chan int) fmt.Println(&quot;Start&quot;) wg.Add(1) go square(&amp;amp;wg, ch) for i := 0; i &amp;lt; 10; i++ { ch &amp;lt;- i * 2 } wg.Wait() fmt.Println(&quot;Finish&quot;)}func square(wg *sync.WaitGroup, ch chan int) { tick := time.Tick(time.Second) terminate := time.After(20 * time.Second) for { select { case &amp;lt;-terminate: fmt.Println(&quot;Terminated@&quot;) wg.Done() return case n := &amp;lt;-ch: fmt.Println(&quot;Square:&quot;, n*n) time.Sleep(time.Second) case &amp;lt;-tick: fmt.Println(&quot;tick!&quot;) } }}" }, { "title": "Handling Error in Golang", "url": "/posts/handlingError/", "categories": "Development, Go", "tags": "golang, handling error, error", "date": "2021-09-09 12:26:00 +0900", "snippet": "이 글은 Tucker님의 고언어 강의 Go 언어가 온당을 듣고 정리한 내용을 토대로 작성하였습니다.Go언어가 온당 YoutubeGo언어에서 에러를 다루는 방법은 크게 두가지가 있다. 프로그램을 죽이는 방법 에러를 처리해서 프로그램을 지속시키는 방법개발 단계에서는 빨리 오류를 찾는게 좋으니까 오류가 나면 빨리빨리 죽이는 경우가 많음.서비스 배포 단계에서는 UX를 향상시키기 위해 프로그램을 지속시키는 방법이 좋을 수 있음. ex) 항공관제시스템을 만든다고 했을 때 오류가 났다고 프로그램을 죽여버리면 위험한 사황이 발생할 수 있으므로 프로그램이 죽지 않게 만들어줘야함. 마찬가지로 인공심장 머신에 들어가는 프로그램처럼 프로그램이 죽으면 치명적인 경우 죽지않는 프로그램을 설계해야함. golang에서는 에러가 발생했을 때 내부에서 처리하는 것이 아닌 error값을 반환해주어 사용자가 에러를 처리할 수 있게끔 설계되어있다.Custom Errorfmt.Errorf(formatter string, ...interface{}) error 함수 or errors.New(text string) error함수 사용나는 후자가 편했다.error typetype error interface { Error() string}Error() string 메소드를 가지면 어떤 타입이든 error 가 될 수 있다.Error Wrappingfunc wrappingExam(filename string) error { f, err := os.Open(finame) if err != nil { return fmt.Errorf(&quot;error: %w&quot;, err) } defer f.Close() return nil}래핑이라는 말 그대로 한 겹씩 에러를 감싸준다고 생각하면 된다. 후입선출이라고 볼 수 있겠다. (마지막으로 감싼 에러가 가장 먼저 벗겨짐.)호출자 입장에서는 어디서 에러가 발생했는지 알 수 없음.맨 아래에서부터 발생한 에러를 감싸서(wrapping) 위로 올림. (반복)이제 여러겹으로 감싸진 에러를 풀기위해 errors.As()로 원하는 에러를 꺼내올 수 있다.Panic처리하기 힘든 에러를 만났을 때 프로그램을 조기 종료하는 방법. (빠르게 죽는 방법)빠르게 종료시켜서 오류를 해결하기 위해서 사용 !panic을 사용하면 프로그램이 바로 종료되면서 어디서 문제가 생겼는지 로그로 바로 볼 수 있어서 에러를 좀 더 명확하고 찾기 쉬워진다.func panic(interface{})// 모든 타입 사용 가능panic(42)panic(&quot;hello panic&quot;)...패닉 전파 그리고 복구프로그램을 개발할 때는 문제를 빠르게 파악해서 해결하는게 중요서비스 배포 시작 뒤에는 최대한 안죽는게 중요함 ! 페이스북이 오류가 발생시마다 웹서버가 종료된다면 사용자 경험이 안좋기 때문에 이럴때 복구를 해야할 필요가 있다.개발 단계에서 panic을 사용해서 개발하다가 서비스 배포를 한다고 했을 때 이 모든 panic함수를 지우고 error를 반환하는 방법으로 바꾸기 어려울 수 있기 때문에 이럴 때 복구(recover)를 해준다.func recover() interface{}// panic()에 넣어주었던 인자를 반환값으로 반환해줌.// defer와 함께 사용된다.Go는 SEH를 지원하지 않는다.SEH(Structured Error Handling) 구조화된 에러.try{} catch {}왜 안쓰는가? 성능문제 에러를 먹어버리는 문제 (오히려 에러 처리를 등한시 한다)에러 처리는 매우 중요함!보통 에러 처리를 귀찮아 하고 코드를 지저분하게 만든다고 생각하여 등한시 하거나 무시하지만에러처리는 매우 중요하다.에러 처리 역시 중요한 코드 일부분으로 여기고 에러를 반환하는 함수에서 반환되는 에러를 제대로 처리해야 한다. 개발 단계에서의 에러는 드러내야 하고 조기에 발견하여 더 큰 문제를 미연에 방지해야 한다.!!" }, { "title": "Data Structure with Golang", "url": "/posts/DsInGo/", "categories": "Development, Go", "tags": "golang, data structure", "date": "2021-09-09 11:46:00 +0900", "snippet": "이 글은 Tucker님의 고언어 강의 Go 언어가 온당을 듣고 정리한 내용을 토대로 작성하였습니다.Go언어가 온당 Youtube연결 리스트(Linked List): 배열과 함께 가장 기본적인 선형 자료구조 중 하나golang에서는 container라는 패키지에서 여러 자료구조를 다룬다.type Element struct{ Value interface{} Next *Element Prev *Element}package mainimport( &quot;container/list&quot; &quot;fmt&quot;)func main(){ v := list.New() e4 := v.PushBack(4) e1 := v.PushFront(1) v.InsertBefore(3, e4) v.InsertAfter(2, e1) for e := v.Front(); e != nil; e = e.Next(){ fmt.Println(e.Value, &quot; &quot;) } fmt.Println() for e := v.Back(); e!=nil; e = e.Prev(){ fmt.Println(e.Value, &quot; &quot;) } }배열 vs 리스트 맨 앞에 요소 삽입 배열의 경우 배열 안의 모든 요소들을 한칸씩 뒤로 보내고 맨 앞에 새 값을 넣는다 O(n) 리스트의 경우 요소 개수에 상관없이 맨 앞 리스트의 prev값을 새 노드의 주소로 넣어주면 되기때문에 O(1) 삽입에서는 리스트 압승! 특정 요소에 접근 배열에서 인덱스 이동 공식 = 배열 시작 주소 + (인덱스 x 타입 크기)=&amp;gt; O(1) 리스트에서는 맨앞 노드에서 내가 원하는 노드까지 한칸한칸 이동해서 접근해야함=&amp;gt; 최악의 경우 n번 이동해야 하므로 O(n) 접근에 있어서는 배열의 승리! 행위 [배열, 슬라이스] [리스트]삽입 O(n) O(1)삭제 O(n) O(n)접근 O(1) O(n)데이터 지역성데이터가 인접해 있을 수록 캐시 성공률이 올라가고 성능도 증가한다.(어떤 연산을 실행하려고 할 때 내가 실행하려는 연산 이후의 연산이 주변 메모리에서 일어날 확률이 높기 때문에 주변 데이터도 다 가져온다. ) =&amp;gt; 캐시 성공찾지 못한경우 = 캐시 실패,캐시를 비우고 다시 캐시를 가져온다.배열의 경우 데이터 지역성이 높아 캐시 성공률이 높아 더 성능이 좋다.일반적으로 요소 수가 적은 경우 리스트보다 배열이 빠르다.(보통 1000개정도 까지는 무난하게 배열이 더 빠르고 10,000개 정도 부터는 고민을 해봐야 되겠다.) 그러면 이진트리의 경우 배열로 구현하는 경우 데이터 지역성이 높아져 더 성능이 좋을지도..?큐 Queue선입선출 (First In First Out) 구조package mainimport( &quot;container/list&quot; &quot;fmt&quot;)type Queue struct{ v *list.List}func (q *Queue) Push(val interface{}){ q.v.PushBack(val)}func (q *Queue) Pop() interface{}{ front := q.v.Front() if front != nil{ return q.v.Remove(front) } return nil}func NewQueue() *Queue{ return &amp;amp;Queue{list.New()}}func main(){ queue := NewQueue() for i := 1; i&amp;lt;5; i++{ queue.Push(i) } v := queue.Pop() for v != nil{ fmt.Printf(&quot;%v -&amp;gt;&quot;, v) v = queue.Pop() }}스택 Stack선입후출(First In Last Out)package mainimport( &quot;container/list&quot; &quot;fmt&quot;)type Stack struct{ v *list.List}func NewStack() *Stack{ return &amp;amp;Stack{list.New()}}func (s *Stack) Push(val interface{}){ s.v.PushBack(val)}func (s *Stack) Pop() interface{}{ back := s.v.Back() if back != nil{ return s.v.Remove(back) } return nil}func main(){ stack := NewStack() books := [5]string{&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;} for i := 0; i &amp;lt; 5; i++{ stack.Push(books[i]) } val := stack.Pop() for val != nil{ fmt.Printf(&quot;%v -&amp;gt;&quot;, val) val = stack.Pop() }}보통 큐 -&amp;gt; 리스트, 스택 -&amp;gt; 배열로 구현한다.링 ring맨 뒤 노드의 Next()가 맨 첫 노드가 되는 리스트package mainimport( &quot;container/ring&quot; &quot;fmt&quot;)func main(){ r := ring.New(5) n := r.Len() for i := 0; i&amp;lt; n; i++{ r.Value = &#39;A&#39; + i r = r.Next() } for j := 0; j&amp;lt;n; j++{ fmt.Printf(&quot;%c&quot;, r.Value) r = r.Next() } fmt.Println() for j := 0; j&amp;lt;n; j++{ fmt.Printf(&quot;%c&quot;, r.Value) r = r.Prev() }}" }, { "title": "[Git] 형상관리 시스템과 Git, Github에 대해 알아보자", "url": "/posts/AboutGit/", "categories": "Development, Git", "tags": "git, github, branch, push, pull, revert, reset", "date": "2021-08-17 23:43:00 +0900", "snippet": "Quest 00. 형상관리 시스템 본 포스팅은 WebDevCurriculum 레포의 퀘스트에서 제공하는 checklist와 Quest를 하나하나 해결하며 기록을 남기기 위한 포스팅 입니다. 시리즈 목록 00. Quest00: 형상관리 시스템과 Git, Github에 대해 알아보자 오늘의 주제오늘의 주제는 형상관리 시스템이다. 형상관리 시스템인 Git의 기초적인 사용법을 알아보자.목표git clone, git add, git commit, git push, git pull, git branch, git stash 명령어를 알고 Git에 대한 이것저것Checklist 형상관리 시스템은 왜 나오게 되었을까요? git은 어떤 형상관리 시스템이고 어떤 특징을 가지고 있을까요? git은 어떻게 개발되게 되었을까요? git이 분산형 시스템을 채택한 이유는 무엇일까요? git과 GitHub은 어떻게 다를까요? git의 clone/add/commit/push/pull/branch/stash 명령은 무엇이고 어떨 때 이용하나요? 그리고 어떻게 사용하나요? git의 Object, Commit, Head, Branch, Tag는 어떤 개념일까요? git 시스템은 히스토리를 어떻게 저장할까요? 리모트 git 저장소에 원하지 않는 파일이 올라갔을 때 이를 되돌리려면 어떻게 해야 할까요?Quest GitHub에 가입한 뒤, 이 커리큘럼의 저장소를 Fork떠서 자신의 저장소에 복사해 둡니다. 터미널에 접속하여 명령어를 이용하여 복사한 저장소(자신의 저장소에 있는 레포)를 clone합니다. 앞으로 git 작업은 되도록 커맨드라인을 통해 하는 것을 권장합니다. 이 문서가 있는 폴더 바로 밑에 있는 sandbox폴더에 파일을 추가한 후 커밋해 보기도 하고, 파일을 삭제해 보고 수정해 보기도 하면서 각각의 단계에서 커밋했을 때 어떤 것들이 저장되는지를 확인합니다. clone, add, commit, push, pull, branch, stash 명령을 충분히 익혔다고 생각되면, 자신의 저장소에 이력을 push합니다.CheckList1. 형상관리 시스템은 왜 나오게 되었을까요?형상관리 시스템이 왜 나오게 되었는지 알려면 형상관리의 정의가 무엇인지 알아야 할 것 같아서 정의를 먼저 찾아보았다. 형상관리 시스템이란?소프트웨어 구성 관리 또는 형상 관리는 소프트웨어의 변경사항을 체계적으로 추적하고 통제하는 것으로, 형상 관리는 일반적인 단순 버전관리 기반의 소프트웨어 운용을 좀 더 포괄적인 학술 분야의 형태로 넓히는 근간을 이야기한다.음.. 나는 소프트웨어적인 관점에서 형상관리 시스템이란 소스코드 등의 변경사항, 버전 등을 체계적으로 관리해주는 시스템이라고 이해를 했다. 그렇다면 이 시스템은 왜 나오게 되었을까?만약 내가 형상관리 시스템이 없던 시절의 개발자였다면 아마 이런 상황들이 한번쯤은 발생하지 않았을까 싶었다. “되던 코드를 고쳤는데 에러가 나.. 근데 되던 코드를 저장을 안해놨어..” “너가 A기능을 만들어 내가 B기능을 만들게! 근데 우리 각각의 코드를 어떻게 합치지..?” “컴퓨터가 고장이나서 내가 짠 코드들을 찾을 수가 없어 ㅠㅠ;;;” “매번 코드를 공유할때마다 압축해서 메일로 보내고 받고.. 협업하기 너무 힘드네 ..”잠깐만 생각을 해봤는데도 굉장히 불편할거같다는 생각이 든다. 당연하게도 형상관리 시스템이 없던 시절에는 이 문제들 외에도 많은 문제점들이 있었을 것이고 이 문제를 해결하기위해 위대하신 개발자 선배님들께서 형상관리 시스템을 만드신 것이 아닐까 생각해볼 수 있을 것 같다.2. git은 어떤 형상관리 시스템이고 어떤 특징을 가지고 있을까요?git은 분산 버전 관리 시스템(Distributed revision control system)이다.버전 관리 시스템은 크게 두가지로 분류할 수 있는데 첫째는 중앙집중식 버전관리 둘째는 분산 버전 관리이다. 중앙 집중식 버전관리의 경우에는 central server에서 코드를 가져오면 그 코드의 commit(변경 기록들)은 가져오지 않고 오직 중앙 서버의 파일만을 받아오는 반면 분산 버전 관리 시스템은 해당 저장소를 변경 기록들과 함께 복제해온다. 그래서 CVCS의 경우 중앙서버에 문제가 생기면 변경기록들을 전부 잃는 반면에 DVCS에서는 중앙서버에 문제가 생겨도 clients중 하나를 골라 변경기록들과 함께 서버를 복원시킬 수 있다.요약git은 분산 버전 관리 시스템이며 저장소를 복제할 때 변경사항의 기록들(commit)을 함께 복제해온다는 특징이 있다.3. git과 Github는 어떻게 다른가요?git은 버전관리 툴, github은 git을 이용한 서비스라고 생각하면 될 것 같다. Github에서 제공하는 서비스를 활용하여 여러사람들이 하나의 저장소를 가지고 보다 쉽게 협업할 수 있다.4. git의 clone/add/commit/push/pull/branch/stash 명령은 무엇이고 어떨 때 이용하나요? 그리고 어떻게 사용하나요? git clone: 원격 저장소의 데이터를 카피해오는 행위이며 이 행위를 clone이라고 한다. $ git clone https://github.com/j1mmyson/repoName.git# Clones a repository to your computer clone 뒤에 따라오는 url은 깃허브의 해당 저장소에서 확인할 수 있다. git add: commit을 하기전에 변경된 사항들을 추가해나가는 행위.commit을 하게되면 staging area에 있는 변경사항들에 대해서 기록을 남기게 되는데 이때 git add 명령어를 통해 staging area에 변경사항들을 올릴 수 있다. $ git add filename # 작업 디렉토리 전체에서 변경된 사항들을 스테이징 에리어에 올려줌.$ git add -A # 현재 디렉토리 하위에 있는 변경사항들만 스테이징 에리어에 올려줌.$ git add . git commit: 로컬 저장소에 staged된 변경사항들에 대하여 변경을 확정짓고 기록을 하는 행위.git commit을 통해 변경된 내용들에 대하여 새롭게 기록을 남긴다. 일종의 flag를 남긴다고 생각하면 될 것 같고 나중에 commit된 기록들 중 데이터를 백업하거나 해당 commit의 변경사항을 보거나 할 수 있다. git에서 사용하는 가장 기본적인 원자 데이터 단위이다. $ git commit -m &quot;commit message&quot; git push: 로컬 저장소에 남긴 기록들의 히스토리를 원격 저장소에 적용하는 행위commit을 통해 내 로컬 저장소에 남은 기록들을 원격 저장소에 보내는 행위이다. $ git push &amp;lt;저장소명&amp;gt; &amp;lt;브랜치명&amp;gt;$ git push origin master # &amp;lt;저장소명&amp;gt;은 아래 명령어로 확인할 수 있다.$ git remote # -u 옵션은 최초 한번만 저장소명, 브랜치명을 입력하고 이후에는 git push만 사용해도 되게 해준다.$ git push -u origin master # 가급적 사용하지 말것, 지양해야 할 행위# -f 옵션으로 강제로 현재 로컬 저장소의 변경사항을 원격 저장소에 덮어씌우는 행위$ git push -f origin master git pull: 원격저장소의 변경사항들을 로컬 저장소로 가져와 merge하는 행위pull = (변경사항을 가져오는 fetch) + (가져온 변경사항을 적용하는 merge) $ git pull # pull은 아래 두가지로 쪼개질 수 있음$ git fetch$ git diff HEAD origin master # 이거는 fetch해서 가져온 변경사항과 현재 내 저장소를 비교해주는 명령어$ git merge git branch: 깃에서는 작업 트리를 관리할 수 있는데 이 작업트리를 다룰 수 있는 명령어이다.Git Branch 기초 $ git branch # 브랜치 목록을 불러온다.$ git branch &amp;lt;branch_name&amp;gt; # 이름이 branch_name인 브랜치를 생성한다. $ git checkout &amp;lt;branch_name&amp;gt; # branch_name 브랜치로 작업공간을 전환해준다. git stash: 현재 작업중인 변경사항을 임시 공간에 저장해두기 위한 명령어현재 브랜치에서 발생한 변경사항들을 커밋해주지 않으면 브랜치 변경이 불가능한데 현재 변경사항을 커밋하고 싶진 않지만 브랜치는 변경하고 싶을 때 stash명령어를 통해 풀어나갈 수 있다. $ git stash $ git stash list # stashed된 변경사항들의 목록을 불러온다.$ git stash apply &amp;lt;stash_name&amp;gt; # stash_name stash를 불러온다. stash_name이 없다면 가장 최근의 stash를 불러온다. $ git stash drop &amp;lt;name&amp;gt; # name의 stash를 제거한다. name이 주어지지 않으면 가장 최근의 stash를 제거한다. $ git stash pop # apply와 동시에 drop을 해주는 명령어 5. git의 Object, Commit, Head, Branch, Tag는 어떤 개념일까요? git 시스템은 히스토리를 어떻게 저장할까요?git이 파일들을 관리하기 위해 파일을 만드는데 이를 Object라고 부르며 tree, blob, commit, tag 4가지로 이루어져있다. commit의 SHA-1 값중 앞 두자리를 폴더명으로, 뒷 38자리를 파일명으로 갖는다.ls .git/objects/01 0f 1b 1c 32 34 48 49 4a 4d 4e 58 7a 7d 7e 84 90 9e a2 ae b6 b9 c2 ce d1 d4 info packls .git/objects/01/a03d6611d865f42d50e6b148ae6293bcb0756d여기서 commit object은 tree SHA-1값, parent 오브젝트의 SHA-1값, author, committer, commit message를 저장한다.Head는 커밋을 가르키는 포인터와 같은 역할을 하며 Branch는 작업 트리를 나타내고, Tag는 특정 커밋에 태그를 달아주는 역할을 한다.6. 리모트 git 저장소에 원하지 않는 파일이 올라갔을 때 이를 되돌리려면 어떻게 해야 할까요?원격 저장소에 커밋을 잘못 기록했을 때 되돌리는 방법은 크게 두가지가 있다. 첫번째는 git reset을 사용해 커밋을 취소하는 방식, 두번째는 git revert를 사용하여 커밋 내용을 되돌리는 방식이다.git reset을 사용하여 커밋 취소하기먼저 아래 명령어로 커밋 기록을 불러온다.$ git log --oneline1ec0471 (HEAD -&amp;gt; byungwook, origin/byungwook) dummy 2cdab146 dummy 101a03d6 test stash4dd0635 byungwook branch3227c4e (origin/master, origin/HEAD, master) fetch and mergeb92b1bf Create fetchtest.txtaed7c04 add text file5115cb1 Quest 19B01a6919 Quest 18B11517cd Quest19F : Small fix7763653 Quest 17-B749da4a Quest 16-B7277533 Quest 20그럼 위처럼 commit id와 함께 커밋 메시지를 불러올 수 있다. 이제 내가 돌아가고 싶은 커밋을 정하고 git reset --hard &amp;lt;commit_id&amp;gt;명령어로 해당 커밋으로 돌아간다. 나는 dummy1, dummy2 커밋을 푸시하기 전인 test stash 커밋때로 돌아가고 싶다고 가정해보자.$ git reset --hard 01a03d6위 명령어를 실행한 후 다시 git log를 실행시켜보면 HEAD가 test stash커밋을 가르키고 있는걸 확인할 수 있다.$ git log --oneline01a03d6 (HEAD -&amp;gt; byungwook) test stash4dd0635 byungwook branch3227c4e (origin/master, origin/HEAD, master) fetch and mergeb92b1bf Create fetchtest.txtaed7c04 add text file5115cb1 Quest 19B01a6919 Quest 18B11517cd Quest19F : Small fix7763653 Quest 17-B749da4a Quest 16-B이 상태에서 원격 저장소로 푸시를 해주어 커밋을 되돌릴 수 있는데 이때 그냥 푸시해버리면 에러가 발생한다. 현재 로컬에서의 커밋 기록이 원격 저장소의 커밋 기록보다 뒤쳐지기 때문에 발생하는 에러인데 이때 -f 옵션으로 강제로 푸시를 해주어야한다.$ git push -f origin &amp;lt;branch_name&amp;gt;강제로 푸시를 밀어넣는 방법으로 이미 원격저장소에 올라간 커밋을 삭제하는 방법이기 때문에 협업하는 상황에서 쓰기 좋은 방법은 아니다. 다른 사람이 작업하고 있을 때 이런식으로 커밋기록을 바꾸어 버리면 커밋기록을 바꾸기 전 저장소를 clone해간 사람들이 푸시할 때 충돌에러가 날 수 있기 때문이다. 다음 방법은 커밋 기록을 되돌렸다는 것을 남겨주는 방식인데 뭔지 한번 알아보자.Revert 로 커밋 내용 되돌리기revert 명령어를 사용하는 방식은 커밋기록을 삭제하는 것이 아닌 “커밋의 변경사항을 되돌린다”는 커밋을 만들어 주는 방식이다.$ git log --oneline74a9df1 (HEAD -&amp;gt; byungwook) commit C458ab3b commit B26acfd8 commit A커밋을 revert 시키려면 해당 커밋의 해시값을 revert명령어의 뒤에 붙여주면 된다.$ git revert 74a9df1명령을 실행하고 파일을 확인해보면 revert시킨 커밋의 변경사항이 폐지되었음을 확인할 수 있을 것이다.또 여러개의 커밋을 한번에 revert시키려면 revert명령을 여러번 수행하면서 커밋을 하나하나씩 되돌려도 되지만 그렇게 되면 한번의 revert명령마다 하나의 커밋이 추가되므로 쓸데없이 많은 커밋이 생겨버린다. 그래서 --nono-commit 옵션을 사용해 커밋을 남기지 않고 revert를 쌓을 수 있다. 또 HEAD~n..을 붙여주어 한번에 여러개의 커밋에 대해 revert를 실행시킬 수 있다.최근에 푸시한 3개의 커밋에 대해 revert를 해주고 싶다면 아래와 같이 원하는 목적을 달성할 수 있다.$ git revert --no-commit HEAD~3..--no-commit옵션을 사용하면 반드시 따로 커밋을 해주어야 한다.$ git commit -m &quot;revert recent 3 commits&quot;$ git push이제 푸시까지 해주고 원격 저장소를 확인해보면 revert했다는 커밋이 남아있음과 동시에 되돌리고 싶었던 커밋이 되돌려 진 것을 확인할 수 있다." }, { "title": "[vuejs/golang] When the syntax of golang template and vue.js overlaps", "url": "/posts/vueGolang/", "categories": "Development, Vue", "tags": "golang, vue, delimiters", "date": "2021-08-01 01:45:00 +0900", "snippet": "problemsmain.gopackage main...func main() { engine := html.New(&quot;./templates&quot;, &quot;.html&quot;) app := fiber.New(fiber.Config{ Views: engine, }) app.Static(&quot;/static&quot;, &quot;./static&quot;) app.Use(logger.New()) app.Get(&quot;/&quot;, index) app.Listen(&quot;:8080&quot;)}func index(c *fiber.Ctx) error { return c.Render(&quot;index&quot;, fiber.Map{ &quot;message&quot;: &quot;hello vue js!&quot;, })}index.html&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt; &amp;lt;meta charset=&quot;UTF-8&quot;&amp;gt; &amp;lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&amp;gt; &amp;lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&amp;gt; &amp;lt;script src=&quot;https://unpkg.com/vue@next&quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;title&amp;gt;Vue tutorial&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt; &amp;lt;div id=&quot;app&quot;&amp;gt; name: &amp;lt;br&amp;gt; age: &amp;lt;/div&amp;gt; {{ .message }} &amp;lt;script src=&quot;static/js/main.js&quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt; const mountedApp = app.mount(&#39;#app&#39;) &amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;error ┌───────────────────────────────────────────────────┐ │ Fiber v2.16.0 │ │ http://127.0.0.1:8080 │ │ (bound on host 0.0.0.0 and port 8080) │ │ │ │ Handlers ............. 4 Processes ........... 1 │ │ Prefork ....... Disabled PID .............. 5430 │ └───────────────────────────────────────────────────┘ 17:03:20 | 500 | 0s | 127.0.0.1 | GET | / | template: &quot;index&quot; is an incomplete or empty templateSolution: delimiters를 [&#39;${&#39;, &#39;}&#39;]로 바꾸어 주었다.main.jsconst app = Vue.createApp({ delimiters: [&#39;${&#39;, &#39;}&#39;], data() { return { name: &quot;son&quot;, age: 24, } }})console.log(&quot;hello&quot;)index.html...&amp;lt;body&amp;gt; &amp;lt;div id=&quot;app&quot;&amp;gt; name: ${ name }&amp;lt;br&amp;gt; age: ${ age } &amp;lt;/div&amp;gt; {{ .message }} &amp;lt;script src=&quot;static/js/main.js&quot;&amp;gt;&amp;lt;/script&amp;gt; ... &amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;" }, { "title": "[Go/testing] golang에서 test code를 짜보자", "url": "/posts/testInGo/", "categories": "Development, Go", "tags": "golang, testing, test code, benchmark, tdd", "date": "2021-07-28 09:15:00 +0900", "snippet": "golang에서는 테스트 코드를 짤 수 있도록 testing이란 패키지를 지원해 준다.오늘은 이 testing패키지를 이용해서 테스트 코드를 짜고 각 함수의 성능을 비교해보는 benchmark까지 다뤄보겠다.testingtesting패키지는 고언어의 표준 패키지이기 때문에 따로 받아올 필요가 없다. 그저 testing패키지를 임포트 해주고 사용하면 된다. 먼저 테스트 코드의 예시를 보겠다.fibo_test.gopackage fibo_testimport ( &quot;testing&quot; &quot;github.com/j1mmyson/testing/fibo&quot;)func TestFibo(t *testing.T) { ans := fibo.GetFibo(50) if ans != 12586269025 { t.Errorf(&quot;Fibo(50) = %d; want 12586269025\\n&quot;, ans) }}Go에서 testing패키지를 이용할 때는 몇가지 규칙을 지켜야 한다. 파일명을 *_test.go로 지을 것. 패키지명을 *_test로 지을 것. 테스트 함수명을 func TestXxx(t *testing.T)의 형태로 지을 것. (UpperCamelCase)테스트 코드를 짜보았다. GetFibo(50)의 결괏값을 받아와서 그 값이 12586269025가 아니면 에러를 반환하는 코드이다. 이제 테스트 코드 속에 보이는 GetFibo() 함수를 짜보자. 테스트 코드를 통해 우리가 원하는 GetFibo()함수의 형태는 정수형 변수를 인자로 받아 정수를 반환해 주는 함수란 것을 알 수 있다.package fibofunc GetFibo(n int) int { n1, n2 := 1, 1 for i := 0; i &amp;lt; n-2; i++ { n1, n2 = n2, n1+n2 } return n2}GetFibo()함수도 완성시켰으니 이제 테스트를 시작해보자.테스트는 테스트 코드가 존재하는 디렉토리에 들어가서 $ go test 명령을 실행시켜주면 된다. 실행시켜보면 아래와 같은 결과를 얻을 수 있다.$ go testPASSok github.com/j1mmyson/testing/fibo 0.010s-v 태그를 붙여서 세부사항까지 확인할 수 있다.$ go test -v=== RUN TestFibo--- PASS: TestFibo (0.00s)PASSok github.com/j1mmyson/testing/fibo 0.009코드를 잘못 짜 테스트가 실패하면 어떻게 될까? 원하는 출력값이 나오지 않도록 임의로 조정한 후 테스트 코드를 돌리면 아래와 같은 결과를 출력해 준다.$ go test--- FAIL: TestFibo (0.00s) fibo_test.go:13: Fibo(50) = 12586269025; want 1258626902FAILexit status 1FAIL github.com/j1mmyson/testing/fibo 0.006s-cover플래그를 통해 테스트 코드의 coverage까지 구할 수 있다. coverrage란 이 프로그램에서 내가 어느 정도까지 테스트 코드를 짰느냐를 나타내는 수치이다. 현재 코드에서 $ go test -cover를 실행시키면 아래처럼 커버리지가 100%라고 나온다.$ go test -coverPASScoverage: 100.0% of statementsok github.com/j1mmyson/testing/fibo 0.007s그렇다면 fibo패키지에 임의의 함수를 하나 추가해보자.package fiboimport &quot;fmt&quot;func GetFibo(n int) int {...}func PrintHello() { fmt.Println(&quot;Hello world!&quot;)}그러고 다시 테스트 코드를 돌려보면 coverage가 떨어진 것을 확인할 수 있다. PrintHello()함수에 대한 테스트 코드가 짜여있지 않기 때문이다.$ go test -coverPASScoverage: 80.0% of statementsok github.com/j1mmyson/testing/fibo 0.006sbenchmarktesting패키지에서는 함수의 성능을 측정할 수 있는 벤치마킹 기능도 제공을 해준다. 앞선 코드에서 n 번 째 피보나치의 수를 구해주는 GetFibo()함수를 구현했었는데, 조금 다른 방법으로 같은 기능을 구현하는 함수를 하나 더 짜보자.func GetFibo(n int) int { n1, n2 := 1, 1 for i := 0; i &amp;lt; n-2; i++ { n1, n2 = n2, n1+n2 } return n2}func GetFibo2(n int) int { var slice []int slice = []int{1, 1} for i := 0; i &amp;lt; n-2; i++ { slice = append(slice, slice[i]+slice[i+1]) } return slice[len(slice)-1]}자, 첫 번째 함수의 경우에는 두 변수를 선언하고 루프를 돌면서 재할당을 반복하는 방식으로 피보나치 수를 구하게끔 구현을 하였고두 번째 함수에서는 slice를 선언하여 dp 알고리즘으로 슬라이스의 뒤쪽에 계속해서 다음 피보나치 수를 붙여가는 방법을 구현해보았다.1번 함수의 경우두 변수 선언 + n * (합연산 + 재할당)2번 함수의 경우슬라이스 선언 + n * (슬라이스에 접근 + 합연산 + 할당) + (중간중간 슬라이스의 용량 늘리기)과 같은 진행 구조를 가질 것 같다. 이렇게 보면 당연히 1번 함수가 더 빠를 것이라고 예상할 수는 있지만 정확히 얼마나 빠른지 알기는 어려울 것 같다. 이렇게 함수를 구현했으니 벤치마킹 코드도 짜보자.fibo_test.go...func BenchmarkFibo(b *testing.B) { for i := 0; i &amp;lt; b.N; i++ { fibo.GetFibo(50) }}func BenchmarkFibo2(b *testing.B) { for i := 0; i &amp;lt; b.N; i++ { fibo.GetFibo2(50) }}각 함수의 인자에 50을 넣은 연산을 testing패키지에서 제공하는 임의의 수 b.N만큼 반복을 돌려 함수의 성능을 측정해 준다는 의미이다. 이제 벤치마킹을 진행해보자.벤치마킹을 해주는 명령은 go test -bench=.이다. 명령을 실행해보면$ go test -bench=.goos: linuxgoarch: amd64pkg: github.com/j1mmyson/testing/fibocpu: Intel(R) Core(TM) i5-8265U CPU @ 1.60GHzBenchmarkFibo-8 60288513 20.00 ns/opBenchmarkFibo2-8 2552655 885.9 ns/opPASSok github.com/j1mmyson/testing/fibo 4.978s이렇게 출력을 해준다. 보면 테스트를 돌린 환경이 나오고 중간쯤 보면 BenchmarkFibo-8 ~~~, BenchmarkFibo2-8 ~~~ 부분을 확인할 수 있는데 해당 부분에서 각 함수의 성능을 알 수 있다. 보시다시피 첫 번째 함수의 벤치마킹은 20.00 ns/op, 두 번째 함수는 885. ns/op가 나온 것을 확인할 수 있고 이를 보고 확실하게 “아! 이 기능은 첫 번째 함수 방식으로 짜는 게 더 성능이 좋구나!”라고 결론을 내릴 수 있게 되는 것이다.속도뿐만 아니라 메모리 사용량에 대해서도 벤치마킹해보고 싶다면 아래처럼 명령을 내리면 확인할 수 있다.$ go test -bench=. -benchmemgoos: linuxgoarch: amd64pkg: github.com/j1mmyson/testing/fibocpu: Intel(R) Core(TM) i5-8265U CPU @ 1.60GHzBenchmarkFibo-8 59181552 19.45 ns/op 0 B/op 0 allocs/opBenchmarkFibo2-8 2588463 838.1 ns/op 992 B/op 5 allocs/opPASSok github.com/j1mmyson/testing/fibo 4.631s" }, { "title": "[Go/gin/embed] gin 프레임워크에서 embed패키지 사용해서 static file serving하기", "url": "/posts/usingEmbedWithGin/", "categories": "Development, Go", "tags": "golang, embed, gin", "date": "2021-07-23 09:42:00 +0900", "snippet": "gin 웹 프레임워크에서는 embed패키지를 사용해 만든 embedFS타입의 변수를 사용하여 정적파일을 서버에 띄우는 기능이 없(는것 같)다. 그래서 구글링과 gin코드를 뒤져서 임시방편으로나마 embedFS타입의 변수를 활용하여 템플릿과 정적파일(css, js …)들을 띄워보았다.ㄴ web ㄴ static/ ㄴ css/ - style.css ㄴ js/ - index.js ㄴ templates - index.html- main.go폴더 구조는 위 처럼 되어있다고 가정하고 코드를 짜보았다.//go:embed web/templates/*.htmlvar templatesFS embed.FS//go:embed web/static/*var staticFS embed.FS위 처럼 embed패키지를 사용해 embed.FS타입의 변수를 생성해준뒤func main() { r := gin.Default() // LoadTemplate r.GET(&quot;/&quot;, index) // Serving static files r.Run(&quot;:8080&quot;)}func index(c *gin.Context){ c.HTML(http.StatusOK, &quot;index.html&quot;, nil)}로컬호스트:8080으로 접속하면 css, js 파일을 필요로 하는 index.html파일을 클라이언트에게 보여준다. 이제 주석으로 처리한 두 부분 1. embed.FS로 load template 해주는 함수 2.embed.FS타입의 변수로 정적파일 띄우기를 채워보자.1번의 경우는 내가 직접 gin패키지 코드를 보면서 짰고 2번은 구글링을 통해 찾게되었다.// 1. LoadHTMLfunc LoadHTMLFromEmbedFS(engine *gin.Engine, em embed.FS, pattern string) { templ := template.Must(template.ParseFS(em, pattern)) engine.SetHTMLTemplate(templ)}// 2. Serve static filesfunc main(){ ... r.GET(&quot;/static/*filepath&quot;, func(c *gin.Context){ c.FileFromFS(path.Join(&quot;/web/&quot;, c.Request.URL.Path), http.FS(staticFS)) }) ...}이 방법으로 앞서 고민중이던 문제를 해결하게 되었다. LoadHTMLFromEmbedFS()함수의 경우 메서드로 짜면 r.LoadHTMLFromEmbedFS()처럼 다른 템플릿 로드 함수들과 통일성있게 사용할 수 있었겠지만 go언어에서 메서드는 해당 구조체가 존재하는 패키지에서만 선언이 가능하여 일단 함수로만 짜두었다.한가지 주의해야할 점은 위 방식대로 정적파일들을 서빙하면 html파일에서 불러올 때 경로를... &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;static/css/style.css&quot;&amp;gt;... &amp;lt;script src=&quot;static/js/index.js&quot;&amp;gt;&amp;lt;/script&amp;gt;...이런식으로 설정해주어야 한다.이렇게하여 gin프레임워크에서 embed.FS타입의 변수를 활용할 수 있다.전체코드github: https://github.com/j1mmyson/gin-embed-examplepackage mainimport ( &quot;embed&quot; &quot;html/template&quot; &quot;net/http&quot; &quot;path&quot; &quot;github.com/gin-gonic/gin&quot;)var ( //go:embed web/templates/*.html templatesFS embed.FS //go:embed web staticFS embed.FS)func main() { r := gin.Default() LoadHTMLFromEmbedFS(r, templatesFS, &quot;web/templates/*&quot;) r.GET(&quot;/&quot;, index) r.GET(&quot;/static/*filepath&quot;, func(c *gin.Context) { c.FileFromFS(path.Join(&quot;/web/&quot;, c.Request.URL.Path), http.FS(staticFS)) }) r.Run()}func index(c *gin.Context) { c.HTML(http.StatusOK, &quot;index.html&quot;, nil)}func LoadHTMLFromEmbedFS(engine *gin.Engine, em embed.FS, pattern string) { templ := template.Must(template.ParseFS(em, pattern)) engine.SetHTMLTemplate(templ)}" }, { "title": "[Devlog] 첫번째 프로젝트를 시작해보았다.", "url": "/posts/myFirstProject/", "categories": "Development, Devlog", "tags": "golang, task manager, side project", "date": "2021-07-17 19:04:00 +0900", "snippet": "드디어 첫 개인 플젝을..!훈련소를 다녀온 지 3주가 다 되어간다. 훈련소를 마치고 일주 정도 있다가 나도 나름 프로젝트라고 말할 수 있을 정도의 프로젝트를 하나쯤 만들어 보자고 다짐하게 되었고 이번 프로젝트를 시작하게 되었다.프로젝트를 시작한 지 2주 정도 지났는데 65% 정도 진행을 한 것 같아 중간 정리 글을 남기게 되었다. 이제 내 기억을 더듬어 어떤 의식의 흐름이 있었는지 되짚어 보는 시간을 가져보도록 하겠다.무엇을 만들까?처음부터 난관에 봉착했다. 어떤 프로젝트를 만들어야 할까?처음에는 뭔가.. 흔하지 않고?? 나만의 어떤 독창적인 프로젝트가 무엇이 있을까 고민을 해보았다...… 진짜 어떻게 해야할지 감이 안잡혔다.이러한 방향으로 프로젝트 아이디어를 떠올리는 건 답이 없다는 결론을 내리게 되었고 우선 내가 무엇을 할 수 있는가?와 나에게 필요한 게 뭐가 있을까?라는 포인트로 관점을 전환하게 되었다. 이렇게 생각을 하다 보니 몇 가지 적당한 기준을 찾게 되었다. 우선은 웹이다. DB를 다뤄보자. 나라도 사용할 수 있는 서비스를 만들자.이렇게 기준을 잡게 되었고 처음엔 블로그 글감 정리 웹페이지를 만들려고 하였고 프로젝트를 진행하던 중간에 Daily Task Manager로 바꾸게 되었다. 이 프로젝트가 더 내가 잘 쓸 수 있을 거 같고 몇몇 추가 기능을 붙이기에 적합하다고 생각했었던 것 같다.그렇게 나는 Daily Task Manager를 만들기 시작했다.Daily Task Manager??내가 작년에 인턴을 할 적에 매일 아침마다 슬랙 채널에 아래처럼 남겨서 작업을 했었다.# 예시입니다.[Done]- api 서버 만들기- writing swagger file[In progress]- writing dockerfile- 에러 핸들링[ToDo]- 서비스 배포하기- 다음 프로젝트 찾기이렇게 하루를 시작하기 전에 내가 뭘 끝냈고 뭘 해야 하는지 적어놓고 하루를 시작하니까 내가 뭘 해야 하는지 몰라 얼타는 시간도 줄어들고 내가 해온 것들을 보고 다음 작업 방향을 잡기도 쉬워서 굉장히 나에게 도움이 많이 되었던 문화(?)였다.그래서 이를 토대로 앱을 만들면 좋겠지만 일단 내가 앱을 만들 줄 모르니까 (ㅠㅠ;) 웹으로 만들어 보기로 하게 된 것이다.어떻게 만들것인가?자 이제 무엇을 만들지 정했으니 어떻게 만들지를 정해야 했다.처음엔 백엔드와 프론트를 구분하여 백엔드에서는 json 파일을 반환해 주는 api만 만들고 프론트에서 요청을 통해 받아온 값으로 화면을 띄워주는 CSR 방식을 채택할까 고민하다가 내가 javascript를 아직 능숙하게 다루지 못하여서 그냥 서버 쪽에서 대부분의 처리를 맡는 방식을 택하게 되었다. (다음엔 꼭 프론트, 백을 구분하여서 작업을 진행해보고 싶다.)대충 이런 모형의 구조설계를 그려놓고 코드를 짰다. 이게 서버 쪽에서 라우팅, db에 쿼리, 화면 렌더링 등의 기능을 전부 해서 그런지 코드가 굉장히 복잡해졌다고 생각된다.. 평소에 코드 짤 때 좀 더 가독성 좋고 확장성 높은 코드를 짜려고 노력하고 클린 코드에 대한 책과 글들을 읽었는데도 막상 직접 짜려니까 맘처럼 쉽지는 않았던 것 같다. 일단 완성을 하고 리팩토링을 하는 시간을 가져봐야겠다. 아무튼 내가 만들려는 daily task manager에 사용된 스택들은 아래와 같다. backend: golang orm: gorm db: mysql frontend: golang, js현재 상황은?서비스를 사용하는 영상을 짧게 따와봤다.차례대로 회원가입, 로그인, 서비스를 사용하는 모습이다.앞으로 남은 일들이제 기본적인 기능은 아래 두 가지 정도만 구현하면 완성이라고 볼 수 있겠다… 카드 수정, 삭제 버튼 달기 날짜에 따른 카드 목록들 불러오기기본적인 기능을 전부 구현하고 나면 전체 목록 불러오기라든지 좀 더 사용자에게 나은 경험을 제공하기 위한 기능들을 고민해 보고 추가하려고 한다. 물론 그전에 코드 한번 훑어보면서 좀 더 나은 코드를 위한 리팩토링부터… 하는 시간을 가져야겠다. 아 그리고 어느 정도 버전 1.0 정도 퀄리티가 되었다 싶으면 aws에 배포도 해야겠다.마무리하며확실히 사용자들이 사용한다고 가정을 하고 프로젝트를 만드니까 생각할 거리들이 굉장히 많은 것 같다. 뭐 로그인, 회원가입을 진행할 때 올바르지 못한 입력이 들어왔을 때 어떻게 사용자에게 메시지를 전달해야 할지부터 시작해서 “daily task는 남들에게 보이고 싶지 않을 수도 있는데 해당 유저의 아이디를 path parameter로 받아와 페이지를 띄우면 누구나 볼 수 있는 페이지가 되겠구나” 해서 로그인 인증 과정을 거쳐 만들어진 쿠키를 통해 페이지를 띄워줘야겠다 하는 과정도 있었고 어떻게 기능을 구현하고 요소들의 위치를 어디에 배치해야 좀 더 사용자에게 더 나은 경험을 전할 수 있을까까지 생각해 볼 기회를 가졌다 ㅋㅋ. 또 진짜 전문가는 마감에서 차이 난다라는 말이 있듯이 프론트가 얼마나 중요한지 ㅋㅋ 프론트의 소중함에 대해 알게 되었고 나도 어느 정도 할 줄은 알아야겠다는 생각이 들어 자바스크립트 프레임워크 하나 정도는 어느 정도 다룰줄 알아야겠다 싶었다. ㅋㅋ 언젠가 vue.js 혹은 앱 프론트까지 다룰 수 있는 flutter에 대한 포스팅도 한 번쯤 올릴 시기가 오지 않을까 싶다.그럼 오늘은 이정도에서 포스팅을 마치고 다음엔 프로젝트를 완성시킨 후 포스팅을 준비해 오겠다." }, { "title": "[Go] .env로 환경변수 설정하기", "url": "/posts/godotenv/", "categories": "Development, Go", "tags": "go, env, dotenv", "date": "2021-06-29 09:58:00 +0900", "snippet": "[Go] .env로 환경변수 설정하기내가 짠 소스코드를 원격저장소에 업로드 하려고 할 때 코드 속에 남들에게 보여주고 싶지않은 내 개인정보(?)가 포함되어 코드를 수정하여 업로드를 해본적이 다들 한 두번 있을것이다.아래처럼 DB연결을 하는 과정에서 사용자, 비밀번호 등이 코드에 나와버리면 그대로 업로드 하기가 꺼려진다.const( // 남들에게 보여주고 싶지 않은 친구들 user = &quot;awsuser&quot; password = &quot;123456&quot; host = &quot;localhost&quot; database = &quot;myDB&quot;)func main(){ var connectionString = fmt.Sprintf(&quot;%s:%s@tcp(%s:3306)/%s?charset=utf8mb4&amp;amp;parseTime=True&quot;, user, password, host, database) mysqlDB, err := sql.Open(&quot;mysql&quot;, connectionString) defer mysqlDB.Close()}오늘은 이와같이 코드를 통한 정보 유출을 막기위한 방법중의 한가지인 .env파일을 통해 환경변수를 설정하는 방법을 알아보겠다.godotenv오늘 소개할 패키지는 godotenv라는 친구다. go get 명령어로 패키지를 받아주자.go get github.com/joho/godotenvGitHub: https://github.com/joho/godotenvDocumentation: https://pkg.go.dev/github.com/joho/godotenv#section-documentationUsage사용법은 무지 간단하다..env파일을 만들고 그 안에 환경변수들을 설정해준뒤 코드에서 아래 형식처럼 불러오면 된다..envDBNAME=&amp;lt;db_name&amp;gt;main.gopackage mainimport ( &quot;fmt&quot; &quot;os&quot; &quot;log&quot; &quot;github.com/joho/godotenv&quot;)func main() { err := godotenv.Load(&quot;.env&quot;) if err != nil { log.Fatal(&quot;Error loading .env file&quot;) } fmt.Println(&quot;env [DBNAME]:&quot;, os.Getenv(&quot;DBNAME&quot;))}" }, { "title": "[Devlog] Golang으로 게시판을 구현해보았다(1)", "url": "/posts/BoardInGo(1)/", "categories": "Development, Devlog", "tags": "golang, board, side project, orm, gorm", "date": "2021-05-28 03:38:00 +0900", "snippet": "[Devlog] Golang으로 게시판을 구현해보았다(1)#2021-05-28아직 완성 짓지 못한 프로젝트이긴 한데 아주 기본적인 기능들은 구현이 된 것 같아 중간 정리를 해보려 한다.프로젝트 아이디어가 떠오르지 않아 뭘 해야 하나 고민하던 찰나에 남들 다 구현할 줄 안다는 게시판,, (솔직히 대충 머리로 상상 코딩해놓고 게시판 정도는 쉽겠지라고 생각했다가 만들면서 새로 알게 된 점이 많았다 ㅋㅋㅠㅠ)을 만들어 보기로 했다.스펙을 나열해보자면 프론트: Go templates 백엔드: Golang, Gorm + mysql 배포: AWS EC2, RDS요정도 되겠다.. 먼저 목차를 정리해보자.목차 ORM 글 쓰기 글 목록 불러오기 + 페이징 글 검색 (제목, 작성자) 글 수정 및 삭제 앞으로의 계획순으로 정리해보겠다. 쓰다보니 양이 많아질 것 같아 이번 글에서는 3. 글 목록 불러오기 + 페이징까지만 정리하겠다.ORM우선 이 프로젝트를 하면서 ORM을 새롭게 사용해 보게 되었다.ORM이란 Object Relational Mapping으로 직역하면 객체-관계 매핑을 뜻하며 따로 쿼리문을 작성하지 않고도 데이터 베이스를 조작할 수 있게 해주어 생산성과 가독성을 높여주는 친구이다(이전엔 쿼리문을 작성하면서 했었는데 orm을 써보니 정말 신세계였다.. ).나는 Go 언어의 orm 패키지인 gorm패키지를 가져와 사용하였다.아래 코드처럼 칼럼 값을 가진 Board 구조체를 선언해 준 뒤gormDB.AutoMigrate(&amp;amp;Board{})행이 실행되면 데이터베이스에 Board 구조체와 같은 구조의 테이블이 존재하면 연결, 그렇지 않다면 새 테이블을 생성해 준다.type Board struct { ID uint `gorm:&quot;primarykey&quot;` CreatedAt time.Time UpdatedAt time.Time Title string Author string Content string}func main() { var connectionString = fmt.Sprintf(&quot;%s:%s@tcp(%s:3306)/%s?charset=utf8mb4&amp;amp;parseTime=True&quot;, user, password, host, database) mysqlDB, err := sql.Open(&quot;mysql&quot;, connectionString) defer mysqlDB.Close() gormDB, err = gorm.Open(mysql.New(mysql.Config{ Conn: mysqlDB, }), &amp;amp;gorm.Config{}) if err != nil { panic(&quot;failed to connect database&quot;) } gormDB.AutoMigrate(&amp;amp;Board{})}이렇게 데이터베이스를 조작해주는 gormDB객체를 생성해주었고 어떻게 쓰일지는 뒤에서 알아가보도록 하자.글 쓰기일단 메인 페이지는 아래처럼 생겨먹었다.게시판 프로젝트에서 글을 쓴다는 것은 사용자가 어떤 양식에 콘텐츠를 입력하면 그 입력값을 데이터베이스에 추가를 해주는 행위라고 볼 수 있다. 그래서 나는 메인 페이지에서 글쓰기버튼을 누르면 /write로 연결해 주었고 /write에서는 사용자의 입력값을 받아 DB에 올리는 작업을 수행해 주었다.func main() { ... http.HandleFunc(&quot;/write&quot;, write) ...}func write(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodPost { title := r.PostFormValue(&quot;title&quot;) author := r.PostFormValue(&quot;author&quot;) content := r.PostFormValue(&quot;content&quot;) newPost := Board{Title: title, Author: author, Content: content} gormDB.Create(&amp;amp;newPost) http.Redirect(w, r, &quot;/&quot;, http.StatusSeeOther) return } tpl.ExecuteTemplate(w, &quot;write.gohtml&quot;, nil)}/write로 이동하게 되면 tpl.ExecuteTemplate()함수로 글을 쓰는 템플릿을 사용자에게 제공해 주었고 입력을 마친 뒤 글쓰기버튼을 누르면 서버로 post신호를 보내 if 문 블럭이 실행되어 입력값을 토대로 DB에 행을 추가해 주게 하였다.글 목록 불러오기글 목록을 불러오는 것은 DB에서 행을 불러와 출력해 주면 되었는데 단순히 불러오기만 하면 되는 게 아니라 페이징도 구현해야 했고 검색기능을 통해 글 목록을 불러올 때 어떻게 페이징을 구현해 주어야 하나 고민을 좀 했던 것 같다.처음엔 현재 페이지, 검색 키워드 등을 토대로 일일이 페이지 링크를 구현해 주어야 하나 싶어서 혹시 더 좋은 방법은 없는지 다른 홈페이지(op.gg, inven, 네이버 카페) 등을 둘러보았는데 다행히 내가 생각했던 것과 비슷하게 각 페이지 버튼(링크?)마다 /board/?page=3&amp;amp;target=제목&amp;amp;value=안녕 형식으로 링크가 걸려있어 내 생각대로 구현을 해 보았다.아직 이 부분 코드 리팩토링을 하지 않아 중복되는 부분이 많고 더 줄일 수 있는 여지가 많이 남아있다..func board(w http.ResponseWriter, r *http.Request) { var b []Board page := r.FormValue(&quot;page&quot;) if page == &quot;&quot; { page = &quot;1&quot; } pageInt, _ := strconv.Atoi(page) if keyword := r.FormValue(&quot;v&quot;); keyword != &quot;&quot; { target := r.FormValue(&quot;target&quot;) switch target { case &quot;title&quot;: q := gormDB.Where(&quot;title LIKE ?&quot;, fmt.Sprintf(&quot;%%%s%%&quot;, keyword)).Find(&amp;amp;b) pg := paginator.New(adapter.NewGORMAdapter(q), MaxPerPage) pg.SetPage(pageInt) if err := pg.Results(&amp;amp;b); err != nil { panic(err) } pgNums, _ := pg.PageNums() pageSlice := getPageList(page, pgNums) temp := PassedData{ PostData: b, Target: target, Value: keyword, PageList: pageSlice, Page: page, } tpl.ExecuteTemplate(w, &quot;board.gohtml&quot;, temp) return q := gormDB.Order(&quot;id desc&quot;).Find(&amp;amp;b) pg := paginator.New(adapter.NewGORMAdapter(q), MaxPerPage) pg.SetPage(pageInt) if err := pg.Results(&amp;amp;b); err != nil { panic(err) } pgNums, _ := pg.PageNums() pageSlice := getPageList(page, pgNums) temp := PassedData{ PostData: b, PageList: pageSlice, Page: page, } tpl.ExecuteTemplate(w, &quot;board.gohtml&quot;, temp)}target이 author인 부분을 뺐는데도 상당히 길다;;;아무튼 보면 paginator객체를 쓴 걸 확인할 수 있는데 이는 쿼리 결괏값을 토대로 페이징을 구현해 주는 패키지이다.쿼리 결과와 max per page를 인자로 주고 pg.SetPage(원하는 페이지), pg.Results(&amp;amp;board)를 해주면 board에 해당 페이지의 게시글 정보가 들어가게 된다.이렇게 /board라우터에 query parameter가 주어지면 해당 파라미터 값에 따라 게시글을 보여주고 query parameter가 주어지지 않으면 전체 게시글 목록을 보여주었다.페이징의 경우 template에 현재 페이지, 현재 페이지+-2 값을 보내주어 받아온 데이터를 토대로 링크 값을 생성해 페이지를 나열해 주었다.이렇게 해서 생성된 페이지의 모습이다. 나름 그럴싸…해보인다 ㅎㅎ…이렇게 페이징을 구현하였고 1, 3에 커서를 올리면 localhost:8080/board/?target=&amp;amp;v=&amp;amp;page=1 이런식으로 되어있다. 이렇게 글쓰기, 글 목록 불러오기, 페이징을 구현하였고 다음 글에서는 검색기능, 수정 및 삭제 등등… 에 대한 내용을 준비해오겠다.전체 코드: https://github.com/j1mmyson/board_generator데모 링크: http://ec2-3-17-39-222.us-east-2.compute.amazonaws.com/ (최신버전이 아닐 수 있음.)" }, { "title": "[Go/embed] embed 패키지로 배포를 더 쉽게", "url": "/posts/embedPackage/", "categories": "Development, Go", "tags": "go, golang, embed", "date": "2021-05-17 10:19:00 +0900", "snippet": "[Go/embed] embed 패키지로 배포를 더 쉽게embed package기존의 고언어에서 어떤 코드 외에 다른 파일이 필요한 실행파일을 실행시키려면 아래와 같이 실행파일 외에 필요한 리소스들이 있어야 실행이 되었다.binaryFileㄴ templates ㄴ index.htmlㄴ static ㄴ index.js이제 1.16.x 버전 이상에서 embed패키지를 사용하여 바이너리파일에 리소스 파일들을 포함하여 빌드할 수 있어 실행파일만으로도 프로젝트를 실행시킬 수 있게되어 작업을 진행하고 바이너리 파일을 배포하기 훨씬 쉬워졌다.How to useembed패키지는 string, []byte, FS 3가지 타입만 지원한다. 각 타입마다 간단한 예시코드를 보자. string: import ( _ &quot;embed&quot; &quot;fmt&quot;) //go:embed hello.txtvar s string func main() { fmt.Println(s)} slice of byte: import ( _ &quot;embed&quot; &quot;fmt&quot;) //go:embed hello.txtvar b []byte func main() { fmt.Println(string(b))} file system: import ( &quot;embed&quot; &quot;fmt&quot;) //go:embed hello.txtvar f embed.FS func main() { data, _ := f.ReadFile(&quot;hello.txt&quot;) fmt.Println(string(data))} 주의!//go:embed에서 //와 go사이에 공백이 없어야한다.vscode에서 ctrl+/를 해버리면 자동으로 주석뒤에 공백한칸이 생겨 실수하기 쉽다.web static files웹 서버에 필요한 파일들을 embed해주는 코드를 짜보았다.package mainimport ( &quot;embed&quot; &quot;html/template&quot; &quot;net/http&quot;)var tpl *template.Template//go:embed templates/*var content embed.FSfunc init() { tpl = template.Must(template.ParseFS(content, &quot;templates/*&quot;))}func main() { http.HandleFunc(&quot;/&quot;, index) http.HandleFunc(&quot;/second&quot;, second) http.ListenAndServe(&quot;:8080&quot;, nil)}func index(w http.ResponseWriter, r *http.Request) { tpl.ExecuteTemplate(w, &quot;index.gohtml&quot;, nil)}func second(w http.ResponseWriter, r *http.Request) { tpl.ExecuteTemplate(w, &quot;second.gohtml&quot;, nil)}이 외에 js, css파일들을 띄우기 위해서는 아래처럼 활용해주면 되겠다.//go:embed static/*var staticFiles embed.FShttp.Handle(&quot;/static/&quot;, http.FileServer(http.FS(staticFiles)))" }, { "title": "[Git] Git Branch 기초", "url": "/posts/UsingBranch/", "categories": "Development, Git", "tags": "git, branch", "date": "2021-05-06 09:41:00 +0900", "snippet": "[Git] git branch 활용 기초편Branch 명령어 git branch git branch: 존재하는 브랜치의 모든 목록을 보여준다. git branch &amp;lt;branch_name&amp;gt;: 이름이 &amp;lt;branch_name&amp;gt;인 브랜치를 생성한다. git checkout git checkout &amp;lt;branch_name&amp;gt;: 브랜치&amp;lt;branch_name&amp;gt;으로 작업 브랜치를 전환해준다. git checkout -b &amp;lt;branch_name&amp;gt;: branch_name을 생성하고 해당 브랜치로 작업 공간을 전환해준다. git merge git merge &amp;lt;branch_name&amp;gt;: 현재 브랜치에 &amp;lt;branch_name&amp;gt;브랜치의 커밋들을 병합해준다. 활용 예시 git branch feature/signup 회원가입 페이지에서 올바르지 않은 입력에 대하여 예외처리를 해주는 기능을 만들 것이므로 feature/signup이라는 브랜치를 만들어주자git branch 명령어로 존재하는 브랜치의 목록을 볼 수 있다. git checkout feature/signup 체크아웃 명령어로 feature/signup브랜치로 이동해주자.1, 2의 명령어를 묶어서 git checkout -b feature/signup로 한번에 실행할 수 있다. signup브랜치에서 작업을 수행하자 작업이 끝났다면 feature/signup브랜치에서 커밋을 올리고 푸시해주자 git commit -m &quot;Improve sign-up UI/UX&quot;, git push 마스터 브랜치로 이동한 후 feature/signup 브랜치를 merge해주자. git checkout main, git merge signup merge한 내용을 push해주자 git push 작업이 끝난 signup브랜치를 삭제해주자. git branch -d signup 원격저장소(깃허브)에서도 브랜치를 삭제해주자. git push origin --delete signup 이번 경우에는 새로 브랜치를 따고 main브랜치에서는 작업을 진행하지 않아 merge 할 때 충돌이 발생하지 않은 경우라 간단하게 진행할 수 있었다. 하지만 merge를 해줄 때 main브랜치에서도 작업이 이루어져 있는 상태라면 충돌이 발생할 수 있다. 다음엔 충돌이 일어났을 때 어떻게 관리해 주어야 하는지에 대해 정리해보겠다." }, { "title": "[Go] Command &#39;go&#39; not found error", "url": "/posts/commandNotFoundError/", "categories": "Development, Go", "tags": "go, golang, command go not found", "date": "2021-05-02 14:56:00 +0900", "snippet": "[Go] Command ‘go’ not found 에러를 해결해보자#2021-05-02Golang 설치를 완료하였더라도 컴퓨터를 재시작 하였을 때 PATH설정이 제대로 적용되어있지 않을 수 있다.그래서 매번 export PATH=$PATH:/usr/local/go/bin을 실행시켜준 뒤 go 명령어를 사용했었는데 $HOME/.profile파일에 export PATH=$PATH:/usr/local/go/bin 을 추가해주면 매번 재시작 할때마다 PATH설정이 되어서 번거롭게 export명령을 실행시켜 줄 필요가 없어진다.vi ~/.profile.profile을 열어주면 대충 아래와 같이 생겼는데 여기서 가장 아래에 export명령어를 추가해주면 된다.# ~/.profile: executed by the command interpreter for login shells.# This file is not read by bash(1), if ~/.bash_profile or ~/.bash_login# exists....# NodejsVERSION=v14.15.0DISTRO=linux-x64export PATH=/usr/local/lib/nodejs/node-$VERSION-$DISTRO/bin:$PATH#Golangexport PATH=$PATH:/usr/local/go/bingo version 명령어를 실행하여 go 명렁어가 제대로 실행되는지 확인해본다." }, { "title": "[AWS/Go] EC2에서 Go server를 지속적으로 호스팅해보자", "url": "/posts/PersistingService/", "categories": "Development, DevOps", "tags": "aws, ec2, go, golang, service, systemd", "date": "2021-04-29 23:51:00 +0900", "snippet": "[AWS] AWS EC2에서 Go binary 서비스하기#2021-04-29이전에 go 언어로 짠 웹 서버 코드를 빌드 하여 aws ec2 인스턴스로 보내준 후 바이너리 파일을 실행시켜서 웹 서버를 호스팅을 해보았다.하지만 이렇게 서비스를 호스팅 했을 때 바이너리 파일을 실행하고 있는 세션을 나가게 되면 서비스 호스팅이 되지 않아 내가 항상 서버를 호스팅 하고 싶다면 내 컴퓨터를 계속 켜놓아 세션을 켜진 상태로 유지해 주어야 했다.이러한 문제점을 system.d를 활용해 해결할 수 있다는 것을 알게 되었고 비로소 바이너리 파일을 실행하고 있는 터미널 세션에서 나가도 호스팅을 유지할 수 있게 되었다.오늘은 그 방법에 대해 정리해 보았다.system.d로 호스팅 유지하기 바이너리 파일을 aws ec2 인스턴스로 보낸다. (scp명령어 혹은 git 명령어 사용) 인스턴스의 /etc/systemd/system경로에 .service 파일을 만들어준다. cd /etc/systemd/systemsudo vi goweb.service goweb.service [Unit]Description=CRUD.gg Server [Service]ExecStart=/home/ubuntu/Go_CRUD/server # 실행할 파일의 경로WorkingDirectory=/home/ubuntu/Go_CRUD # 실행할 파일이 존재하는 폴더의 경로User=rootGroup=rootRestart=always [Install]WantedBy=multi-user.target 아래 명령어를 실행하여 서비스 배포 시작 sudo systemctl enable goweb.servicesudo systemctl start goweb.servicesudo systemctl status goweb.service # goweb.service가 잘 실행되는지 확인 세션에서 나간 후에도 서비스가 잘 배포되고 있는지 확인해본다. " }, { "title": "[AWS/Go] AWS에 웹을 구축해보자", "url": "/posts/HelloAWS/", "categories": "Development, DevOps", "tags": "aws, ec2, go, golang", "date": "2021-04-21 21:48:00 +0900", "snippet": "AWS에 웹을 구축해보자목차 AWS회원가입 EC2 인스턴스 생성 키페어 발급 웹 서버 코딩/ 바이너리 파일 생성 scp명령어로 인스턴스에 바이너리 파일 전송 ssh로 서버에 접속 접속한 서버에서 바이너리 파일 실행 브라우저로 내가 만든 AWS 웹 서버에 접속1. 회원가입AWS 회원가입을 해준다.2. 인스턴스 생성AWS 로그인 - 인스턴스 - 인스턴스 시작을 통해 새 인스턴스를 생성해준다.이 과정에서 여러가지 설정을 해줄 수 있다.나의 경우 1. AMI 선택 : Amazon Linux 2 AMI, 5. 태그 추가 : Name: webserver 그리고 6. 보안 그룹 구성에서는 내 노트북에서만 ssh접속을 할 수 있게 현재 내 ip에서만 접속을 할 수 있게 해주었고 목적이 웹 서버 배포이기 때문에 80번 포트는 누구든지 접근할 수 있게 해주었다. 이렇게 설정을 완료해주고 시작하려고 하면 키페어를 발급해준다.3. 키페어 발급 ! 키페어는 한번 발급받으면 다시 받을 수 없으니 잘 보관할 것!발급받은 키페어를 기억하기 쉬운 위치에 저장한다. 나 같은 경우 어디에서든 접근하기 쉽게 홈디렉터리에 저장해주었다.chmod 400명령어를 통해 나에게만 읽기권한을 주도록 하자. 권한을 수정하고 pem파일을 옮기면 권한이 초기화 되는 듯 하니 꼭 먼저 옮겨주고 권한을 부여해주자.mv keypairname.pem ~/.ssh/cd ~/.sshchmod 400 keypairname.pem 여기서 chmod란? chmod란 파일에 대한 권한을 설정해주는 명령어로써, chmod뒤에 나오는 숫자는 각각 나/그룹/전체의 권한을 뜻하며 권한에는 read(4), write(2), excute(1) 세 가지가 있다. 400같은 경우 read / 0 / 0 이므로 나에게만 읽기 권한이 있다는 뜻.700은 read(4)+write(2)+excute(1) / 0 / 0 이 되므로 나에게만 읽기, 쓰기, 실행 권한이 있다는 뜻이다.4. 웹 서버 코딩/ 바이너리 파일 생성이제 본격적으로 웹 서버를 띄울 코드를 짜보자. 간단하게 80번 포트에 접속하면 “Hello AWS!”텍스트를 볼 수 있게 하였다.package mainimport ( &quot;io&quot; &quot;net/http&quot;)func main() { http.HandleFunc(&quot;/&quot;, index) http.ListenAndServe(&quot;:80&quot;, nil)}func index(w http.ResponseWriter, r *http.Request) { io.WriteString(w, &quot;Hello AWS!&quot;)}그러고 바이너리 파일을 만들어 주면 되는데 이 때 만들어질 바이너리 파일을 AWS에 띄운 인스턴스의 운영체제에 맞게 만들어주어야 한다. go env명령어로 현재 설정되어있는 파라미터를 확인할 수 있고 빌드 시킬 때 아래와 같이 따로 설정하여 파일을 빌드할 수 도 있다.GOOS=linux GOARCH=amd64 go build -o custom_binaryfilename5. scp명령어로 바이너리 파일 전송scp -i ~/.ssh/[keypair].pem ./custom_binaryfilename [user]@[public_DNS]:위 명령어를 통해 내 로컬에서 인스턴스로 파일을 전송해줄 수 있다.나같은 경우 user = ubuntu였으며 public_DNS는 AWS EC2 인스턴스 탭의 인스턴스 요약에서 확인할 수 있다. 이제 파일이 제대로 보내졌는지 확인하기 위해 인스턴스에 접속을 해보자.6. ssh로 인스턴스에 접속ssh -i ~/.ssh/[keypair].pem [user]@[public_DNS]여기서 user와 public_DNS는 scp명령어 실행 할 때와 같은 인자값이다. 접속한 인스턴스에서 빠져나오려면 ctrl+c 혹은 exit을 타이핑하여 나올 수 있다.7. 바이너리 파일 실행파일 실행 권한을 주기 위해 chmod명령어를 사용해 준다. 이번엔 나에게만 읽기,쓰기,실행 권한을 부여할 것이다. 권한을 부여한 후 실행을 시켜준다.sudo chmod 700 [binary_file_name]sudo ./[binary_file_name]인스턴스 요약탭에서 퍼블릭 IPv4 주소에 접속하여 웹 서버가 제대로 띄워졌는지 확인해본다." }, { "title": "[Devlog] Go로 만드는 웹 (2): 회원가입, 로그인&amp;아웃 기능 구현..!", "url": "/posts/WebInGo(2)/", "categories": "Development, Devlog", "tags": "golang, web, side project, cookie, session", "date": "2021-04-14 00:42:00 +0900", "snippet": "Go로 만드는 웹 (2): 회원가입, 로그인&amp;amp;아웃 기능 구현..!# 2021-04-12드디어 어제..!내가 개인 프로젝트로 진행하던(Crud.gg라고 하겠습니다) crud.gg에 로그인, 로그아웃, 회원가입 기능을 붙였다. 이를 구현하기위해 1. 쿠키와 세션, 2. 비밀번호 암호화, 3. db 분리, 4. 로그인 원리? 등의 키워드로 공부를 하였다. 그 결과 ! 아직 보완하고 정리해야할 부분이 많이 남아있지만 회원가입을 하고 로그인, 로그아웃 하는 데 까지 구현을 성공하였다 ㅠㅠ.이제 코드 정리도 좀 하고 일정시간이 지나면 세션을 삭제하는 기능을 구현할 예정이고 어떤 api를 호출하여 좀 재미있고 흥미로운 프로젝트를 만들 수 있을까 고민중이다.머릿속에 있는 생각은 두 가지 있는데 하나는 블랙서바이벌:영원회귀 전적검색이고 다른 하나는 하스스톤 api를 호출하여 유저들에게 유익한 컨텐츠를 제공할 수 있게 하는 것이다.블랙서바이벌의 경우 얼마전에 api를 제공했다고 들었는데 아직 자세히 찾아보지는 못한 상태이다.하스스톤도 블랙서바이벌과 같이 내가 굉장히 좋아하는 게임인데 전적 검색기능을 제공하는 사이트가 없어 내가 한번 만들어 볼까 생각을 했었는데 아쉽게도 블리자드 api에서는 게임유저들의 전적에 대한 데이터를 제공해주지 않았다 ㅠㅠ.(제공을 해주지 않았기 때문에 하스스톤 전적검색 사이트도 없었겠지…) 아무튼 컨텐츠의 경우 일단 좀 더 crud.gg를 튼튼하게 만들고 난 후 다시 고민해볼 생각이다.이제 내가 어떻게 지금까지의 웹을 구현했는지 기록하는 시간을 가져보겠다.DataBase우선 데이터 베이스는 두 개의 테이블로 구성을 하였다.하나는 클라이언트의 상태를 유지를 위한 session테이블, 다른 하나는 모든 회원의 정보를 갖는 user테이블이다. session테이블에는 클라이언트의 쿠키와 대조하여 상태를 유지할 수 있게끔 해주는 session_id필드와 session_id와 user테이블의 연결을 위한 user_id필드가 있고 user_id는 user테이블의 primary key인 id필드에 대한 외래키이다.한번 로그인을 하고 로그인한 상태를 유지할 때 session_id와 user_id만 있으면 제 기능을 할 수 있기 때문에 불필요한 데이터 호출을 줄이기 위해 테이블을 나누었다. (이 글을 쓰다가 생각났는데 session테이블의 user_id를 primary key로 해주어 중복 로그인을 방지해야겠다..)그렇게 해서 만들어진 두 테이블이다.# session table+------------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+------------+--------------+------+-----+---------+-------+| session_id | varchar(100) | NO | | NULL | || user_id | varchar(100) | NO | MUL | NULL | |+------------+--------------+------+-----+---------+-------+# user table+----------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+--------------+------+-----+---------+-------+| id | varchar(30) | NO | PRI | NULL | || password | varchar(255) | YES | | NULL | || created | datetime | NO | | NULL | || name | varchar(30) | NO | | NULL | |+----------+--------------+------+-----+---------+-------+user 테이블을 보면 password필드만 길이가 255인 것을 확인할 수 있다 ㅋㅋ. 이는 보안을 위해 데이터베이스에 비밀번호를 암호화 하여 저장해주었기 때문이다. 너무 당연한 사실인데 평소에는 생각을 못했던 부분이었다. 비밀번호를 plain text 그대로 저장해버리면 보안에 있어서 매우 취약하고 악용될 여지도 있을 것이다.그래서 아마 해싱과 같은 방법으로 비밀번호를 저장하게 되어 db가 유출되어도 비밀번호 원문을 알지 못해 2차 피해를 막을 수 있을것이다. 이미 시중에 나와있는 서비스의 대부분의 경우 비밀번호 찾기 기능을 하면 원래의 비밀번호를 알려주지않고 임시 비밀번호를 알려주는 이유였다 ㅋㅋㅋ. (임시비밀번호 제공 기능도 구현해야겠네..)회원가입사실 회원가입의 경우에는 비교적 특별할 게 없었다.그냥 회원가입 페이지에서 post 요청이 오면 해당 페이지의 form데이터를 받아와 DB에 넣어주는 기능만 하면 되었다. (또 글을 쓰다가 생각 났는데 사용자가 유효하지 않은 입력을 넣어주었을 때 예외처리도 해주어야겠다.)아직 회원가입을 포함해 모든 코드 정리를 하지 않았지만 코드를 보자.func signUp(w http.ResponseWriter, req *http.Request) { // 이미 로그인이 되어있다면 index페이지로 redirect. if alreadyLoggedIn(req) { http.Redirect(w, req, &quot;/index&quot;, http.StatusSeeOther) return } // 이부분은 그냥 페이지를 띄워주는 건데 굳이 if문에 넣지 않아도 될것같다. if req.Method == http.MethodGet { tpl.ExecuteTemplate(w, &quot;signup.gohtml&quot;, nil) } // &quot;submit&quot;버튼을 누르면 실행되는 블럭. db에 user정보를 저장하고 로그인페이지로 redirect. if req.Method == http.MethodPost { CreateUser(db, req) http.Redirect(w, req, &quot;/&quot;, http.StatusSeeOther) }}로그인로그인 기능 부터 할 이야기가 많지만… 최대한 짧게 정리하겠다 ㅋㅋ..로그인 기능을 구현하기 위해 어떻게 상태를 유지해야 하나.. 찾아보다가 쿠키와 세션에 대해 알게 되었고 공부를 하고나서 바로 적용시켰다.로그인 페이지로 들어왔을 때 이미 로그인이 된 상태라면 index페이지로 redirect해주었다.회원가입 버튼을 누르면 회원가입 페이지로, 로그인버튼을 누르면 입력한 id, pw를 검증하여 인덱스 페이지로 이동하게끔 해주었다. 코드는 아래와 같다. 마찬가지로 코드 설명은 주석으로 대체!func login(w http.ResponseWriter, req *http.Request) { // 이미 로그인이 되었다면 index page로 redirect if alreadyLoggedIn(req) { http.Redirect(w, req, &quot;/index&quot;, http.StatusSeeOther) return } // login 버튼이 눌렸다면 if req.Method == http.MethodPost { user, err := ReadUser(db, req) // 입력받은 데이터가 db에 존재하는지 확인 // 없다면 에러 페이지 반환 =&amp;gt; 추후에 login page에 알람을 띄워주는 형태로 해주자 if err != nil { http.Error(w, err.Error(), http.StatusForbidden) return } sID := uuid.New() // session_id로 쓸 uuid 생성 // name이 session이고 Value가 uuid인 쿠키를 생성 =&amp;gt; 상태유지를 위함1 c := &amp;amp;http.Cookie{ Name: &quot;session&quot;, Value: sID.String(), } http.SetCookie(w, c) // session table에 uuid와 id를 저장 =&amp;gt; 상태유지를 위함2 CreateSession(db, c.Value, user.Id) // 로그인 완료, 인덱스페이지로 redirect http.Redirect(w, req, &quot;/index&quot;, http.StatusSeeOther) return } tpl.ExecuteTemplate(w, &quot;login.gohtml&quot;, nil)}이렇게 로그인을 성공하게 되면 일단 위와 같이 내가 로그인 한 회원의 정보를 볼 수 있게끔 해주었다.로그아웃로그아웃은 더더더더욱 간단하다.그냥 session쿠키, session쿠키와 대응하는 session 테이블의 행을 삭제해주면 끝이기 때문.그렇게 되면 더이상 상태를 유지해주는 뭐가 없기때문에 로그아웃이 된다.func logout(w http.ResponseWriter, req *http.Request) { // 로그인이 되어있지 않다면 로그인 페이지로 redirect if !alreadyLoggedIn(req) { http.Redirect(w, req, &quot;/&quot;, http.StatusSeeOther) return } c, _ := req.Cookie(&quot;session&quot;) // delete session DeleteSession(db, c.Value) // cookie의 maxage가 음수인 것은 삭제를 의미한다 c = &amp;amp;http.Cookie{ Name: &quot;session&quot;, Value: &quot;&quot;, MaxAge: -1, } http.SetCookie(w, c) // cookie와 session을 삭제하였으니 로그인 페이지로 redirect! http.Redirect(w, req, &quot;/&quot;, http.StatusSeeOther)}마치며..위에서 보여준 코드들은 일단 페이지를 띄워주는 코드들이고 이 외에도 세션에 대한 코드, DB를 다루는 코드 등 (사실 이부분이 더 많긴함) 이 있지만 글에서는 이 정도로만 정리하겠다. 전체 코드 소스는 여기서 확인할 수 있다.오늘 내가 혼자 만들고있는 crud.gg 웹 프로젝트의 중간 진행상황에 대해 정리해보았는데 막상 이렇게 정리해보니까 되게 별거 없다고 느껴졌다 ㅋㅋㅋㅋ.. 아직 그만큼 할 일이 많이 남았고 고민해야 할 부분도 많이 남은 것 같다.다음엔 내가 이 글을 쓰며 중간중간 기록한 보완점 들, 일정시간이 지나면 로그아웃이 되는 기능 등을 구현하여 돌아오겠다. 일단 내일 있는 프로그래머스 월간 코드 챌린지를 준비해야 한다.. 얼마전에 있었던 스타트업 코딩 페스티벌 2021때 봤던 코테 이후로는 알고리즘 문제를 단 한 문제도 풀지 않은 것 같다 ㅋㅋㅋㅋ. 1~2주 정도 알고리즘을 쉬었으니 다시 꾸준히…… 알고리즘 문제를 풀어줘야겠다..프로그래머스 월간 코드챌린지를 마치고 코드 정리, 앞서 거론한 기능들 구현, 흥미로운 api 찾고 적용해보기 등의 컨텐츠를 잘 준비해 오겠다.Todo 중복 로그인 방지 비밀번호 찾기 (로그인 시) 입력 예외처리 일정시간 경과 시 로그아웃 코드정리 api 찾기 …" }, { "title": "[삽질] 자꾸 예상치 못한 301 redirect가 일어날 때...", "url": "/posts/301redirect/", "categories": "Development, Devlog", "tags": "go, golang, 301, moved permanently, redirect, cache, no-cache", "date": "2021-04-11 01:19:00 +0900", "snippet": "자꾸 예상치 못한 301 redirect가 일어날 때… 아니 분명 맞는데 왜 내 생각대로 코드가 안돌아가 - - ;;;;;오늘 아래 코드를 돌리는데 &quot;/bar&quot;로 갈 때 bar.gohtml가 보여지도록 해주었는데 자꾸 index페이지로 돌아가는 것이었다…func main() { http.HandleFunc(&quot;/&quot;, index) http.HandleFunc(&quot;/bar&quot;, bar) http.HandleFunc(&quot;/hello&quot;, hello) http.Handle(&quot;/favicon.ico&quot;, http.NotFoundHandler()) http.ListenAndServe(&quot;:8080&quot;, nil)}func bar(w http.ResponseWriter, req *http.Request) { // get cookie c, err := req.Cookie(&quot;session&quot;) if err != nil { http.Redirect(w, req, &quot;/&quot;, http.StatusSeeOther) return } un, ok := dbSessions[c.Value] if !ok { http.Redirect(w, req, &quot;/&quot;, http.StatusSeeOther) return } u := dbUsers[un] tpl.ExecuteTemplate(w, &quot;bar.gohtml&quot;, u)}아무리 봐도 코드는 잘못된게 없어보이는데 index로 redirect되는 이유를 찾지못하여 한참을 삽질하던 찰나에..브라우저 개발자 도구에서 network탭을 살펴보니…!!!/bar에서 301(moved permanently / from disk cache) 코드를 반환해주면서 /로 돌아가는 것을 확인했다.그리고 뒤에 보이는 from disk cache…. 캐시라는 단어를 보자마자 “아 내가 혹시 이전에 설정해놓은 것이 캐시에 남아서 이렇게 되었나?” 라는 생각이 뇌리를 스쳤고, 이전에 redirect를 공부하며 짰던 코드를 보니 아니나 다를까… /bar에 /로 moved permanently redirect를 해주었던 것이 발견되었다..func bar(w http.ResponseWriter, r *http.Request) { fmt.Println(&quot;Your request method at bar: &quot;, r.Method) http.Redirect(w, r, &quot;/&quot;, http.StatusMovedPermanently)} ㅂㄷㅂㄷ….HTTP 캐시들은 보통 GET에 대한 응답만을 캐싱한다고 한다. 그래서 /bar에서 301을 반환해주는 get메소드를 캐싱하여 캐시에 남았고 그 후에 /bar에 접근할 때 캐시 리소스를 재사용하여 /로 redirect 되었던 것이었다.해서 브라우저 설정에 들어가서 캐시를 삭제하고 나니 제대로 실행이 되었다!하지만 매번 이렇게 캐시를 삭제할 수 는 없지 않을까? 예를들어 웹 서비스를 사용하는 유저들에게 “제대로 동작하지 않으면 캐시를 삭제하고 다시 시도해보세요.” 라는 메세지를 남길수도 없는 노릇이다.. 그래서 찾아보니 이럴 때는 HTTP 헤더에 Cache-control을 설정해주면 된다는 걸 알게되었다.no-store =&amp;gt; 캐시는 클라이언트 요청 혹은 서버 응답에 관해 아무것도 저장하지 않는다.no-cache =&amp;gt; 캐시된 복사본을 사용자에게 릴리즈 하기 전에 휴효성 확인을 위해 원 서버로 요청을 보낸다.이 외에도 여러 값이 있는데 no-cache로 헤더를 지정해주면 오늘과 같은 상황을 해결해 줄 수 있다.Golang에서는 아래 함수의 첫째줄과 같이 헤더를 설정해줄 수 있다.func bar(w http.ResponseWriter, r *http.Request) { w.Header().Set(&quot;Cache-Control&quot;, &quot;no-cache, private, max-age=0&quot;) fmt.Println(&quot;Your request method at bar: &quot;, r.Method) http.Redirect(w, r, &quot;/&quot;, http.StatusMovedPermanently)}" }, { "title": "[Go] Golang에서의 쿠키", "url": "/posts/Cookie/", "categories": "Development, Go", "tags": "go, cookie", "date": "2021-04-08 00:21:00 +0900", "snippet": "[Go] Golang에서의 쿠키쿠키란 무엇인가?쿠키는 서버가 클라이언트의 웹 브라우저에 저장하는 정보/파일 입니다. 최대 4kb까지 저장이 가능하며 쿠키의 최대 갯수는 브라우저마다 상이합니다. 상태를 유지를 포함해 여러 활용이 가능하며 클라이언트에게 파일을 저장하게 하므로 서버의 부하를 덜어주는 역할도 합니다.쿠키는 key:value쌍을 가지며 두 값 외에도 여러 값을 가집니다. 아래는 go언어에서의 cookie 타입입니다. 몇 개 알아보자면 Path는 쿠키를 전송할 요청 경로를, Domain은 쿠키를 전송할 도메인을 뜻하며 Expires, MaxAge는 쿠키의 만료에 대한 요소인데 뒤에서 다뤄보겠습니다.2021-04-11 추가cookie.Secure: https에서만 생성 가능한 쿠키cookie.HttpOnly: javascript로 접근 불가능type Cookie struct { Name string Value string Path string // optional Domain string // optional Expires time.Time // optional RawExpires string // for reading cookies only // MaxAge=0 means no &#39;Max-Age&#39; attribute specified. // MaxAge&amp;lt;0 means delete cookie now, equivalently &#39;Max-Age: 0&#39; // MaxAge&amp;gt;0 means Max-Age attribute present and given in seconds MaxAge int Secure bool HttpOnly bool SameSite SameSite // Go 1.11 Raw string Unparsed []string // Raw text of unparsed attribute-value pairs}쿠키 쓰기고언어에서는 쿠키를 net/http패키지의 SetCookie(w ResponseWriter, cookie *Cookie)함수로 만들 수 있습니다. ResponseWriter인터페이스와 Cookie구조체를 인자로 전해주어 사용합니다.func createCookie(w http.ResponseWriter, req *http.Request) { http.SetCookie(w, &amp;amp;http.Cookie{ Name: &quot;name of cookie&quot;, Value: &quot;value of cookie&quot;, Path: &quot;/&quot;, })}쿠키 읽기이렇게 만든 쿠키를 request의 메서드 request.Cookie(name string)를 사용해 읽어줍니다.반환값으로 쿠키와 에러를 받으며 name을 가진 쿠키가 없을경우 http.ErrNoCookie에러를 반환해줍니다.func readCookie(w http.ResponseWriter, req *http.Request) { cookie, err := req.Cookie(&quot;name of cookie&quot;) if err == http.ErrNoCookie { fmt.Println(&quot;there is no cookie named &#39;name of cookie&#39;&quot;) return } fmt.Fprintln(w, &quot;Your cookie: &quot;, cookie)}request.Cookies()를 사용해 여러개의 쿠키를 한번에 읽어올 수도 있습니다.func readCookie(w http.ResponseWriter, req *http.Request) { cookie, err := req.Cookies(&quot;name of cookie&quot;) if err == http.ErrNoCookie { fmt.Println(&quot;there is no cookie named &#39;name of cookie&#39;&quot;) return } for _, c := range cookie { fmt.Fprinln(w,&quot;cookie: &quot;, c) } fmt.Fprintln(w, &quot;Your cookie: &quot;, cookie)}전체 코드package mainimport ( &quot;fmt&quot; &quot;net/http&quot;)func main() { http.HandleFunc(&quot;/&quot;, createCookie) http.HandleFunc(&quot;/read&quot;, readCookie) http.Handle(&quot;/favicon.ico&quot;, http.NotFoundHandler()) http.ListenAndServe(&quot;:8080&quot;, nil)}func createCookie(w http.ResponseWriter, req *http.Request) { http.SetCookie(w, &amp;amp;http.Cookie{ Name: &quot;name of cookie&quot;, Value: &quot;value of cookie&quot;, Path: &quot;/&quot;, })}func readCookie(w http.ResponseWriter, req *http.Request) { cookie, err := req.Cookie(&quot;name of cookie&quot;) if err == http.ErrNoCookie { fmt.Println(&quot;there is no cookie named &#39;name of cookie&#39;&quot;) return } fmt.Fprintln(w, &quot;Your cookie: &quot;, cookie)}코드를 돌려 localhost:8080에 접속을 하면 인덱스 페이지에서 name이 &quot;name of cookie&quot;, value가 &quot;value of cookie&quot;인 쿠키를 만들게 됩니다. 만들어진 쿠키는 크롬 브라우저에서 F12/Application/Storage/Cookies에서 확인할 수 있습니다. 이렇게 쿠키를 생성해준 뒤 localhost:8080/read로 이동해주면 쿠키의 정보를 제대로 읽어올 수 있는것 을 확인할 수 있습니다.쿠키 삭제이렇게 만든 쿠키를 삭제하는 방법에는 두가지가 있습니다. 첫 째는 쿠키의 Expires값을 설정해 주는 것, 둘 째는 쿠키의 MaxAge값을 설정해 주는 것입니다. 이 두가지의 차이점은 expires는 쿠키를 언제까지 지속시킬 지에 대한 시각을 받고, MaxAge는 그 시점부터 얼마나 지속시킬지에 대한 시간을 받습니다. 허나 expires는 Deprecated되었다고 하니 MaxAge로 쿠키의 만료시간을 정해주는 게 좋아보입니다. golang에서 쿠키의 Expires, MaxAge값을 따로 설정해 주지 않으면 해당 쿠키는 session cookie가 되며 session cookie는 브라우저를 닫을 때 같이 삭제되는 쿠키입니다. 이와 대립하는 쿠키의 종류는 persistent cookie로 항상 유지되는 쿠키를 뜻합니다.쿠키의 MaxAge값을 -1로 설정해주면 쿠키가 삭제되고 자연수 n으로 설정해주면 n초동안 지속된 뒤 삭제됩니다.Expires값을 통해 쿠키의 수명을 정해주고 싶다면 time패키지를 사용해주면 되겠다.func expireCookie(w http.ResponseWriter, req *http.Request) { cookie, err := r.Cookie(&quot;cookie-name&quot;) if err := nil{ // 에러처리 } // 1. 쿠키 삭제 // cookie.MaxAge = -1 // 2. 쿠키를 5초간 지속 // cookie.MaxAge = 5 // 3. expires 설정, 현재시간으로 부터 1시간 뒤 == 쿠키의 만료시각 // expiration := time.Now().Add(time.Hour) // cookie.Expires = expiration http.SetCookie(w, cookie) http.Redirect(w, req, &quot;/&quot;, http.StatusSeeOther)}" }, { "title": "[Go] 정적파일을 서버에 올려보자", "url": "/posts/ServingFiles/", "categories": "Development, Go", "tags": "go, file server, StripPrefix, static", "date": "2021-03-26 11:53:00 +0900", "snippet": "[Go] 정적 파일을 서버에 올려보자Go언어로 웹 서버를 구현을 해보다가 분명 올바른 위치에 js, css파일이 있는데 서버를 실행시켰을 때 js, css파일을 찾지 못하는 상황이 발생했었다. 경로를 몇번 고쳐보기도 하고 구글링을 해보다가 웹서버에 파일을 올려주어야 한다는 것을 알게 되었다.. 그래서 오늘은 어떻게 서버에 정적 파일들을 서버에 올리는지에 대하여 정리해보려 합니다.http.Handlefunc Handle(pattern string, handler Handler)http.Handle()함수는 pattern와 handler를 받아서 pattern경로에 받아온 핸들러를 라우팅 해주는 함수입니다. 여기서 Handler타입은 ServeHTTP(ResponseWriter, *Request)메소드를 갖는 인터페이스 타입으로 데이터를 받아 응답해주는 역할을 해줍니다.type Handler interface { ServeHTTP(ResponseWriter, *Request)}http.FileServerfunc FileServer(root FileSystem) HandlerFileServer는 FileSystem타입의 root를 받아 root디렉토리에 존재하는 컨텐츠들을 제공해주는 Handler를 반환해준다. 아래 코드를 실행시켜보면 경로 “/”에서 http.Dir(&quot;.&quot;)(현재 위치)의 파일들을 제공해주는 것을 볼 수 있습니다.func main(){ http.Handle(&quot;/&quot;, http.FileServer(http.Dir(&quot;.&quot;))) fmt.Println(&quot;Serving ... &quot;) http.ListenAndServe(&quot;:8080&quot;, nil)}특이한 경우로 해당 경로에 index.html파일이 존재하면 index.html로 redirects 해준다고 합니다.- main.go- static - index.html - style.css - index.js위와 같은 경로에서 아래 코드를 실행시키면 static폴더의 파일들이 서버에 올라가게 되면서 index.html을 감지하여 css, js 가 제대로 적용된 index.html페이지로 redirect 되는 것을 확인할 수 있겠습니다.func main(){ http.Handle(&quot;/&quot;, http.FileServer(http.Dir(&quot;/static&quot;))) fmt.Println(&quot;Serving ...&quot;) http.ListenAndServe(&quot;:8080&quot;, nil)}http.StripPrefix끝으로 http.StripPrefix를 사용하여 내가 올리려는 디렉토리를 대체 이름의 디렉토리로 서버에 올릴 수 있습니다. 아래처럼 해주어 현재 작업하고 있는 경로에 존재하는 폴더 /assets를 서버의 /exam 폴더로 올라가게 해줄 수 있습니다.func main(){ http.HandleFunc(&quot;/&quot;, index) http.Handle(&quot;/exam/&quot;, http.StripPrefix(&quot;/exam&quot;, http.FileServer(http.Dir(&quot;./assets&quot;)))) http.ListenAndServe(&quot;:8080&quot;, nil)}func index(w http.ResponseWriter, req *http.Request) { w.Header().Ser(&quot;Content-Type&quot;, &quot;text/html; charset=utf-8&quot;) io.WriteString(w, `&amp;lt;img src=&quot;/exam/gopher.jpg&quot;&amp;gt;`)}실행해보면 index페이지에서는 /exam폴더 아래의 gopher.jpg 를 찾고 있는데 제대로 받아오는 것을 확인할 수 있습니다." }, { "title": "[Js] var, let, const의 차이점에 대해 알아보자", "url": "/posts/var,let,const/", "categories": "Development, Javascript", "tags": "js, javascript, var, let, const", "date": "2021-03-24 15:31:00 +0900", "snippet": "[Js] var, let, const의 차이점에 대해 알아보자javascript에서는 var, let, const 세가지 키워드로 변수를 선언해 줄 수 있습니다.그런데 자바스크립트에서 var키워드로 변수를 생성하는 방법은 지양해야한다고 합니다. 그렇다면 왜 var키워드를 쓰면 안되는지, 이 세가지 키워드의 차이점은 무엇인지에 대해 알아봅시다.1. 재선언자바스크립트에서 var는 계속해서 재선언이 가능합니다. 때문에 긴 코드를 짤 때 실수로 같은 이름을 가진 변수를 선언해주어도 아무런 에러, 워닝을 알려주지 않기 때문에 예상치 못한 결과값 발생을 불러올 수 있습니다.var x = 0;var x = 10; // error가 발생하지 않음.var와는 달리 let, const는 재선언이 되지 않습니다. var보다는 let, const로 변수를 선언해 주어야 하는 첫번째 이유입니다. let과 const의 차이는 재할당의 여부입니다. let은 재할당이 가능하지만 const는 재할당이 불가능하며 const는 반드시 선언과 함께 값을 초기화 해주어야 합니다.let y = 0;let y = 10; // errorconst z = 5;const z = 10; // errorconst q; // error2. 호이스팅호이스팅이란 var의 선언이나 함수의 선언을 해당 스코프에서 최상단으로 끌어 올려 먼저 선언하는 것을 말합니다. 호이스팅은 변수, 함수의 선언만 끌어 올리고 할당은 무시합니다(*). 호이스팅은 var, function 선언식만을 대상으로 합니다. 글로는 이해가 어려울 수 있으니 코드를 봅시다.console.log(x); // undefined, 선언만 끌어오고 10이 할당되지 않았음을 볼 수 있다.var x = 10;위와 같은 경우 var선언이 호이스팅되어 스코프의 상단으로 올라가 consol.log()가 실행되기전에 미리 선언이 된 것 처럼 작동하여 에러가 발생하지 않습니다. 아래와 같은 좀더 복잡한 상황도 있습니다.if(false)에는 절대 도달할 수 없지만 var v가 호이스팅되어 console.log()에서 에러가 발생하지 않는 것을 확인할 수 있습니다. (오…)foo(); function foo(){ console.log(&quot;v&quot;, v); if(false){ // 절대 도달할 수 없는 부분 var v; }}3. 스코프var: 함수 스코프 / let, const: 블록 스코프를 가집니다.스코프에 대해서는 아래 글에 조금더 자세히 정리 해놓았습니다.[Js]자바스크립트 (3)스코프" }, { "title": "[Go] Golang에서 커스텀 에러를 생성해보자", "url": "/posts/CustomError/", "categories": "Development, Go", "tags": "go, golang, error, custom error", "date": "2021-03-24 09:52:00 +0900", "snippet": "[Go] Golang에서 커스텀 에러를 생성해보자go는 error타입을 기본적으로 제공해줍니다. go공식페이지에서 error타입을 찾아보면 아래와 같습니다.type error interface{ Error() string}문자열을 반환해주는 Error() 메소드를 갖는 객체들은 모두 에러 타입이 될 수 있습니다. 따라서 우리는 아래와 같이 커스텀 에러를 만들어 줄 수 있습니다.type CustomError struct{ Code string Message string}func (e *CustomError) Error() string{ return e.Code + &quot;, &quot; + e.Message}CustomError구조체에 code, message 두개의 파라미터를 갖게 하고 에러코드와 에러메세지를 함께 반환해주는 Error()메소드를 구현해 주었습니다.func isSame(a int, b int) (bool, error){ if a == b{ return true, &amp;amp;CustomError{Code: &quot;C001&quot;, Message: &quot;Not same&quot;} } return false, nil}func main(){ a := 10 b := 10 result, err := isSame(a, b) if err != nil{ fmt.Println(err.Error()) }}간단하게 예제코드를 작성해보았는데 사실 함수에 들어온 두 정수형 변수가 같지 않을 때 에러값을 리턴해준다는 것이 적절하진 않지만… 아무튼,, 위와 같은 방식으로 함수안에서 예외상황이 발생했을 때 에러를 반환해주어 내가 잡고자 하는 에러를 핸들링해줄 수 있습니다." }, { "title": "[Js] 자바스크립트: (4)프로토타입과 this", "url": "/posts/Js-(4)protoType/", "categories": "Development, Javascript", "tags": "js, javascript, prototype, this", "date": "2021-03-18 00:00:00 +0900", "snippet": "[Js] 자바스크립트: (4)프로토 타입과 this프로토타입 이란?자바스크립트의 모든 객체는 프로토타입을 갖습니다. 프로토타입이란 객체의 부모 역할을 담당하는 객체로 해당 객체에 존재하지 않는 프로퍼티에 접근하려고 할 때, 자바스크립트는 객체의 프로토타입 객체에서 그 프로퍼티를 찾으려 시도합니다. 나한테 존재하지 않은 프로퍼티를 프로토타입(부모) 객체에서 상속받았다고 생각하면 편합니다.아래 예시코드를 들어보겠습니다. 자신의 이름을 출력하는 함수 sayHello를 가진 객체 person이 있고, sayHello를 갖지 않는 객체 student의 프로토타입을 person으로 해주었습니다. 맨 마지막 줄에서 student가 갖고있지 않은 프로퍼티 sayHello를 호출했고 자바스크립트는 student의 프로토타입인 person에서 sayHello를 찾게됩니다.let person = { sayHello: function(){ console.log(this.name); }, name: &quot;noname&quot;,}let student = { name: &quot;byungwook&quot;, age: 24, grade: &quot;A&quot;,}student.__proto__ = person;student.sayHello() // &quot;byungwook&quot; 모든 객체는 [[Prototype]]을 갖습니다.유일하게 함수 객체의 경우에만 prototype프로퍼티를 갖습니다.function sayHello(){ }console.log(sayHello.prototype.constructor) // sayHelloconstructor 프로퍼티모든 프로토타입 객체는 constructor프로퍼티를 갖습니다. constructor프로퍼티는 자기 자신을 생성한 객체를 가리킵니다.프로토타입 변경프로토타입 객체는 다른 객체로 변경할 수 있습니다. 이 때 아래와 같은 과정을 거치게 됩니다. 프로토타입 객체 변경 시점 이전에 생성된 객체 기존 프로토타입 객체를 [[Prototype]]에 바인딩 합니다. 프로토타입 객체 변경 시점 이후에 생성된 객체 변경된 프로토타입 객체를 [[Prototype]]에 바인딩 합니다. function Person(name){ this.name = name;}const foo = new Person(&#39;son&#39;);Person.prototype = {gender: &#39;male&#39;};const bar = new Person(&#39;byungwook&#39;);console.log(foo.gender); // undefinedconsole.log(bar.gender); // &#39;male&#39;console.log(foo.constructor); // Person(name)console.log(bar.constructor); // Object()this함수에서의 this함수 안에 있는 this는 함수의 주인에게 바인딩됩니다. 함수의 주인은 전역객체입니다.function test(){ console.log(this);}test() 메서드에서의 this메서드에 있는 this는 메서드를 호출한 객체로 바인딩됩니다.const person = { name: &quot;byungwook&quot;, sayHello: function(){ console.log(this.name); },};person.sayHello() // &quot;byungwook&quot;이벤트 핸들러에서의 this이벤트 핸들러에서의 this는 이벤트를 받는 HTML 요소를 가리킵니다.const btn = document.querySelector(&#39;#btn&#39;);btn.addEventListener(&#39;click&#39;, function(){ console.log(this); // &#39;#btn&#39;});생성자에서의 this생성되는 객체로 바인딩됩니다.function Person(name){ this.name = name;}const son = new Person(&#39;son&#39;);console.log(son.name); // son프로토타입에서의 thisthis는 프로토타입에 영향을 받지 않습니다. this는 어디에서 호출했든 상관없이 .앞에 있는 객체를 가리킵니다.아래 코드를 통해 예시를 들어봅시다.let hamster = { stomach: [&#39;banana&#39;, &#39;apple&#39;], eat(food){ this.stomach.push(food); }};let ham1 = { __proto__: hamster, stomach: [],};let ham2 = { __proto__: hamster, stomach: [],};ham1.eat(&quot;orange&quot;);ham2.eat(&quot;grape&quot;);console.log(ham1.stomach);console.log(ham2.stomach);this가 프로토타입에 영향을 받았다면 마지막 두 출력문에서 모두 [&#39;banana&#39;, &#39;apple&#39;, &#39;orange&#39;, &#39;grape&#39;]가 나왔어야 합니다. ham1.eat에서 eat함수안의 this는 .eat 앞의 ham1을 참조하게 됩니다." }, { "title": "[Devlog] Go로 만드는 웹 (1): MySQL 연동", "url": "/posts/WebInGo(1)/", "categories": "Development, Devlog", "tags": "golang, mysql, web, side project", "date": "2021-03-17 00:00:00 +0900", "snippet": "Go로 만드는 웹 (1): MySQL 연동현재 golang, mysql을 사용하여 로그인, 회원가입을 하는 웹페이지를 만들고 있다.음.. 일단 이 처음부터 다른 사람이 짜놓은 코드라던가 best practice는 보지 않고 만들어 보기로 했다. 뭔가 한번 봐버리면 그 틀에서 헤어 나오지 못할까 봐 일단 내 방식대로 완성을 시키고 다른 사람들이 주로 쓰는 코드와 비교해 보기로 하였다.내가 만들고자 하는 것은 일단 로그인, 회원가입이 가능한 페이지를 만들고(1차 목표) 흥미로운 API를 찾아 내 페이지에서 해당 API를 호출하여 뭔가 새로운 기능을 붙이는 것이다(2차 목표). 혼자서 웹 개발을 하는 것이 처음이라 아직 배워야 할 것도 많고 부족함도 많지만 하나하나 배우다 보면 어떤 걸 공부해야 하는지, 어떤 부분이 부족한지 알 수 있지 않을까 싶다. 그럼 내가 현재까지 구현한 부분에 대해 정리해보겠다.데이터베이스 부분을 진행할 때는 내가 전에 올렸던 글 Linux에서 MySQL 설치부터 CRUD까지를 참고하였다. ( 이렇게 내가 해본 것을 내 블로그만 보고 다시 재현할 수 있게끔 하는 것이 글을 정리하는 목적 중 하나이다!). 우선 데이터베이스를 만들어야 하는데 데이터베이스를 만들고 새 계정에 권한을 부여했다.GRANT ALL Privileges On &amp;lt;DB_NAME&amp;gt; TO &amp;lt;DB_ID&amp;gt;@localhost그러고 아래와 같은 테이블을 생성해주었다.+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | varchar(30) | NO | PRI | NULL | || password | varchar(30) | NO | | NULL | || created | datetime | NO | | NULL | || name | varchar(30) | NO | | NULL | |+----------+-------------+------+-----+---------+-------+고언어에서 mysql을 다루려면 go get github.com/go-sql-driver/mysql 명령어를 통해 mysql 드라이버를 받아야 한다. 드라이버를 받았다면 아래와 같은 코드로 연결을 해줄 수 있다.package mainimport ( &quot;database/sql&quot; &quot;net/http&quot; &quot;text/template&quot; _ &quot;github.com/go-sql-driver/mysql&quot;)var db *sql.DBfunc main(){ var connectionString = &quot;user:pw@tcp(host:3306)/dbName&quot; var err error db, err = sql.Open(&quot;mysql&quot;, connectionString) checkError(err) defer db.Close() pingDB(db)}db를 전역변수로 해준 까닭은 후에 HandlerFunc에서 db를 다른 함수로 전달해주기 위해 전역변수로 생성해주었다. 아 그리고 위 코드를 실행했을 때 connection error가 발생한다면 서버가 꺼져있다면 $ sudo service mysql start로 서버를 켠다. 해당 DB에 접근권한이 없는 user를 사용했는지 확인한다.정도를 체크해보면 되겠다.그러고 이제 서버로 폼데이터를 보낼 페이지를 작성하였다. 우선 로그인 페이지, 회원가입 페이지만 만들어 놓았으며 아래와 같이 간단하게 만들어보았다.로그인 페이지회원가입 버튼을 누르면 회원가입 페이지로 이동한다.회원가입 페이지상단의 CRUD.gg를 누르면 홈으로 되돌아가고 아래 양식을 작성한 후 Create를 눌러 폼데이터를 서버에 전송한다.앞으로 로그인을 성공했을 때의 페이지, 비밀번호 변경 페이지, 회원 정보 불러오기 등의 페이지를 추가할 것이다. 로그인을 위해 쿠키, Access token 등 공부를 해봐야 할 것 같다..이제 서버쪽을 살펴보자. net/http패키지 기반으로 구현하였으며 http/HandleFunc로 라우팅을 해주었다. 이게 그냥 서버를 띄우니까 명시적으로 불러주지 않은 파일들을 서버에 올라가지 않아 css가 제대로 적용이 안되었는데 http.FileServer()로 해결을 해주었다. func main()func main(){ // ... http.HandleFunc(&quot;/&quot;, index) http.HandleFunc(&quot;/signUp&quot;, signUp) http.Handle(&quot;/template/&quot;, http.StripPrefix(&quot;/template/&quot;, http.FileServer(http.Dir(&quot;template&quot;)))) fmt.Println(&quot;Listening...&quot;) http.ListenAndServe(&quot;:8080&quot;, nil) // ...}func index()func index(res http.ResponseWriter, req *http.Request) { tpl := template.Must(template.ParseFiles(&quot;template/index.htm&quot;)) err := tpl.Execute(res, nil) if err != nil { log.Fatalln(&quot;error executing template&quot;, err) }}func signUp()func signUp(res http.ResponseWriter, req *http.Request) { if req.Method == &quot;GET&quot; { tpl := template.Must(template.ParseFiles(&quot;template/signUp.htm&quot;)) err := tpl.Execute(res, nil) if err != nil { log.Fatalln(&quot;error executing template&quot;, err) } } if req.Method == &quot;POST&quot; { Create(db, req) http.Redirect(res, req, &quot;/&quot;, http.StatusSeeOther) }}func Create()func Create2(db *sql.DB, req *http.Request) { id := req.PostFormValue(&quot;id&quot;) password := req.PostFormValue(&quot;password&quot;) name := req.PostFormValue(&quot;name&quot;) t := time.Now().Format(&quot;2006-01-02 15:04:05&quot;) stmt, err := db.Prepare(&quot;insert into user (id, password, name, created) values (?, ?, ?, ?)&quot;) checkError(err) defer stmt.Close() res, err := stmt.Exec(id, password, name, t) checkError(err) count, err := res.RowsAffected() checkError(err) fmt.Println(count, &quot;rows affected&quot;)}일단…. 회원가입 페이지에서 폼데이터를 서버로 전송하여 데이터베이스에 작성한 데이터 기반으로 새로운 유저를 만들어 저장해주는 것 까지는 완료를 하였다. 아직 코드가 많이 더러운것같다.. 로그인 기능까지 구현하고 코드를 한번 싹 정리해야겠다.마치면서 지금까지 한 것들을 정리해보면 로그인, 회원가입 페이지 웹서버와 DB서버 연결 (Go + Mysql) 회원가입시 DB에 회원 업로드(보안 취약/에러 핸들링 해줘야함)정리해보니 별로 안되는거 같다.. 음 앞으로 해야할 것들은 로그인 기능 구현 로그인 인증 및 유지 비밀번호 등 보안 보완 코드 정리 Golang web server 프레임워크 찾아보기생각나는건 이정도 있는 것 같다. 다음에는 로그인 기능 구현과 함께 돌아오겠다." }, { "title": "[Js] 자바스크립트: (3)스코프", "url": "/posts/Js-(3)Scope/", "categories": "Development, Javascript", "tags": "js, javascript, scope", "date": "2021-03-10 00:00:00 +0900", "snippet": "[Js]자바스크립트: (3)스코프스코프란?스코프란 말 그대로 어떤 객체의 유효범위를 의미합니다. 혹은 어떤 함수가 어떤 변수를 참조할 때 그 변수를 어떻게 찾는지, 참조하려는 변수의 이름이 중복되었을 경우 어떻게 명시할 것인지 찾는 규칙이라고도 볼 수 있습니다.아래와 같은 코드가 주어졌을 때 console.log(x)함수는 어떤 x값을 참조해야하는지 어떤 규칙에 따라 정해야 할 것입니다.const x = &quot;global x&quot;;function f(){ const x = &quot;local x&quot;; console.log(x);}f(); // &quot;local x&quot;console.log(x); // &quot;global x&quot;보시다시피 f();의 실행값과 console.log(x);의 실행값이 다른 것을 확인할 수 있습니다. 만약 스코프가 존재하지 않았다면 console.log(x)가 어디에 있는 x값을 참조해야하는지 알 수 없었을 것입니다. 이렇듯 스코프는 식별자 이름의 충돌을 방지해주는 역할을 합니다. 오늘은 자바스크립트에서의 스코프에 대해 알아 보겠습니다. 결론부터 말하자면 자바스크립트에서는 함수 레벨 스코프(function-level-scope)와 렉시컬 스코프(Lexical scope)를 따른다. 그렇다면 함수 레벨 스코프와 렉시컬 스코프가 무엇인지, 또 다른 종류의 스코프는 어떤게 있는지에 대해 알아보겠습니다.블록 레벨 스코프 vs 함수 레벨 스코프블록 레벨 스코프란 코드블록 { ... }내에서만 참조(접근)할 수 있는 스코프를 의미합니다.블록 안에서 생성된 변수를 그 블록 밖에서 참조할 수 없다는 의미입니다. 대부분의 C-Family language는 블록 레벨 스코프를 따릅니다. 아래는 블록 레벨 스코프의 한 예시 입니다.int main(){ if(true){ int x = 5; printf(&quot;x = %d&quot;, x); } printf(&quot;x = %d&quot;, x); // error! return;}위 코드처럼 if문 블록 안에서 선언된 변수 x를 if문 블록 밖에서 참조하지 못하는 것을 블록 레벨 스코프라고 할 수 있겠습니다.앞서 자바스크립트에서는 함수 레벨 스코프를 따른다고 했는데 함수 레벨 스코프란 함수 내에서 선언된 변수를 함수 밖에서는 참조하지 못하는 것을 의미합니다. 따라서 함수가 아닌 블록에서 선언된 변수를 블록 밖에서도 참조할 수 있습니다.var x = 0;{ var x = 1; console.log(x); // 1}console.log(x); // 1하지만 자바스크립트에서도 블록 레벨 스코프를 사용할 수 있습니다.let과 const로 변수를 선언해주게되면 해당 변수는 블록 레벨 스코프를 따릅니다.(자바스크립트에서 var사용은 지양하고 let과 const사용을 지향하는데 자바스크립트가 함수 레벨 스코프를 따른다고 말해도 될지 잘 모르겠다 ㅇㅅㅇ;)let block = 0;{ let block = 1; console.log(block); // 1}console.log(block); // 0, block변수가 블록 스코프를 따름!내부함수내부함수는 자신을 포함하고 있는 외부함수의 변수에 접근할 수 있습니다.var x = &#39;global&#39;;function foo(){ var x = &#39;local&#39;; console.log(x); // &quot;local&quot; function bar(){ console.log(x); // &quot;local&quot; } bar();}foo();console.log(x); // &quot;global&quot;렉시컬 스코프글의 시작에서 자바스크립트는 렉시컬 스코프를 따른다고 했었습니다.렉시컬 스코프란 함수를 어디서 호출하는지가 아니라 어디에 선언하였는지에 따라 변수의 스코프를 결정해주는 것을 의미합니다. 따라서 아래와 같은 코드에서 bar()함수의 변수x는 자신을 호출한 함수 foo()의 x를 참조하는 것이 아닌, 전역변수인 x를 참조합니다.var x = 1;function foo(){ var x = 10; bar();}function bar(){ console.log(x);}foo(); // 1bar(); // 1암묵적 전역아래와 같은 코드에서 변수 y를 보면 선언하지 않았는데 값을 할당하려는 것을 볼 수 있습니다. 자바스크립트에서 이는 에러를 발생시키지 않고 전역변수가 선언된 것 처럼 기능합니다. 이렇게 y=20;이라고 선언을 해주면 window객체의 프로퍼티y값을 생성하게 됩니다. 따라서 window.y는 전역 객체의 프로퍼티가 되어 전역 변수처럼 동작하게 되고 이를 암묵적 전역(implicit global)이라고 합니다.암묵적 전역으로 생성된 y는 window객체의 프로퍼티 입니다.var global = 10;처럼 생성된 변수는 전역객체입니다.따라서 y는 객체의 프로퍼티를 삭제하는 delete연산으로 삭제할 수 있지만 전역변수로 선언된 global변수는 delete연산자로 삭제할 수 없습니다.var global = 10;prop = 20;console.log(window.global) // 10console.log(window.prop) // 20delete global; // false, 전역변수라 삭제되지 않음.delete prop; // true, 프로퍼티라 삭제됨.console.log(window.global); // 10console.log(window.prop); // undefined이번 글에서는 자바스크립트의 스코프에 대해 알아보았는데요 스코프에 대한 개념이 잡혀있지 않은 상태에서 코딩을 하면 원하는 결과가 나오지 않았을 때 어디서 잘못됐는지 찾기 어려운 상황이 많이 생길것 같아요.다음글에서는 let const var의 차이점에 대해 간단히 정리하고 넘어가볼까 해요. 그럼 다음 글에서 봐요!" }, { "title": "[Js] 자바스크립트: (2)함수", "url": "/posts/Js-(2)Function/", "categories": "Development, Javascript", "tags": "js, javascript, function", "date": "2021-03-10 00:00:00 +0900", "snippet": "[Js]자바스크립트: (2)함수함수 선언함수 선언문가장 일반적인 함수 선언 방식입니다. 함수 선언문은 아래와 같이 작성할 수 있습니다.function hello(){ console.log(&quot;hello world!&quot;);}function printInput(input){ console.log(input); return input;}함수 선언문으로 정의된 함수는 아래와 같이 호출할 수 있습니다.반환값을 갖는 함수의 경우 함수의 반환값을 변수에 저장할 수 있습니다.hello();printInput(&quot;hello world!&quot;);let result = printInput(&quot;hello world!&quot;);함수 표현식함수 선언문 말고 함수 표현식을 사용해서도 함수를 선언할 수 있습니다.함수 표현식은 아래와 같이 작성할 수 있습니다.let sayHello = function(){ console.log(&quot;Hello!&quot;);}; 함수 표현식의 경우 let variable = ~~~;의 형태를 띄고있기 때문에 끝에 세미콜론;이 들어가게됩니다.자바스크립트에서 if {}, for{}, function f{}과 같이 중괄호로 만들어진 블록에서는 끝에 세미콜론;을 붙이지 않아도 됩니다.화살표 함수위에서 설명한 두 방법 외에 더 간결하고 트렌디해보이는 방법으로도 함수를 선언할 수 있습니다.화살표 함수를 사용하는 것인데 화살표 함수는 아래와 같이 나타낼 수 있습니다.// let func = (args1, args2, ...) =&amp;gt; expression;let printInput = (input) =&amp;gt; console.log(input);// let multipleLine = (args, args2, ...) =&amp;gt; {// expression;//};let add = (a, b) =&amp;gt;{ console.log(a+b); return a+b;};함수 표현식 vs 함수 선언문함수 표현식으로 선언한 함수의 경우에는 함수 표현식이 있는 행까지 스크립트가 실행되어야 해당 함수를 사용할 수 있습니다. 아래와 같이 함수 표현식까지 도달하지 못한 상태에서 해당 함수를 호출하려고 하면 에러가 발생하는 것을 확인할 수 있습니다.hello(); // error!let hello = function(){ console.log(&quot;hello world!&quot;);};hello(); // 정상 작동.반대로 함수 선언문을 통해 함수를 선언해주면 선언문까지 도달하지 않은 상태에서도 함수를 호출할 수 있습니다. 그 이유는 자바스크립트에서는 스크립트를 실행하기 전에 전역에 선언된 함수 선언문을 찾고 미리 해당 함수를 생성해 놓기 때문입니다. 그래서 함수 선언식으로 함수를 선언해주면 언제 어디에서든 해당 함수에 접근을 할 수 있는 것이죠.매개변수원시 타입 인수함수에 전달하려는 매개변수의 타입이 원시 타입 변수인 경우 Call By Value로 동작합니다.call by value는 깊은복사로써 인자의 값만 복사하는 것 입니다.function plus(num){ num += 1; return num;}let n = 0;let result = plus(n);console.log(result); // 1console.log(n); // 0객체형 인수객체형 인수가 함수의 인자로 전달되면 Call By Reference로 동작합니다. call by reference는 call by value와 달리 얕은복사로 값을 전달하여 함수 내에서 매개변수의 값을 변경했을 때 객체형의 인수값도 같이 변경이 됩니다.function setName(obj){ obj.name = &quot;byungwook&quot;;}const obj = { name: &#39;son&#39;,};console.log(obj.name); // sonsetName(obj);console.log(obj.name); // byungwookFunction propertyfunction.lengthlength 프로퍼티는 함수 정의 시 작성된 매개변수의 갯수를 나타냅니다.function foo(){}console.log(foo.length); // 0function bar(x){ return x;}console.log(bar.length); // 1function.namename 프로퍼티는 함수명을 값으로 갖습니다.익명함수의 경우에는 빈문자열을 값으로 갖습니다.const f = function hello(){};console.log(f.name); // helloconst anonymous = function(){};console.log(anonymous.name); // &#39;&#39;이번글에서는 자바스크립트의 함수에 대해 알아보았는데요 다른 언어의 함수의 특징과 크게 다른부분은 없어서 그런지 크게 어려웠던 부분은 없었던 것 같아요. 다음 주제는 자바스크립트의 스코프에 대해 정리해볼까 합니다. 다음 글에서 봐요!" }, { "title": "[Js] 자바스크립트: (1)객체", "url": "/posts/Js-(1)Object/", "categories": "Development, Javascript", "tags": "js, javascript, object", "date": "2021-03-02 00:00:00 +0900", "snippet": "자바스크립트: (1)객체객체란?자바스크립트에서에서 객체는 다양한 데이터를 담을 수 있는 자료형이다.key-value 쌍을 저장하는 형태이며 다른 언어에서의 구조체 혹은 딕셔너리 비슷한 동작을 하는 듯 싶다. 프로퍼티와 메서드로 구성되어 있다. 프로퍼티(Property): 객체의 상태를 나타내는 값(Data) 메서드(Method): 프로퍼티를 참조할 수 있는 함수객체 생성객체는 new Object()혹은 중괄호{}를 사용하여 선언할 수 있다.let user = new Object();let user = { // Key: Value, name: &quot;byungwook&quot;, age: 24, hello: function(){ alert(&quot;Hello&quot; + this.name); },};객체를 선언하고 typeof로 선언한 객체의 타입을 확인해보면 타입이 object인 것을 확인할 수 있다.var obj = {};var obj2 = new Object();console.log(typeof obj); // objectconsole.log(typeof obj2); // object프로퍼티 접근let user = { &#39;fname&#39;: &quot;byungwook&quot;, &#39;last-name&#39;: &quot;son&quot;, age: 24, 1: 10,} 속성값에 문자형이나 심볼형에 속하지 않은 값이 들어가면 자동으로 문자열로 변환됩니다.따라서 키 값 1 은 자동으로 문자열 &quot;1&quot;로 변환됩니다.점 표기법객체의 속성과 메소드에는 점 표기법을 통해 접근할 수 있다.user.fname; // &quot;byungwook&quot;user.last-name; // `-`가 javascript의 예약어라 SyntaxError 발생.user.age; // 24대괄호 표기법대괄호 표기법을 사용하여 예약어를 포함하고 있는 속성에 접근할 수 있다.예약어를 포함하여 띄어쓰기등 키값에 어떤 문자열이 들어가던 동작한다. 단, 대괄호 안의 키값은 항상 따옴표로 감싸주어야 한다(“”, ‘’ 둘다 사용 가능하다).대괄호 표기법이 점 표기법보다 표현할 수 있는 범위가 훨씬 넓다. 근데 이게 좋은건지는 잘 모르겠다. key값이 길고 복잡하면 불편할거같아서 나라면 그냥 점 표기법으로 key값을 CamelCase로 나타내지 않을까 싶다.user[&#39;first name&#39;]; // &quot;byungwook&quot;user[&#39;last-name&#39;] // &quot;son&quot;let key = &quot;age&quot;;user[key] // &quot;24&quot;프로퍼티 삭제delete 연산자를 사용하여 객체의 프로퍼티를 삭제할 수 있다.console.log(user);delete user.name;console.log(user);delete user;console.log(user);Const 객체자바스크립트에서는 const로 선언된 객체도 수정할 수 있다.처음엔 이게 뭔 소린가 싶었다.. const는 상수를 의미하는데 const 객체의 프로퍼티를 생성, 수정, 삭제가 가능하다니..?더 알아보니 const 객체의 프로퍼티는 보호받지 못하지만 객체에 대한 참조를 변경하지 못한다고 한다 (재할당 no!). 또 const로 객체를 생성하고 프로퍼티값에 변화를 주어도 객체의 주소값은 변하지 않아 객체를 생성할 때는 const로 생성하는 것이 좋다고 한다.const user = {};user.name = &quot;byungwook&quot;;user.name = &quot;hello&quot;;const 객체는 아래와 같이 user = ~~~처럼 재할당을 시도하면 에러가 발생한다.const user = {};user = { name: &quot;byungwook&quot;, age: 24,};Uncaught TypeError: Assign to constant variable.단축 프로퍼티아래와 같이 객체의 key값과 value값이 같을 경우 줄여서 사용할 수 있다.function createUser(name, age) { let obj = { name: name, age: age, }; return obj;}function createUser(name, age) { let obj = { name, age, }; return obj;}in 연산자Javascript에서는 존재하지 않는 프로퍼티에 접근하면 undefined를 반환해주어 프로퍼티의 존재 여부를 알 수 있다.그 외에도 in연산자를 사용하여 존재 여부를 알 수 있다.const user = { name: &quot;byungwook&quot;, age: 24,};console.log(&quot;name&quot; in user);for .. in 반복문for .. in반복분으로 객체의 모든 키값을 조회할 수 있다.let user = { name: &quot;byungwook&quot;, age: 24, gender: &quot;male&quot;,};for (k in user) { console.log(k); // name, age, gender console.log(user[k]); // &quot;byungwook&quot;, 24, &quot;male&quot;}오늘은 자바스크립트의 거의 모든 면에 녹아있는 객체에 대해 공부해보았다.새로운 지식을 많이 알 수 있어서 그런지 새로운 언어를 공부하는 것은 재밌는 것 같다 ㅋㅋ.다음 시간에는 함수, 스코프, var/let/const를 공부할 예정이다." }, { "title": "[Python] python에서 입력값을 받는 여러가지 방법", "url": "/posts/pythonInput/", "categories": "Development, Python", "tags": "python, input", "date": "2021-02-17 00:00:00 +0900", "snippet": "Python에서 입력값을 받는 여러가지 방법 알고리즘 문제를 풀 때 입력값을 받아야 하는 경우가 있다. (특히 백준)오늘 알고리즘 문제를 풀다가 기록해두고픈 방법 하나를 발견하였고 기존에 쓰던 방법과 함께 정리해보려 한다.1. 하나의 값만 입력받을 때입력값 n을 받아 구구단 n단을 출력하는 예제와 같이 하나의 입력값을 받는 경우다.# input #623input()함수의 반환값은 기본적으로 문자열이다.여러 코딩테스트 문제를 풀다보면 입력받은값을 Int타입으로 받아와야하는 경우가 많은데 int()함수로 간단하게 해결할 수 있다.n = input() # n = &quot;623&quot; (default = 문자열)n = int(input()) # n = 623 (입력값을 int형 변수로 받고싶을 때)input()함수 대신에 sys패키지의 함수를 사용해서 입력값을 받을 수도 있다.sys패키지의 함수를 사용해서 입력값을 받아오는 속도가 input()함수를 사용할 때보다 빠르다고 한다.import sysn = sys.stdin.readline()2. 한줄에 여러값을 받을 때한줄에 여러값이 들어오고 공백을 기준으로 입력값을 분리하여 저장해야하는 경우다.# input #3 6 9 12 15split()함수를 통해 분리가 가능하며 split()함수에 인자값을 넣어주지않으면 공백을 기준으로 나눈다. 공백이 아니라 ,와 같은 특정값에 따라 분리해주고 싶다면 인자로 넣어주면 된다. ex) input().split(&#39;,&#39;)num_list = input().split()num_list# [&quot;3&quot;, &quot;6&quot;, &quot;9&quot;, &quot;12&quot;, &quot;15&quot;]import sysnum_list = sys.stdin.readline().split()# [&quot;3&quot;, &quot;6&quot;, &quot;9&quot;, &quot;12&quot;, &quot;15&quot;]한줄에 여러값을 Int타입으로 리스트에 저장하고 싶다면 map()함수를 사용한다.num_list = list(map(int, input().split()))num_list# [3, 6, 9, 12, 15]import sysnum_list = list(map(int, sys.stdin.readline().split()))# [3, 6, 9, 12, 15]3. 입력이 여러줄로 들어왔을 때이 방법이 내가 기록하고싶었던 방법이다. 문제를 풀고나서 다른사람의 풀이를 보다가 발견한 방법인데 어떠한 유형의 입력값이 들어와도 편하게 사용할 수 있을것 같았다.입력값을 한줄마다 나누어 저장하는 방법인데 앞서 보여준 두 방법과 결합하여 거의 모든 입력값에 대해 대응할 수 있겠다.# Input #----------10byungwookaaabbbimport sysdata = sys.stdin.read().splitlines()# data[0] = &quot;10&quot;# data[1] = &quot;byungwook&quot;# data[2] = &quot;aaa&quot;# data[3] = &quot;bbb&quot;# 와 같이 한줄씩 잘라서 리스트에 저장됨.sys.stdin.read().splitlines()로 입력값을 받아오는 코드를 내 터미널에서 테스트해보고 싶을 때, 입력값의 끝을 알려주어야 하는데 이 신호를 EOF(End Of File)라 하며 윈도우에서는 Ctrl + z 리눅스, 맥에서는 Ctrl + d를 입력해 입력의 끝을 알릴 수 있다." }, { "title": "[MySQL] Linux에서 MySQL 설치부터 CRUD까지", "url": "/posts/MySQL/", "categories": "Development, DataBase", "tags": "mysql, database", "date": "2021-02-13 00:00:00 +0900", "snippet": "MySQL 설치부터 CRUD까지 최근 Go언어로 블록체인을 구현하는걸 시도해보고 있는데 내가 생성한 블록을 저장할 데이터베이스가 있어야 한다는 것을 알았고, 데이터베이스에 대해 무지한 나를 발견했다..ㅋㅋ 그래서 데이터베이스의 종류중에 가장 많이 쓰이는 관계형 데이터베이스, 그 중 가장 많이 쓰이는 것 중 하나인 MySQL을 알아보기로 했고 생활코딩 이고잉님의 강의를 보며 내용을 정리해보았다.설치 (Linux) $ sudo apt-get update $ sudo apt-get install mysql-server실행 $ sudo service mysql start로 서버를 켜고, $ sudo mysql -u root -p를 통해 root 아이디로 mysql server에 접속한다. -u :user , -p: password를 의미한다 초기 비밀번호는 없다. 그냥 엔터한번 쳐주면 된다. 그러면 mysql&amp;gt; 과 같은 행이 나오면 성공적으로 설치가 된 것이다..! 비밀번호 설정SET PASSWORD = PASSWORD(&#39;&amp;lt;your_password&amp;gt;&#39;);리눅스에서 처음 설치하면 비밀번호가 설정되어있지 않아 그냥 엔터만 치고 들어왔는데위 명령어로 비밀번호를 설정해줄 수 있다.mysql&amp;gt; quit 하고 다시 $ sudo mysql -u root -p로 mysql을 켜주면 방금 설정한 비밀번호를 입력해야만 들어갈 수 있는걸 확인할수 있겠다.DataBase(Schema)데이터베이스 생성 CREATE DATABASE &amp;lt;DB_NAME&amp;gt;;데이터베이스 삭제 DROP DATABASE &amp;lt;DB_NAME&amp;gt;;데이터베이스 조회 SHOW DATABASES;데이터베이스 접근: 데이터베이스에 접근하여 SQL언어를 통해 데이터베이스 서버에 명령을 내릴 수 있다. USE &amp;lt;DB_NAME&amp;gt;;TABLE (표)CREATECREATE TABLE topic( id INT(11) NOT NULL AUTO_INCREMENT, title VARCHAR(100) NOT NULL, description TEXT NULL, created DATETIME NOT NULL, author VARCHAR(30) NULL, profile VARCHAR(100) NULL, PRIMARY KEY(id)); NULL: NULL값도 허용하겠다. NOT NULL: NULL값이 들어오는걸 허용하지 않겠다. INT(11): 자릿수가 최대 11인 int형 데이터만 받겠다. AUTO_INCREMENT: 행이 추가될때마다 자동으로 1씩 증가시키겠다. PRIMARY KEY(id): id를 primary key로 설정하겠다.(primary key는 중복될 수 없는 유일한 값을 가져야 한다.)SHOWSHOW COLUMNS FROM topic;DESC topic;생성된 테이블에 대한 정보를 한눈에 보고싶다면 위 명령어를 입력해주면 아래처럼 보기좋게 나오는걸 볼 수 있다. bb+-------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || title | varchar(100) | NO | | NULL | || description | text | YES | | NULL | || created | datetime | NO | | NULL | || author | varchar(30) | YES | | NULL | || profile | varchar(100) | YES | | NULL | |+-------------+--------------+------+-----+---------+----------------+현재 접속(?)한 데이터베이스에 있는 테이블 목록을 보고싶으면 데이터베이스 서버에서 데이터베이스 목록을 조회했던 것과 같이 SHOW TABLES 해주면 된다.SHOW TABLES;CRUD이제 데이터베이스의 꽃(?)이라고 볼 수 있는 CRUD를 해보자. CRUD란 Create Read Update Delete 를 의미한다.CREATEINSERT INTO 명령어를 통해 내가 원하는 테이블에 데이터를 입력할 수 있다.INSERT INTO topic (title, description, created, author, profile) VALUES (&quot;MySQL&quot;, &quot;MySQL is ...&quot;, NOW(), &quot;byungwook&quot;, &quot;developer&quot;);READSELECT 명령어를 통해 topic 테이블에 있는 모든 열에 대한 데이터를 읽어올 수 있다.SELECT * FROM topic;이런식으로 특정 열 혹은 특정 조건을 만족하는 데이터만 읽어올 수도 있다.# 특정 열만 읽기.SELECT id, title FROM topic;# 특정 조건을 만족하는 데이터만 읽기.SELECT * FROM topic WHERE id &amp;gt; 2;# 이런식으로 저자가 byungwook인 데이터의 title만 읽어오는 식으로 응용 가능!SELECT title FROM topic WHERE author = &quot;byungwook&quot;;UPDATEUPDATE 명령어로 특정 조건을 만족하는 데이터를 수정할 수 있다.# topic 테이블에서 id가 2인 데이터의 description을 &quot;Oracle is ...&quot;로, title을 &quot;ORACLE&quot;로 수정하겠다.UPDATE topic SET description= &quot;Oracle is ...&quot;, title = &quot;ORACLE&quot; WHERE id = 2;DELETEDELETE명령어를 사용할 때 WHERE키워드를 써주지 않으면 모든 데이터가 날라가니 주의하자..!DELETE FROM topic WHERE id = 1;" }, { "title": "[Markdown] 마크다운 문법 5분컷", "url": "/posts/MarkdownSyntax/", "categories": "Development, MarkDown", "tags": "markdown, md", "date": "2021-01-26 00:00:00 +0900", "snippet": "빠르게 간단한 마크다운 문법을 익혀보자 내가 주로 쓰는것들 위주로헤더(Header)# H1## H2### H3#### H4##### H5###### H6 H1 H2H3H4H5H6목록(List)1. 순서가2. 있는3. 목록- 순서가- 없는- 목록 - 탭으로 - 들여쓰기 순서가 있는 목록 순서가 없는 목록 탭으로 들여쓰기 인용구(Quote)&amp;gt; 인용구는&amp;gt;&amp;gt; `&amp;gt;` 를 늘려서&amp;gt;&amp;gt;&amp;gt; 들여쓰기(?) 가능 인용구는 &amp;gt; 를 늘려서 들여쓰기(?) 가능 구분선(Hr)---폰트(Font)__bold1__**bold2***italic1*_italic2_~~cancel~~bold1 bold2 italic1 italic2 cancel코드블럭(Code Block)​```pythonmsg = &quot;여러줄 코드블럭&quot;print(msg)​```` 한줄짜리 코드블럭 `msg = &quot;여러줄 코드블럭&quot;print(msg)` 한줄짜리 코드블럭`링크(Link)[GitHub](https://github.com/)GitHub: &amp;lt;https://github.com/&amp;gt;GitHub GitHub: https://github.com/이미지(Image)![Alt](image/path/img.PNG)크기조정을 하고싶다면&amp;lt;img src=&quot;img/path/img.PNG&quot; width = &quot;400px&quot; height=&quot;300px&quot;&amp;gt;&amp;lt;/img&amp;gt;&amp;lt;/img&amp;gt;체크박스(Check box)- [x] 게임- [ ] 공부 게임 공부" }, { "title": "GitHub Pages를 사용해 내 프로젝트를 배포해보자", "url": "/posts/DeployProject/", "categories": "Development, DevOps", "tags": "gh-pages, deploy, github", "date": "2021-01-25 00:00:00 +0900", "snippet": "GitHub-Pages를 사용해 내 프로젝트를 배포해보자. index.html을 갖는 웹프로젝트를 빠르고 간단하게 배포하는 방법을 정리해봄.프로젝트를 Github-Pages로 배포하는 방법은 다음과 같다. 새 레포 생성 Repo에 내 프로젝트 푸시 gh-pages 브랜치 생성 프로젝트 페이지 settings/GitHub Pages에서 배포 설정 user_name.github.io/RepoName에서 배포된 플젝 확인새 Repo 생성깃허브에서 새 레포를 만들어준다.Repo에 내 프로젝트 푸시 $ git clone https://github.com/userName/RepoName.git $ cd RepoName $ touch index.html 혹은 에디터 등으로 프로젝트파일 생성 $ git add . &amp;amp; $ git commit -m &quot;commit message&quot; $ git push origin maingh-pages 브랜치 생성깃허브 페이지에서도 아래와 같이 간단하게 새 브랜치를 딸 수 있다.Repo/settings프로젝트 레포의 settings에 들어가 GitHub Pages를 확인해보자.아마 gh-pages를 따게되면 자동으로 아래처럼 설정되어있을 것이다.보면 Your site is published at ~~~ , 내 플젝이 해당 링크에 배포되었다는 메세지를 확인할 수 있다.Deploy Success!해당 링크에서 내 프로젝트가 잘 배포된 것을 확인할 수 있다." }, { "title": "[알고리즘] 그래프 탐색 알고리즘 DFS와 BFS에 대해 알아보자", "url": "/posts/DFSBFS/", "categories": "Development, Algorithm", "tags": "graph, dfs, bfs", "date": "2020-12-31 00:00:00 +0900", "snippet": "DFS와 BFS에 대해 알아보자. DFS는 Deep First Search, BFS는 Breadth First Search로 그래프를 탐색하는 알고리즘 중 가장 대표적인 그래프 탐색 알고리즘이다.DFS, BFS의 개념을 알고 파이썬으로 어떻게 구현하는지에 대해 알아보자.그래프(Graph)그래프를 표현하는 방법에는 대표적으로 두 가지가 있다. 하나는 인접 행렬로 표현하는 경우, 다른 하나는 인접 리스트로 표현하는 경우이다.나의 경우에는 인접리스트로 그래프를 표현하는 방법을 주로 사용한다. 아래의 코드처럼 간선이 주어지면 인접리스트로 그래프를 표현할 수 있다.인접리스트로 그래프 표현하기n = 노드의 갯수graph = list()for i in range(n): graph.append([])edge = [[0, 1], [1, 2], [1, 3], [2, 4]]for [v, dst] in edge: graph[v].append(dst)# graph[0] = [1]# graph[1] = [2, 3]# graph[2] = [4]위 코드와 다르게 각 노드를 숫자가 아닌 문자로 표현하고 싶다면 인접리스트 대신 파이썬의 딕셔너리를 사용하면 될 것 같다.아래는 내가 그래프를 나타내고 탐색알고리즘을 돌릴 때 visited라는 변수를 통해 각 노드 방문 유무를 확인할 때 쓰는 방법이다.# 1번째 방법visited = []# 노드 v를 방문을 할 때 마다visited.append(v)# 2번째 방법n = 노드의 갯수visited = [False] * n# 노드 v를 방문 할 때 마다visited[v] = TrueDFS(Deep First Search)DFS는 깊이우선탐색으로 그래프를 탐색하는 데에 있어서 가능한 깊은곳 까지 탐색하고 더이상 탐색할 노드가 없으면 이전 노드로 돌아가면서 순회하는 탐색알고리즘이다.DFS는 스택을 활용하여 간단하게 구현할 수 있다.Stack으로 DFS 구현하기def dfs(graph, start): visited = [] stack = [start] while stack: node = stack.pop() if node not in visited: visited.append(node) stack.extend(graph[node])BFS(Breadth First Search)BFS는 너비우선탐색으로 그래프를 탐색 할 때 현재 노드에 인접한 모든 노드를 우선적으로 탐색하고 다음 노드로 넘어가며 그래프를 순회하는 탐색알고리즘이다.BFS는 큐를 활용하여 간단하게 구현할 수 있다.Queue로 BFS 구현하기visited = [False] * (노드의 갯수)def bfs(graph, start, visited): q = [start] while q: node = q.pop(0) if not visited[node]: visited[node] = True q.extend(graph[node])특정 노드 v로 부터 너비우선 탐색을 하였을 때 각 노드의 최단 깊이를 알고싶으면 이런식으로도 구현할 수 있다.BFS로 노드의 최단 깊이 구하기global d # 각 노드의 깊이를 담은 리스트d = [0] * (노드의 갯수)def bfs(v, l, visited): global d depth = 0 q = [(v, depth)] while(q): v, depth = q.pop(0) if not visited[v]: d[v] = depth visited[v] = True depth += 1 for i in l[v]: q.append([i, depth])print(d)" }, { "title": "[자료구조] 스택(Stack)과 큐(Queue)에 대해 알아보자", "url": "/posts/stackQue/", "categories": "Development, DataStructure", "tags": "data structure, stack, queue", "date": "2020-12-15 00:00:00 +0900", "snippet": "스택(Stack)과 큐(Queue)에 대해 알아보자. 스택과 큐는 자료구조에서 가장 기본적인 자료구조이다.자료구조를 처음 배울때도 아마 스택과 큐를 가장먼저 배웠던 것 같다.그만큼 굉장히 쉽고 간단하지만 중요한 자료구조이다.스택(Stack)데이터의 출입구가 하나인 자료구조.아래그림과 같은 통처럼 생긴 자료구조라고 생각하면 쉬울것같다.출입구가 하나이므로 1. 가장 먼저 넣은 데이터가 가장 아래에 쌓이게 되고 2. 가장 위에 있는 데이터만 꺼낼 수 있다.위의 1, 2번의 특성을 LIFO(Last In First Out) 혹은 선입후출 이라고 부른다.마지막에 들어간 데이터가 가장 먼저 나온다는 뜻이다.스택의 연산: Push , Pop, Peekpush스택 자료구조에 데이터를 삽입하는 행위를 push 라고한다.stack = [1, 2, 3]data = stack.push(4)print(&quot;stack = &quot;, stack) # stack = [1, 2, 3, 4]pop스택 자료구조에서 가장 위에 존재하는 데이터를 뽑아내는 연산을 pop이라고 한다.pop연산을 해주면 가장 위에있던 데이터는 스택에서 사라지게된다.stack = [1, 2, 3]data = stack.pop() # 3print(&quot;stack = &quot;, stack) # stack = [1, 2]peek (혹은 top)pop연산을 해주게되면 상위에있던 데이터가 스택에서 사라지게된다.상위에있는 데이터를 조회만 하고 싶을때는 pop연산은 적절하지 않다.이처럼 상위데이터를 조회해주는 연산이 peek이다.stack = [1, 2, 3]data = stack.top()print(&quot;stack=&quot;, stack) # [1, 2, 3]자료구조 in python1. 배열로 구현class Stack(list): def __init__(self): self.stack = [] def push(self, data): self.stack.append(data) def pop(self): if !self.is_empty(): # 스택이 비어있지않다면 return self.stack.pop() return def peek(self): return self.stack[-1] def is_empty(self): if len(self.stack) == 0: return True return False2. 연결리스트로 구현class Node: def __init__(self, data): self.data = data self.next = Noneclass Stack: def __init__(self): self.latest = None def push(self, data): new_node = Node(data) new_node.next = self.latest self.latest = new_node def pop(self): if !self.is_empty(): data = self.latest.data self.latest = self.latest.next return data return def is_empty(self): if self.latest == None: return True return False def peek(self): if !self.is_empty(): return self.latest.data return위처럼 두가지 방법으로 구현할 수 있다. 근데 나같은 경우 알고리즘 문제를 풀거나 간단한 코드를 짤때 그냥 배열만 선언해주어 배열에서 스택을 구현하는데 대충 아래 코드와 비슷하게 한다.stack = []# pushstack.append(1)stack.append(2)stack.append(3)# stack = [1, 2, 3]# peekdata = stack[-1] # data = 3 / stack = [1, 2, 3]#popdata = stack.pop() # data = 3 / stack = [1, 2]큐(Queue)큐 자료구조는 출구와 입구가 각각 하나 존재하는 자료구조이다.위 아래가 뚫려있는 원통을 생각하면 쉽다.여기서 가장 먼저들어온(출구에 가까운) 데이터의 위치를 front라 칭하고 가장 나중에 들어온 데이터의 위치를 rear라 칭한다.출입구가 하나씩 존재하고 통로가 하나이므로 먼저들어간 데이터가 먼저 나올 수 밖에없다.이러한 특성을 선입선출, FIFO(First In First Out)이라 한다.먼저 대기열에 들어온 task를 먼저 처리하는 방식의 작업에 쓰일 수 있다.번호표를 뽑거나 줄을 서서 기다리는 구조를 Queue라고 볼 수 있다!큐의 연산: Enqueue, Dequeue …Enqueue큐 자료구조에 데이터를 삽입하는 행위를 Enqueue, put이라고 한다.from queue import Queueque = Queue()que.put(1)que.put(2)# que: [1, 2] Dequeue큐 자료구조에서 front자리에 위치한 데이터를 꺼내는 행위를 Dequeue, get이라고 한다.from queue import Queueque = Queue()que.put(1)que.put(2)# que: [1, 2]data = que.get()# data = 1 / que = [2]Queue in python파이썬에서 큐는 1. 배열로 구현하거나 2. Queue 모듈을 불러와서 사용한다.1. 배열로 구현que = []# enqueueque.append(1)que.append(2)que.append(3)# get frontdata = que[0] # data: 1 / que: [1, 2, 3]# dequeuedata = que.pop(0) # data: 1 / que: [2, 3]2. Queue 모듈from queue import Queueque = Queue()# enqueueque.put(1)que.put(2)que.put(3)# dequeuedata = que.get() # data: 1 / que: [2, 3]# get queue sizesize = que.qsize()여러가지 큐큐는 스택과 다르게 여러가지 종류가 있다.일반적인 큐의 단점을 보완한 원형큐 라던지,큐에 저장된 순서와는 상관없이 우선순위에 따라 데이터 저장 위치가 달라지는 Priority Queue 등이 존재한다.이러한 큐들은 다음에 따로 다루겠다." }, { "title": "[개발자 블로그] Jekyll의 Chirpy테마로 깃허브 블로그 만들기", "url": "/posts/StartingBlog/", "categories": "Blog", "tags": "blogging, chirpy, jekyll", "date": "2020-12-14 00:00:00 +0900", "snippet": "이글의 베이스는 Chipy 공식 홈페이지의 Getting Started글이며 번역 + a 느낌으로 써내려보려고한다.Installation 깃허브에서 Chirpy Repo를 Fork 따오자. 그 후 Fork따온 레포명을 {GithubUserName}.github.io로 변경해주자. (깃허브 user name이 j1mmyson이라면 j1mmyson.github.io처럼) 터미널을 켜고 Fork따온 레포를 로컬로 가져오자. 원하는 위치로 이동하여 아래 명령어를 실행하면된다.$ git clone https://github.com/USERNAME/USERNAME.github.io.git -b master --single-branch Setting up the local environment로컬에서 블로그를 운영하려면 몇가지 설치가 필요하다.Jekyll 설치 가이드에서 자신의 운영체제에 맞게 설치를 완료하면 된다.제대로 설치가 되었다면$ ruby -v$ gem -v$ gcc -v ## g++ -v, make -v위 명령어들을 실행했을 때 버전이 뜨는것을 확인할 수 있을것이다.3가지가 제대로 설치되었다면 블로그 레포경로로 이동하여 $ bundle install명령을 실행하면 모든 dependencies들이 자동으로 설치될것이다.혹시 위 명령어에서 can`t find bundler와 같은 에러가 발생하였다면 Update RubyGems: $ gem update --system 을 통해 루비젬을 업데이트해주거나 Install the exact Bundler: $ gem install bundler -v &quot;$(grep -A 1 &quot;BUNDLED WITH&quot; Gemfile.lock | tail -n 1)&quot; 명령어로 설치하는 방법이 있다.자 이제 모든 requirement를 설치하였다.UsageInitialization이제 프로젝트 폴더로 이동하여 아래 명령어를 통해 Initialization을 해준다.$ bash tools/init.sh Note: 깃허브 페이지에 배포하는 것을 원치않는다면 위 명렁어 뒤에 --no-gh옵션을 붙여 실행하면된다.위 명령어를 실행하면 아래와 같은 작업들이 수행된다. 특정 파일과 폴더를 삭제한다. .travis.yml _posts 폴더 속 파일들 docs 폴더 --no-gh옵션을 붙여주었다면 .github폴더가 삭제될것이다. 그렇지 않다면, .github/workflows/pages-deploy.yml.hook의 .hook확장자 파일을 삭제함으로써 Github Action workflow를 셋업할 수 있다. 그 후에 .github폴더의 다른 파일, 폴더들을 삭제하면 된다. 자동으로 commit을 생성한다.Configuration_config.yml파일로 가서 여러가지 설정값들을 고정해주어야 한다. 아래값들이 대표적인(중요한?) 설정값들이다. _config.yml파일에서 아래에 해당하는 값들을 바꾸어주면된다. url: 블로그의 주소를 넣어주면 된다.e.g. url: &#39;https://j1mmyson.github.io&#39; avatar: 대표사진으로 쓰일 이미지 파일을 넣으면된다. 일반적으로 이미지 파일은 /assets/img/폴더에 넣고 불러쓴다.e.g. avatar: /assets/img/byungwook.png timezone: Find your timezone에서 자신이 속한 지역을 찾아 넣으면 된다.e.g. timezone: Asia/Seoul theme_mode: 블로그의 테마모드를 설정해주는 값. 다크와 라이트중 선택할 수 있다.e.g. theme_mode: darkRun Locally포스팅을 배포하기전에 내 로컬에서 포스팅 혹은 변경사항이 제대로 적용되었는지 아래 명령어를 통해 확인해볼 수 있다.$ bundle exec jekyll s위 명령어를 실행하고 localhost:4000으로 접속하여 확인할 수 있다.Deploy on Github Pages 아무 변경사항을 origin/master(최근에 master -&amp;gt; main으로 바뀌었다고는 하던데..) 푸시해주어 Github Actions workflow를 발동?(trigger) 시킨다. 빌드가 제대로 완료되었다면 레포의 브랜치에 gh-pages브랜치가 생성된것을 확인할 수 있을것이다. 레포의 setting으로 들어가서 아래로 쭈욱 내리면 Github Pages에 대한 설정이 나온다.위 스크린샷처럼 Branch를 gh-pages로 변경해준뒤 save를 클릭해주자.끝났다! 이제 _post/폴더에서 markdown파일을 작성하여 깃허브에 푸시해주면 블로그에 포스팅이 업데이트되는것을 확인할 수 있을것이다." }, { "title": "[개발자 블로그] Chirpy테마 게시글 작성 가이드", "url": "/posts/postingGuide/", "categories": "Blog", "tags": "blogging", "date": "2020-12-13 00:00:00 +0900", "snippet": "첫글로 Writting New Post페이지를 번역해보았다.Naming &amp;amp; PathYYYY-MM-DD-TITLE.EXTENSION 의 형식으로 새 파일을 만들어주고 _post/ 폴더에 넣어준다.EXTENSION은 md 혹은 markdown으로 해주어야한다.Front Matter기본적으로, 글을 작성할 때 아래와 같은 양식의 Front Matter를 작성해야 한다.---title: TITLEdate: YYYY-MM-DD HH:MM:SS +/- TTTTcategories: [TOP_CATEGORIE, SUB_CATEGORIE]tags: [TAG] # TAG는 반드시 소문자로 이루어져야함!--- Note: post의 layout이 기본적으로 post으로 설정되어있어서 Front Matter에 따로 layout변수를 만들어 주지 않아도 된다.Timezone of date더 정확한 시간을 포스트에 제공하기 위해서는 _config.yml의 timezone만 설정해줄 것이 아니라, Post FrontMatter에서 date필드에도 post timezone을 제공해주어야한다.형식: +/-TTTT, e.g. +0800.Categories &amp;amp; Tag각 포스트의 categories는 2개의 요소로 구성되어있으며 tags는 0~무한 개의 요소를 가질 수 있다.categories: [Animal, Insect]tags: [bee]Table of Contents기본적으로, Table of Contents(TOC)는 포스트의 오른쪽 패널에 위치한다. 만약 너가 이 기능을 끄고싶다면 _config.yml파일로가서 toc값을 false로 바꾸어주면된다. 하나의 포스트에만 이 기능을 끄고싶다면 FrontMatter에서 toc값을 false로 바꾸면된다:---toc: false---CommentsTOC와 비슷하게 Disqus comments가 각 포스트마다 기본적으로 내장되어있으며, 모든 글에대한 comments유무는 _config.yml파일의 comments값에 의해 결정된다. 하나의 포스트에만 이 기능을 끄고 싶다면 FrontMatter에서 값을 설정해주면된다:---comments: false---Mathematics웹페이지의 성능적인 이유에서 mathematical 기능은 기본적으로 꺼져있으나 아래 코드를 추가하여 켤 수 있다:---math: true---MermaidMermaid는 훌륭한 표생성 도구이다. 아래코드를 추가함으로 기능을 켤 수 있다.---mermaid: true---그러면 너는 ```mermaid로 그래프 코드를 감싸 다른 마크다운 언어와 같이 사용할 수 있다.ImagesPreview image포스트의 최상단에 이미지를 넣고싶다면 아래와 같이 url을 추가하여 이미지를 넣을 수 있다:---image: /path/to/image-file---Image caption이미지를 삽입한 다음 라인에 아래와 같이 Italics를 추가해서 이미지 캡션을 달 수 있다. 이미지 캡션은 이미지의 하단에 달린다:![img-description](/path/to/image)_Image Caption_Image sizewidth를 아래와같이 추가하여 이미지 사이즈를 설정할 수 있다.![image-description](path){: width=&quot;400px&quot;}기본적으로 이미지의 위지는 centered이다. 아래 3가지 방법으로 이미지의 위치를 normal, left, right중 하나로 설정할 수 있다: Normal ![Desktop View](/assets/img/sample/mockup.png){: width=&quot;350&quot; class=&quot;normal&quot;} Left ![Desktop View](/assets/img/sample/mockup.png){: width=&quot;350&quot; class=&quot;left&quot;} Right ![Desktop View](/assets/img/sample/mockup.png){: width=&quot;350&quot; class=&quot;right&quot;} 너가 이미지의 위치를 정하게되면 image caption은 달 수 없게된다.Pinned Posts너의 홈페이지 메인화면에 특정 게시물을 고정시킬 수 있다. 순서는 포스팅 날짜가 최근일수록 위로 올라오게된다.---pin: true---Code Block마크다운 문법 ``` 를 통해 쉽게 코드블럭을 생성할 수 있다.This is a common code snippet, without syntax highlight and line number.Specific Language```language를 통해 line number 와 syntax highlight를 갖는 코드블럭을 생성할 수 있다. Note: The Jekyll style {% highlight LANGUAGE %} or {% highlight LANGUAGE linenos %} are not allowed to be used in this theme !items: - part_no: A4786 descrip: Water Bucket (Filled) price: 1.47 quantity: 4Liguid Codes만약 Liquid snippet(수도코드?)를 배치하고싶다면 liquid code를 {% raw %}와 {% endraw %}로 감싸주면된다.{% if product.title contains &#39;Pack&#39; %} This product&#39;s title contains the word Pack.{% endif %}Learn More더 많은걸 알고싶다면, 여기로Jekyll Docs:Posts." } ]
